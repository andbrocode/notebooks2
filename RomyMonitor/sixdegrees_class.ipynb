{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7052e991-cbfd-49c2-a9b2-e7555ba3f031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4f123b-619c-4dc7-970a-7ca8f2956c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == 'lighthouse':\n",
    "    root_path = '/home/andbro/'\n",
    "    data_path = '/home/andbro/kilauea-data/'\n",
    "    archive_path = '/home/andbro/freenas/'\n",
    "    bay_path = '/home/andbro/ontap-ffb-bay200/'\n",
    "    lamont_path = '/home/andbro/lamont/'\n",
    "elif os.uname().nodename == 'kilauea':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/import/ontap-ffb-bay200/'\n",
    "    lamont_path = '/lamont/'\n",
    "elif os.uname().nodename in ['lin-ffb-01', 'ambrym', 'hochfelln']:\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/import/ontap-ffb-bay200/'\n",
    "    lamont_path = '/lamont/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279d50f4-2190-45fd-b777-b5beb4fd83fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class sixdegrees():\n",
    "\n",
    "    from obspy import UTCDateTime, Stream\n",
    "\n",
    "    def __init__(self, conf):\n",
    "\n",
    "        self.config = conf\n",
    "\n",
    "        # define startime\n",
    "        if 'tbeg' in conf.keys():\n",
    "            self.tbeg = UTCDateTime(conf['tbeg'])\n",
    "        else:\n",
    "            print(\"-> no starttime given!\")\n",
    "\n",
    "        # define endtime\n",
    "        if 'tend' in conf.keys():\n",
    "            self.tend = UTCDateTime(conf['tend'])\n",
    "        else:\n",
    "            print(\"-> no starttime given!\")\n",
    "\n",
    "        # set verbose (print information)\n",
    "        if 'verbose' in conf.keys():\n",
    "            self.verbose = conf['verbose']\n",
    "        else:\n",
    "            self.verbose = False\n",
    "\n",
    "        # seed id of stream\n",
    "        if 'seed' in conf.keys():\n",
    "            self.net, self.sta, self.loc, self.cha = conf['seed'].split('.')\n",
    "        else:\n",
    "            self.net, self.sta, self.loc, self.cha = \"XX.XXXX..\".split('.')\n",
    "\n",
    "        # seed id of rotation stream\n",
    "        if 'rot_seed' in conf.keys():\n",
    "            self.rot_seed = conf['rot_seed']\n",
    "        else:\n",
    "            print(\"-> no rotation seed id given!\")\n",
    "\n",
    "        # seed id of translation stream\n",
    "        if 'tra_seed' in conf.keys():\n",
    "            self.tra_seed = conf['tra_seed']\n",
    "        else:\n",
    "            print(\"-> no translation seed id given!\")\n",
    "\n",
    "        # station coordinates\n",
    "        if 'station_lon' in conf.keys() and 'station_lat' in conf.keys():\n",
    "            self.station_longitude = conf['station_lon']\n",
    "            self.station_latitude = conf['station_lat']\n",
    "        else:\n",
    "            print(\"-> no station coordinates given!\")\n",
    "\n",
    "        # define project name\n",
    "        if 'project' in conf.keys():\n",
    "            self.project = conf['project']\n",
    "        else:\n",
    "            self.project = \"test\"\n",
    "\n",
    "        # define working directory\n",
    "        if 'workdir' in conf.keys():\n",
    "            self.workdir = conf['workdir']\n",
    "        else:\n",
    "            self.workdir = \"./\"\n",
    "\n",
    "        # define directory for output data\n",
    "        if 'path_to_data_out' in conf.keys():\n",
    "            self.path_to_data_out = conf['path_to_data_out']\n",
    "        else:\n",
    "            self.path_to_data_out = self.workdir+\"output/\"\n",
    "\n",
    "        # path to SDS file structure for rotation data\n",
    "        if 'path_to_sds_rot' in conf.keys():\n",
    "            self.rot_sds = conf['path_to_sds_rot']\n",
    "        else:\n",
    "            print(\"-> no path to SDS file structure for rotation data given!\")\n",
    "\n",
    "        # path to SDS file structure for translaton data\n",
    "        if 'path_to_sds_tra' in conf.keys():\n",
    "            self.tra_sds = conf['path_to_sds_tra']\n",
    "        else:\n",
    "            print(\"-> no path to SDS file structure for translaton data given!\")\n",
    "\n",
    "        # path to translation station inventory\n",
    "        if 'path_to_inv_tra' in conf.keys():\n",
    "            self.tra_inv = conf['path_to_inv_tra']\n",
    "        else:\n",
    "            print(\"-> no path to translation station inventory given!\")\n",
    "\n",
    "        # path to rotation station inventory\n",
    "        if 'path_to_inv_rot' in conf.keys():\n",
    "            self.rot_inv = conf['path_to_inv_rot']\n",
    "        else:\n",
    "            print(\"-> no path to rotation station inventory given!\")\n",
    "\n",
    "\n",
    "        self.tra_output = \"ACC\"\n",
    "\n",
    "\n",
    "    # ____________________________________________________\n",
    "\n",
    "    def attributes(self):\n",
    "        return [a for a in dir(self) if not a.startswith('__')]\n",
    "\n",
    "    def check_path(self, dir_to_check):\n",
    "\n",
    "        from os import path, mkdir\n",
    "\n",
    "        if not path.isdir(dir_to_check):\n",
    "            mkdir(dir_to_check)\n",
    "            sixdegrees.check_path(self, dir_to_check)\n",
    "        else:\n",
    "            print(f\" -> {dir_to_check} exists\")\n",
    "\n",
    "    def get_rotation(self):\n",
    "        return self.st.select(channel=\"*J*\")\n",
    "\n",
    "    def get_translation(self):\n",
    "        return self.st.select(channel=\"*H*\")\n",
    "\n",
    "    def read_from_sds(path_to_archive, seed, tbeg, tend, data_format=\"MSEED\"):\n",
    "        \"\"\"\n",
    "        VARIABLES:\n",
    "         - path_to_archive\n",
    "         - seed\n",
    "         - tbeg, tend\n",
    "         - data_format\n",
    "\n",
    "        DEPENDENCIES:\n",
    "         - from obspy.core import UTCDateTime\n",
    "         - from obspy.clients.filesystem.sds import Client\n",
    "\n",
    "        OUTPUT:\n",
    "         - stream\n",
    "\n",
    "        EXAMPLE:\n",
    "        >>> st = __read_sds(path_to_archive, seed, tbeg, tend, data_format=\"MSEED\")\n",
    "        \"\"\"\n",
    "\n",
    "        import os\n",
    "        from obspy.core import UTCDateTime, Stream\n",
    "        from obspy.clients.filesystem.sds import Client\n",
    "\n",
    "        tbeg, tend = UTCDateTime(tbeg), UTCDateTime(tend)\n",
    "\n",
    "        if not os.path.exists(path_to_archive):\n",
    "            print(f\" -> {path_to_archive} does not exist!\")\n",
    "            return\n",
    "\n",
    "        ## separate seed id\n",
    "        net, sta, loc, cha = seed.split('.')\n",
    "\n",
    "        ## define SDS client\n",
    "        client = Client(path_to_archive, sds_type='D', format=data_format)\n",
    "\n",
    "        ## read waveforms\n",
    "        try:\n",
    "            st = client.get_waveforms(net, sta, loc, cha, tbeg, tend, merge=-1)\n",
    "        except:\n",
    "            print(f\" -> failed to obtain waveforms!\")\n",
    "            st = Stream()\n",
    "\n",
    "        return st\n",
    "\n",
    "    def load_data(self, t1, t2):\n",
    "        '''\n",
    "        Load data for translation and rotaion as obspy stream\n",
    "        '''\n",
    "\n",
    "        from obspy import Stream, UTCDateTime\n",
    "\n",
    "        st0 = Stream()\n",
    "\n",
    "        t1, t2 = UTCDateTime(t1), UTCDateTime(t2)\n",
    "        print(self.tra_sds, self.tra_seed)\n",
    "        try:\n",
    "            # read translational data\n",
    "            tra = sixdegrees.read_from_sds(self.tra_sds, self.tra_seed, t1-1, t2+1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" -> loading translation data failed!\")\n",
    "            if self.verbose:\n",
    "                print(e)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tra)\n",
    "\n",
    "        try:\n",
    "            tra = tra.detrend(\"linear\")\n",
    "\n",
    "            tra = tra.filter('highpass', freq=0.005, zerophase=True)\n",
    "\n",
    "            # remove response\n",
    "            tra = tra.remove_response(self.tra_inv, output=self.tra_output)\n",
    "\n",
    "            st0 += tra\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" -> removing response failed!\")\n",
    "            if self.verbose:\n",
    "                print(e)\n",
    "\n",
    "        try:\n",
    "            # read rotational data\n",
    "            rot = sixdegrees.read_from_sds(self.rot_sds, self.rot_seed, t1-1, t2+1)\n",
    "\n",
    "            st0 += rot\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" -> loading rotation data failed!\")\n",
    "            if self.verbose:\n",
    "                print(e)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(rot)\n",
    "\n",
    "        # check if stream has correct length\n",
    "        if len(st0) < 6:\n",
    "            print(f\" -> missing stream data\")\n",
    "\n",
    "       # check if merging is required\n",
    "        if len(st0) > 6:\n",
    "            st0 = st0.merge(method=1, fill_value=0)\n",
    "\n",
    "        # change seed id\n",
    "        for tr in st0:\n",
    "            tr.stats.network = self.net\n",
    "            tr.stats.station = self.sta\n",
    "            tr.stats.location = self.loc\n",
    "\n",
    "        # assign stream to object\n",
    "        self.st = st0\n",
    "\n",
    "    def trim_stream(self, set_common=True, set_interpolate=False):\n",
    "        '''\n",
    "        Trim a stream to common start and end times (and interpolate to common times)\n",
    "        '''\n",
    "\n",
    "        from numpy import interp, arange\n",
    "\n",
    "        def __get_size(st0):\n",
    "            return [tr.stats.npts for tr in st0]\n",
    "\n",
    "        # get size of traces\n",
    "        n_samples = __get_size(self.st)\n",
    "\n",
    "        # check if all traces have same amount of samples\n",
    "        if not all(x == n_samples[0] for x in n_samples):\n",
    "            print(f\" -> stream size inconsistent: {n_samples}\")\n",
    "\n",
    "            # if difference not larger than one -> adjust\n",
    "            if any([abs(x-n_samples[0]) > 1 for x in n_samples]):\n",
    "\n",
    "                # set to common minimum interval\n",
    "                if set_common:\n",
    "                    _tbeg = max([tr.stats.starttime for tr in self.st])\n",
    "                    _tend = min([tr.stats.endtime for tr in self.st])\n",
    "                    self.st = self.st.trim(_tbeg, _tend, nearest_sample=True)\n",
    "                    print(f\"  -> adjusted: {__get_size(self.st)}\")\n",
    "\n",
    "                    if set_interpolate:\n",
    "                        _times = arange(0, min(__get_size(self.st)), self.st[0].stats.delta)\n",
    "                        for tr in self.st:\n",
    "                            tr.data = interp(_times, tr.times(reftime=_tbeg), tr.data)\n",
    "            else:\n",
    "                # adjust for difference of one sample\n",
    "                for tr in self.st:\n",
    "                    tr.data = tr.data[:min(n_samples)]\n",
    "                print(f\"  -> adjusted: {__get_size(self.st)}\")\n",
    "\n",
    "    def get_time_intervals(self, tbeg=None, tend=None, interval_seconds=3600, interval_overlap=0):\n",
    "        '''\n",
    "        Obtain time intervals\n",
    "        '''\n",
    "\n",
    "        from obspy import UTCDateTime\n",
    "\n",
    "        if tbeg is None:\n",
    "            tbeg = self.tbeg\n",
    "        else:\n",
    "            tbeg = UTCDateTime(tbeg)\n",
    "\n",
    "        if tend is None:\n",
    "            tend = self.tend\n",
    "        else:\n",
    "            tend = UTCDateTime(tend)\n",
    "\n",
    "        times = []\n",
    "        t1, t2 = tbeg, tbeg + interval_seconds\n",
    "\n",
    "        while t2 <= tend:\n",
    "            times.append((t1, t2))\n",
    "            t1 = t1 + interval_seconds - interval_overlap\n",
    "            t2 = t2 + interval_seconds - interval_overlap\n",
    "\n",
    "        self.time_intervals = times\n",
    "        return times\n",
    "\n",
    "    def get_octave_bands(self, fmin=None, fmax=None, faction_of_octave=1, plot=False):\n",
    "        '''\n",
    "        Computing octave frequency bands\n",
    "\n",
    "        Arguments:\n",
    "            - fmin:    (float) minimum center frequency\n",
    "            - fmax:    (float) maximum center frequency\n",
    "            - fraction_of_octave:    (int) octave fraction (e.g. [1] = octaves, 3 = third octaves, 12 = 12th octaves)\n",
    "            - plot:    (bool) show frequency bands\n",
    "\n",
    "        Example:\n",
    "\n",
    "        >>> flower, fupper, fcenter = __get_octave_bands(f_min, f_max, fband_type=\"octave\", plot=False)\n",
    "        '''\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        from acoustics.octave import Octave\n",
    "        from numpy import array\n",
    "\n",
    "        if fmin is None:\n",
    "            fmin = self.fmin\n",
    "        if fmax is None:\n",
    "            fmax = self.fmax\n",
    "\n",
    "        # avoid fmin = zero\n",
    "        if fmin == 0:\n",
    "            print(f\" -> set fmin to 1e-10\")\n",
    "            fmin = 1e-10\n",
    "\n",
    "        f_lower, f_upper, f_center = [], [], []\n",
    "\n",
    "        # compute f-bands\n",
    "        _octaves = Octave(fraction=faction_of_octave,\n",
    "                          interval=None,\n",
    "                          fmin=fmin,\n",
    "                          fmax=fmax,\n",
    "                          unique=False,\n",
    "                          reference=1000.0\n",
    "                         )\n",
    "\n",
    "        # store for object\n",
    "        self.f_center = array(_octaves.center)\n",
    "        self.f_lower = array(_octaves.lower)\n",
    "        self.f_upper = array(_octaves.upper)\n",
    "\n",
    "        # checkup plot\n",
    "        if plot:\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            for fl, fc, fu in zip(self.f_lower, self.f_center, self.f_upper):\n",
    "                plt.axvline(fu, color=\"r\")\n",
    "                plt.axvline(fl, color=\"r\")\n",
    "                plt.axvline(fc, ls=\"--\")\n",
    "                plt.axvline(fmin, color=\"g\")\n",
    "                plt.axvline(fmax, color=\"g\")\n",
    "                plt.xscale(\"log\")\n",
    "            plt.show();\n",
    "\n",
    "        return self.f_lower, self.f_upper, self.f_center\n",
    "\n",
    "    def interpolate_nan(array_like):\n",
    "        '''\n",
    "        interpolate NaN values in array linearly\n",
    "        '''\n",
    "\n",
    "        from numpy import isnan, interp\n",
    "\n",
    "        array = array_like.copy()\n",
    "\n",
    "        nans = isnan(array)\n",
    "\n",
    "        def get_x(a):\n",
    "            return a.nonzero()[0]\n",
    "\n",
    "        array[nans] = interp(get_x(nans), get_x(~nans), array[~nans])\n",
    "\n",
    "        return array\n",
    "\n",
    "    def store_as_pickle(self, obj, name):\n",
    "\n",
    "        import os, pickle\n",
    "\n",
    "        ofile = open(name+\".pkl\", 'wb')\n",
    "        pickle.dump(obj, ofile)\n",
    "\n",
    "        if os.path.isfile(name+\".pkl\"):\n",
    "            print(f\" -> stored: {name}.pkl\")\n",
    "\n",
    "    def get_event_info(self, station_lat=None, station_lon=None, event_time=None, time_offset=20, fdsn_client=\"USGS\"):\n",
    "        '''\n",
    "        Extract information of event from catalog\n",
    "        '''\n",
    "\n",
    "        from obspy.clients.fdsn import Client\n",
    "        from obspy.geodetics.base import gps2dist_azimuth\n",
    "\n",
    "        # get event if not provided\n",
    "        if event_time is None:\n",
    "            print(\" -> provide event_time !!!\")\n",
    "            return\n",
    "        else:\n",
    "            events = Client(fdsn_client).get_events(starttime=event_time-time_offset, endtime=event_time+time_offset)\n",
    "            if len(events) > 1:\n",
    "                print(f\" -> {len(events)} events found!!!\")\n",
    "                print(events)\n",
    "                return\n",
    "\n",
    "            elif len(events) > 0:\n",
    "                event = events[0]\n",
    "                print(f\" ->  no event found!!!\")\n",
    "                return\n",
    "\n",
    "        # event location from event info\n",
    "        self.source_latitude = event.origins[0].latitude\n",
    "        self.source_longitude = event.origins[0].longitude\n",
    "\n",
    "        # compute paremeters\n",
    "        if None in [station_lat, station_lon]:\n",
    "            dist, az, baz = gps2dist_azimuth(\n",
    "                                             self.source_latitude, self.source_longitude,\n",
    "                                             self.station_latitude, self.station_lonitude,\n",
    "                                            )\n",
    "        else:\n",
    "            dist, az, baz = gps2dist_azimuth(\n",
    "                                             self.source_latitude, self.source_longitude,\n",
    "                                             station_lat, station_lon,\n",
    "                                            )\n",
    "\n",
    "        self.baz_catalog = baz\n",
    "        self.az_catalog = az\n",
    "        self.epicentral_distance = dist\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\" -> Epicentral distance [m]:       {round(self.epicentral_distance, 1)}\")\n",
    "            print(f\" -> Theoretical azimuth [deg]:     {round(self.az_catalogbaz, 1)}\")\n",
    "            print(f\" -> Theoretical backazimuth [deg]: {round(self.baz_catalogbaz, 1)}\")\n",
    "\n",
    "    def compute_backazimuth(self, wave_type=\"love\", fmin=None, fmax=None, out=False):\n",
    "\n",
    "        '''\n",
    "        This method estimates a backazimuth for either\n",
    "         - Love waves (vertical rotation rate and transverse acceleration) or\n",
    "         - Rayleigh waves (vertical acceleration and transverse rotation rate)\n",
    "        and compares it to a theoretical backazimuth computed from the source and receiver location.\n",
    "\n",
    "        RETURN:\n",
    "        - out:  dictionary with output data. Keywords:\n",
    "                'baz_mesh', 'baz_corr', 'baz_theo', 'acc_transverse', 'acc_radial', 'rot_vertical', 'event'\n",
    "\n",
    "        >>> out = __compute_backazimuth(st_acc, st_rot, config, wave_type=\"love\", event=None, plot=True, show_details=False)\n",
    "\n",
    "        '''\n",
    "\n",
    "        from numpy import ones, arange, linspace, asarray, array, meshgrid, nan, shape\n",
    "        from numpy import arctan, pi, linspace, cov, argsort, corrcoef, correlate, zeros\n",
    "        from numpy.linalg import eigh\n",
    "        from obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "        from obspy.signal.rotate import rotate_ne_rt\n",
    "\n",
    "        # _______________________________\n",
    "        # check config keywords\n",
    "        keywords = ['tbeg', 'tend', 'sampling_rate',\n",
    "                    'station_latitude', 'station_longitude',\n",
    "                    'baz_step', 'baz_win_sec', 'baz_win_sec_overlap']\n",
    "\n",
    "        for key in keywords:\n",
    "            if key not in sixdegrees.attributes(self):\n",
    "                print(f\" -> {key} is missing in config!\\n\")\n",
    "                return\n",
    "\n",
    "        # _______________________________\n",
    "        # prepare streams\n",
    "        ACC = sixdegrees.get_translation(self).copy()\n",
    "        ROT = sixdegrees.get_rotation(self).copy()\n",
    "\n",
    "        # get amount of samples for data\n",
    "        n_samples = len(ROT.select(channel=\"*Z\")[0])\n",
    "\n",
    "        # adjust overlaps\n",
    "        overlap = self.baz_win_sec_overlap / self.baz_win_sec\n",
    "\n",
    "        # prepare time windows for loop\n",
    "        n_windows = n_samples // (int(self.sampling_rate * self.baz_win_sec))\n",
    "\n",
    "        # prepare backazimuths for loop\n",
    "        backazimuths = linspace(0, 360 - self.baz_step, int(360 / self.baz_step))\n",
    "\n",
    "        # prepare data array\n",
    "        corrbaz = ones([backazimuths.size, n_windows])*nan\n",
    "\n",
    "        degrees = []\n",
    "        windows = []\n",
    "\n",
    "        bazs = ones(n_windows)*nan\n",
    "\n",
    "        # _______________________________\n",
    "        # backazimuth estimation with Love or Rayleigh waves\n",
    "        # loop over backazimuth degrees\n",
    "        for i_deg in range(0, len(backazimuths)):\n",
    "\n",
    "            degrees.append(i_deg)\n",
    "\n",
    "            # loop over time windows\n",
    "            for i_win in range(0, n_windows):\n",
    "\n",
    "                if i_deg == 0:\n",
    "                    windows.append(i_win)\n",
    "\n",
    "                # infer indices\n",
    "                idx1 = int(self.sampling_rate * self.baz_win_sec * i_win)\n",
    "                idx2 = int(self.sampling_rate * self.baz_win_sec * (i_win + 1))\n",
    "\n",
    "                # add overlap\n",
    "                if i_win > 0 and i_win < n_windows:\n",
    "                    idx1 = int(idx1 - overlap * self.baz_win_sec * self.sampling_rate)\n",
    "                    idx2 = int(idx2 + overlap * self.baz_win_sec * self.sampling_rate)\n",
    "\n",
    "                # prepare traces according to selected wave type\n",
    "                if wave_type.lower() == \"love\":\n",
    "\n",
    "                    if self.verbose and i_deg == 0 and i_win == 0:\n",
    "                        print(f\"\\n -> using {wave_type} waves for BAz estimation ...\")\n",
    "\n",
    "                    # rotate NE to RT\n",
    "                    R, T = rotate_ne_rt(ACC.select(channel='*N')[0].data,\n",
    "                                        ACC.select(channel='*E')[0].data,\n",
    "                                        backazimuths[i_deg]\n",
    "                                       )\n",
    "\n",
    "                    # compute correlation for backazimuth\n",
    "                    ccorr = correlate(ROT.select(channel=\"*Z\")[0][idx1:idx2],\n",
    "                                      T[idx1:idx2],\n",
    "                                      0, demean=True, normalize='naive', method='fft'\n",
    "                                     )\n",
    "\n",
    "                    # get maximum correlation\n",
    "                    xshift, cc_max = xcorr_max(ccorr)\n",
    "\n",
    "                    if xshift != 0:\n",
    "                        print(f\" -> maximal cc not a shift=0: shift={xshift} | cc={cc_max}\")\n",
    "\n",
    "                elif wave_type.lower() == \"rayleigh\":\n",
    "\n",
    "                    if self.verbose and i_deg == 0 and i_win == 0:\n",
    "                        print(f\"\\n -> using {wave_type} waves for BAz estimation ...\")\n",
    "\n",
    "                    # rotate NE to RT\n",
    "                    R, T = rotate_ne_rt(ROT.select(channel='*N')[0].data,\n",
    "                                        ROT.select(channel='*E')[0].data,\n",
    "                                        backazimuths[i_deg]\n",
    "                                       )\n",
    "\n",
    "                    # compute correlation for backazimuth\n",
    "                    ccorr = correlate(ACC.select(channel=\"*Z\")[0][idx1:idx2],\n",
    "                                      T[idx1:idx2],\n",
    "                                      0, demean=True, normalize='naive', method='fft'\n",
    "                                     )\n",
    "\n",
    "                    # get maximum correlation\n",
    "                    xshift, cc_max = xcorr_max(ccorr)\n",
    "\n",
    "                    if xshift != 0:\n",
    "                        print(f\" -> maximal cc not a shift=0: shift={xshift} | cc={cc_max}\")\n",
    "\n",
    "                elif wave_type.lower() == \"tangent\":\n",
    "\n",
    "                    # no grid search, no degrees loop required\n",
    "                    if i_deg > 0:\n",
    "                        continue\n",
    "\n",
    "                    # prepare data\n",
    "                    dat = (zeros((len(rot_n[idx1:idx2]), 2)))\n",
    "                    dat[:, 0] = ROT.select(channel='*E')[0].data[idx1:idx2]\n",
    "                    dat[:, 1] = ROT.select(channel='*N')[0].data[idx1:idx2]\n",
    "\n",
    "                    # compute covariance\n",
    "                    covar = cov(dat, rowvar=False)\n",
    "\n",
    "                    # get dominant eigenvector\n",
    "                    Cprime, Q = eigh(covar, UPLO='U')\n",
    "\n",
    "                    # sorting\n",
    "                    loc = argsort(abs(Cprime))[::-1]\n",
    "\n",
    "                    # formating\n",
    "                    Q = Q[:, loc]\n",
    "\n",
    "                    # get backazimuth using tangent of eigenvectors\n",
    "                    baz0 = -arctan((Q[1, 0]/Q[0, 0]))*180/pi\n",
    "\n",
    "                    # if negative due to tangent .. add 180 degrees\n",
    "                    if baz0 <= 0:\n",
    "                        baz0 += 180\n",
    "\n",
    "                    # remove 180° ambiguity\n",
    "                    R, T = rotate_ne_rt(ROT.select(channel='*N')[0].data,\n",
    "                                        ROT.select(channel='*E')[0].data,\n",
    "                                        baz0\n",
    "                                       )\n",
    "\n",
    "                    # correlatet with acceleration\n",
    "                    ccorr = correlate(ACC.select(channel=\"*Z\")[0][idx1:idx2],\n",
    "                                      T[idx1:idx2],\n",
    "                                      0, demean=True, normalize='naive', method='fft'\n",
    "                                     )\n",
    "\n",
    "                    # get maximum correlation\n",
    "                    xshift, cc_max = xcorr_max(ccorr)\n",
    "\n",
    "                    # if correlation positive add 180 degrees\n",
    "                    if (cc_max > 0):\n",
    "                        baz0 += 180\n",
    "\n",
    "                    cc_max = abs(cc_max)\n",
    "\n",
    "                    # ## add new values to array\n",
    "                    # if abs(cc_max) > cc_thres:\n",
    "                    #     baz[j] = baz0\n",
    "                    #     ccor[j] = abs(corr_baz)\n",
    "\n",
    "                else:\n",
    "                    print(f\" -> unknown wave type: {wave_type}!\")\n",
    "\n",
    "                corrbaz[i_deg, i_win] = cc_max\n",
    "\n",
    "                if wave_type.lower() == \"tangent\":\n",
    "                    bazs[i_win] = baz0\n",
    "\n",
    "        # extract maxima\n",
    "        if wave_type.lower() == \"tangent\":\n",
    "            maxbaz = bazs\n",
    "            maxcorr = corrbaz[0, :]\n",
    "        else:\n",
    "            maxbaz = array([backazimuths[corrbaz[:, l1].argmax()] for l1 in range(0, n_windows)])\n",
    "            maxcorr = array([max(corrbaz[:, l1]) for l1 in range(0, n_windows)])\n",
    "\n",
    "        # create mesh grid\n",
    "        t_win = arange(0, self.baz_win_sec*n_windows+self.baz_win_sec, self.baz_win_sec)\n",
    "        t_win_center = t_win[:-1]+self.baz_win_sec/2\n",
    "        grid = meshgrid(t_win, backazimuths)\n",
    "\n",
    "        # add one element for axes\n",
    "        windows.append(windows[-1]+1)\n",
    "        degrees.append(degrees[-1]+self.baz_step)\n",
    "\n",
    "        # add results to object\n",
    "        if wave_type.lower() == \"love\":\n",
    "            self.baz_grid_love = corrbaz\n",
    "            self.baz_degrees_love = degrees\n",
    "            self.baz_windows_love = windows\n",
    "            self.baz_corr_love = maxcorr\n",
    "            self.baz_max_love = maxbaz\n",
    "            self.baz_times_love = t_win_center\n",
    "\n",
    "        elif wave_type.lower() == \"rayleigh\":\n",
    "            self.baz_grid_rayleigh = corrbaz\n",
    "            self.baz_degrees_rayleigh = degrees\n",
    "            self.baz_windows_ralyeigh = windows\n",
    "            self.baz_corr_rayleigh = maxcorr\n",
    "            self.baz_max_rayleigh = maxbaz\n",
    "            self.baz_times_rayleigh = t_win_center\n",
    "\n",
    "        elif wave_type.lower() == \"tangent\":\n",
    "            self.baz_grid_tangent = corrbaz\n",
    "            self.baz_degrees_tangent = degrees\n",
    "            self.baz_windows_tangent = windows\n",
    "            self.baz_corr_tangent = maxcorr\n",
    "            self.baz_max_tangent = maxbaz\n",
    "            self.baz_times_tangent = t_win_center\n",
    "\n",
    "        if out:\n",
    "            # _______________________________\n",
    "            # prepare output\n",
    "            output = {}\n",
    "\n",
    "            output['baz_mesh'] = grid\n",
    "            output['baz_corr'] = corrbaz\n",
    "            output['acc'] = ACC\n",
    "            output['rot'] = ROT\n",
    "            output['cc_max_t'] = t_win_center\n",
    "            output['cc_max_y'] = maxbaz\n",
    "            output['cc_max'] = maxcorr\n",
    "\n",
    "            return output\n",
    "\n",
    "    @staticmethod\n",
    "    def get_fft(arr, dt, window=None):\n",
    "\n",
    "        '''\n",
    "        Calculating a simple 1D FastFourierSpectrum of a time series.\n",
    "\n",
    "        >>> frequencies, spectrum, phase = __fft(signal_in, dt ,window=None,normalize=None)\n",
    "        '''\n",
    "\n",
    "        from scipy.fft import fft, fftfreq, fftshift\n",
    "        from scipy import signal\n",
    "        from numpy import angle, imag\n",
    "\n",
    "        # determine length of the input time series\n",
    "        n = int(len(arr))\n",
    "\n",
    "        # calculate spectrum (with or without window function applied to time series)\n",
    "        if window is not None:\n",
    "            win = signal.get_window(window, n);\n",
    "            spectrum = fft(arr * win)\n",
    "        else:\n",
    "            spectrum = fft(arr)\n",
    "\n",
    "        # calculate frequency array\n",
    "        frequencies = fftfreq(n, d=dt)\n",
    "\n",
    "        # calculate amplitude spectrum\n",
    "        magnitude = abs(spectrum) * 2.0 / n\n",
    "\n",
    "        # calculate phase spectrum\n",
    "        phase = angle(spectrum, deg=False)\n",
    "\n",
    "        return frequencies[0:n//2], magnitude[0:n//2], phase[0:n//2]\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_waveform_cc(rot0, acc0, baz, fmin, fmax, distance=None, twin_sec=5, twin_overlap=0.5):\n",
    "\n",
    "        from obspy.signal.cross_correlation import correlate\n",
    "        from obspy.signal.rotate import rotate_ne_rt\n",
    "        from numpy import linspace, ones\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        def __cross_correlation_windows(arr1, arr2, dt, Twin, overlap=0, lag=0, demean=True, plot=False):\n",
    "\n",
    "            from obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "            from numpy import arange, array, roll\n",
    "\n",
    "            N = len(arr1)\n",
    "            n_interval = int(Twin/dt)\n",
    "            n_overlap = int(overlap*Twin/dt)\n",
    "\n",
    "            # time = arange(0, N*dt, dt)\n",
    "\n",
    "            times, samples = [], []\n",
    "            n1, n2 = 0, n_interval\n",
    "            while n2 <= N:\n",
    "                samples.append((n1, n2))\n",
    "                times.append(int(n1+(n2-n1)/2)*dt)\n",
    "                n1 = n1 + n_interval - n_overlap\n",
    "                n2 = n2 + n_interval - n_overlap\n",
    "\n",
    "            cc = []\n",
    "            for _n, (n1, n2) in enumerate(samples):\n",
    "\n",
    "                _arr1 = roll(arr1[n1:n2], lag)\n",
    "                _arr2 = arr2[n1:n2]\n",
    "                ccf = correlate(_arr1, _arr2, 0, demean=demean, normalize='naive', method='fft')\n",
    "                shift, val = xcorr_max(ccf, abs_max=False)\n",
    "                cc.append(val)\n",
    "\n",
    "            return array(times), array(cc)\n",
    "\n",
    "\n",
    "        rot = rot0.copy()\n",
    "        acc = acc0.copy()\n",
    "\n",
    "        Nrow, Ncol = 3, 1\n",
    "\n",
    "        fig, ax = plt.subplots(Nrow, Ncol, figsize=(15, 6), sharex=True)\n",
    "\n",
    "        acc_scaling, acc_unit = 1e3, f\"mm/s$^2$\"\n",
    "        rot_scaling, rot_unit = 1e6, f\"$\\mu$rad/s\"\n",
    "\n",
    "        lw = 1\n",
    "\n",
    "        font = 12\n",
    "\n",
    "        acc_z = acc.select(channel=\"*Z\")[0].data\n",
    "        rot_z = rot.select(channel=\"*Z\")[0].data\n",
    "\n",
    "        acc_r, acc_t = rotate_ne_rt(acc.select(channel=\"*N\")[0].data, acc.select(channel=\"*E\")[0].data, baz)\n",
    "        rot_r, rot_t = rotate_ne_rt(rot.select(channel=\"*N\")[0].data, rot.select(channel=\"*E\")[0].data, baz)\n",
    "\n",
    "        rot_z*=rot_scaling\n",
    "        rot_r*=rot_scaling\n",
    "        rot_t*=rot_scaling\n",
    "\n",
    "        acc_z*=acc_scaling\n",
    "        acc_r*=acc_scaling\n",
    "        acc_t*=acc_scaling\n",
    "\n",
    "        acc_z_max = max([abs(min(acc_z)), abs(max(acc_z))])\n",
    "        acc_r_max = max([abs(min(acc_r)), abs(max(acc_r))])\n",
    "        acc_t_max = max([abs(min(acc_t)), abs(max(acc_t))])\n",
    "\n",
    "        rot_z_max = max([abs(min(rot_z)), abs(max(rot_z))])\n",
    "        rot_r_max = max([abs(min(rot_r)), abs(max(rot_r))])\n",
    "        rot_t_max = max([abs(min(rot_t)), abs(max(rot_t))])\n",
    "\n",
    "        dt = rot[0].stats.delta\n",
    "\n",
    "        rot0 ,acc0, rot0_lbl, acc0_lbl = rot_z, acc_t, \"ROT-Z\", \"ACC-T\"\n",
    "        rot1 ,acc1, rot1_lbl, acc1_lbl = rot_t, acc_z, \"ROT_T\", \"ACC-Z\"\n",
    "        rot2 ,acc2, rot2_lbl, acc2_lbl = rot_z, -acc_r, \"ROT-Z\", \"-1xACC-R\"\n",
    "\n",
    "        tt0, cc0 = __cross_correlation_windows(rot0 ,acc0, dt, twin_sec, overlap=twin_overlap, lag=0, demean=True)\n",
    "        tt1, cc1 = __cross_correlation_windows(rot1, acc1, dt, twin_sec, overlap=twin_overlap, lag=0, demean=True)\n",
    "        tt2, cc2 = __cross_correlation_windows(rot2, acc2, dt, twin_sec, overlap=twin_overlap, lag=0, demean=True)\n",
    "\n",
    "        cmap = plt.get_cmap(\"coolwarm\", 12)\n",
    "\n",
    "\n",
    "        ax[0].plot(rot.select(channel=\"*Z\")[0].times(), rot0, label=rot0_lbl, color=\"tab:red\", lw=lw, zorder=3)\n",
    "        ax00 = ax[0].twinx()\n",
    "        ax00.plot(acc.select(channel=\"*Z\")[0].times(), acc0, label=acc0_lbl, color=\"black\", lw=lw)\n",
    "        ax01 = ax[0].twinx()\n",
    "        cm = ax01.scatter(tt0, ones(len(tt0))*-0.9, c=cc0, alpha=abs(cc0), cmap=cmap, label=\"\")\n",
    "\n",
    "        ax[0].set_ylim(-rot_z_max, rot_z_max)\n",
    "        ax00.set_ylim(-acc_t_max, acc_t_max)\n",
    "        ax01.set_ylim(-1, 1)\n",
    "        ax01.yaxis.set_visible(False)\n",
    "\n",
    "        ax[1].plot(rot.select(channel=\"*N\")[0].times(), rot1, label=rot1_lbl, color=\"tab:red\", lw=lw, zorder=3)\n",
    "        ax11 = ax[1].twinx()\n",
    "        ax11.plot(acc.select(channel=\"*Z\")[0].times(), acc1, label=acc1_lbl, color=\"black\", lw=lw)\n",
    "        ax12 = ax[1].twinx()\n",
    "        ax12.scatter(tt1, ones(len(tt1))*-0.9, c=cc1, alpha=abs(cc1), cmap=cmap, label=\"\")\n",
    "\n",
    "        ax[1].set_ylim(-rot_t_max, rot_t_max)\n",
    "        ax11.set_ylim(-acc_z_max, acc_z_max)\n",
    "        ax12.set_ylim(-1, 1)\n",
    "        ax12.yaxis.set_visible(False)\n",
    "\n",
    "        ax[2].plot(rot.select(channel=\"*N\")[0].times(), rot2, label=rot2_lbl, color=\"tab:red\", lw=lw, zorder=3)\n",
    "        ax22 = ax[2].twinx()\n",
    "        ax22.plot(acc.select(channel=\"*Z\")[0].times(), acc2, label=acc2_lbl, color=\"black\", lw=lw)\n",
    "        ax23 = ax[2].twinx()\n",
    "        ax23.scatter(tt2, ones(len(tt2))*-0.9, c=cc2, alpha=abs(cc2), cmap=cmap, label=\"\")\n",
    "\n",
    "        ax[2].set_ylim(-rot_z_max, rot_z_max)\n",
    "        ax22.set_ylim(-acc_r_max, acc_r_max)\n",
    "        ax23.set_ylim(-1, 1)\n",
    "        ax23.yaxis.set_visible(False)\n",
    "\n",
    "        cc0 = round(correlate(rot0, acc0, 0, demean=True, normalize='naive', method='auto')[0], 2)\n",
    "        cc1 = round(correlate(rot1, acc1, 0, demean=True, normalize='naive', method='auto')[0], 2)\n",
    "        cc2 = round(correlate(rot2, acc2, 0, demean=True, normalize='naive', method='auto')[0], 2)\n",
    "        cc = [cc0, cc1, cc2]\n",
    "\n",
    "        ## sync twinx\n",
    "        ax[0].set_yticks(linspace(ax[0].get_yticks()[0], ax[0].get_yticks()[-1], len(ax[0].get_yticks())))\n",
    "        ax00.set_yticks(linspace(ax00.get_yticks()[0], ax00.get_yticks()[-1], len(ax[0].get_yticks())))\n",
    "\n",
    "        ax[1].set_yticks(linspace(ax[1].get_yticks()[0], ax[1].get_yticks()[-1], len(ax[1].get_yticks())))\n",
    "        ax11.set_yticks(linspace(ax11.get_yticks()[0], ax11.get_yticks()[-1], len(ax[1].get_yticks())))\n",
    "\n",
    "        ax[2].set_yticks(linspace(ax[2].get_yticks()[0], ax[2].get_yticks()[-1], len(ax[2].get_yticks())))\n",
    "        ax22.set_yticks(linspace(ax22.get_yticks()[0], ax22.get_yticks()[-1], len(ax[2].get_yticks())))\n",
    "\n",
    "        for i in range(3):\n",
    "            ax[i].legend(loc=1, ncols=4)\n",
    "            ax[i].grid(which=\"both\", alpha=0.5)\n",
    "            ax[i].set_ylabel(f\"$\\Omega$ ({rot_unit})\", fontsize=font)\n",
    "            ax[i].text(0.05, 0.9, f\"CC={cc[i]}\", ha='left', va='top', transform=ax[i].transAxes, fontsize=font-1)\n",
    "\n",
    "        for _ax in [ax00, ax11, ax22]:\n",
    "            _ax.legend(loc=4)\n",
    "            _ax.set_ylabel(f\"$a$ ({acc_unit})\", fontsize=font)\n",
    "\n",
    "        ax[2].set_xlabel(\"Time (s)\", fontsize=font)\n",
    "\n",
    "        tbeg = acc[0].stats.starttime\n",
    "        ax[0].set_title(f\"{tbeg.date} {str(tbeg.time).split('.')[0]} UTC  |  f = {fmin}-{fmax} Hz  |  BAz = {round(baz, 1)}°  |  ED = {round(distance/1000,1)} km  |  T = {twin_sec}s ({int(100*twin_overlap)}%)\")\n",
    "\n",
    "        cax = ax[Nrow-1].inset_axes([0.8, -0.35, 0.2, 0.1], transform=ax[Nrow-1].transAxes)\n",
    "        cb = plt.colorbar(cm, cax=cax, shrink=0.4, location='bottom', orientation='horizontal')\n",
    "        cm.set_clim(-1, 1)\n",
    "        cb.set_label(\"Cross-Correlation\", fontsize=font, loc=\"left\", labelpad=-43, color=\"black\", backgroundcolor=\"w\")\n",
    "\n",
    "        plt.show();\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c902111d-677b-49fa-8809-fd7df0d03691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "\n",
    "config = {}\n",
    "\n",
    "config['project'] = \"rolode/\"\n",
    "\n",
    "config['verbose'] = True\n",
    "\n",
    "config['tbeg'] = UTCDateTime(\"2024-09-09T00:00:00\")\n",
    "config['tend'] = UTCDateTime(\"2024-09-09T01:00:00\")\n",
    "\n",
    "config['tra_seed'] = 'GR.FUR..BH*' # seed of translational data\n",
    "config['rot_seed'] = 'BW.ROMY.30.BJ*' # seed of rotational data\n",
    "\n",
    "config['station_lon'] = 11.275501\n",
    "config['station_lat'] = 48.162941\n",
    "\n",
    "# specify response information file\n",
    "config['path_to_inv_tra'] = data_path+'stationxml_ringlaser/station_GR_FUR.xml' #seismometer\n",
    "config['path_to_inv_rot'] = data_path+'stationxml_ringlaser/station_BW_ROMY.xml' #blueSeis\n",
    "\n",
    "config['path_to_sds_rot'] = archive_path+\"temp_archive/\"\n",
    "config['path_to_sds_tra'] = bay_path+\"mseed_online/archive/\"\n",
    "\n",
    "test = sixdegrees(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134aa94-a571-47af-8ded-929668d3e8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andbro/ontap-ffb-bay200/mseed_online/archive/ GR.FUR..BH*\n"
     ]
    }
   ],
   "source": [
    "test.load_data(t1=config['tbeg'], t2=config['tend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf3558-883b-4848-ad09-c03e61a9c25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.trim_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd58ce-0d4b-438c-ba08-9410cc6336c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84337943-6cab-4e87-84a2-6776e939c28b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.fmin = 0.1\n",
    "test.fmax = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75336498-deb0-4f47-84a1-46be93bae948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.plot_waveform_cc(test.get_rotation(),\n",
    "                      test.get_translation(),\n",
    "                      300,\n",
    "                      test.fmin, test.fmax,\n",
    "                      distance=0,\n",
    "                      twin_sec=30,\n",
    "                      twin_overlap=0.5\n",
    "                     );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996822db-6f36-4dd6-be02-9072bcf76b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords = ['tbeg', 'tend', 'sampling_rate',\n",
    "            'station_latitude', 'station_longitude',\n",
    "            'baz_step', 'baz_win_sec', 'baz_win_sec_overlap']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1109794-cdde-4baf-b666-3ab1ca742edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.sampling_rate = 20\n",
    "test.baz_step = 1\n",
    "test.baz_win_sec = 30\n",
    "test.baz_win_sec_overlap = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cdad4-54c1-4f36-b715-5abc2403b69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.compute_backazimuth(wave_type=\"rayleigh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c5381-2284-42d2-9dab-91828707484c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.compute_backazimuth(wave_type=\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b849a1-f5c8-4646-bcd9-2a5751c6c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.compute_backazimuth(wave_type=\"tangent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd90c22-6115-40ea-be3f-a74044af6591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(test.baz_times_love, test.baz_max_love)\n",
    "plt.scatter(test.baz_times_rayleigh, test.baz_max_rayleigh)\n",
    "plt.scatter(test.baz_times_tangent, test.baz_max_tangent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1bb15-41e1-4e7a-8790-a338dcd99c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.pcolormesh(test.baz_windows_love, test.baz_degrees_love, test.baz_grid_love)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb2d5e-9a3a-4723-a9cf-4d932801143a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617486a-9689-4a1e-97bd-4a97c66f251b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
