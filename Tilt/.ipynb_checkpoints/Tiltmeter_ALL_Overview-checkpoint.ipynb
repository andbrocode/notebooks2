{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extensive-movement",
   "metadata": {},
   "source": [
    "## Tiltmeter ALL Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-resort",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T15:09:20.288504Z",
     "start_time": "2021-02-19T15:09:20.284413Z"
    }
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "animal-despite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:14.047049Z",
     "start_time": "2023-01-16T16:30:11.464372Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import obspy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import arange, linspace, sqrt, diff, nan, gradient, nanmax\n",
    "from pandas import read_csv, DataFrame\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from numpy.ma import filled, isMaskedArray, masked\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from obspy import UTCDateTime\n",
    "from pathlib import Path\n",
    "\n",
    "from andbro__querrySeismoData import __querrySeismoData\n",
    "from andbro__get_seconds import __get_seconds\n",
    "from andbro__readYaml import __readYaml\n",
    "from andbro__get_timeaxis import __get_timeaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de643ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:14.050309Z",
     "start_time": "2023-01-16T16:30:14.048049Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == \"lighthouse\":\n",
    "    root_path = \"/home/andbro/\"\n",
    "    data_path = \"/home/andbro/kilauea-data/\"\n",
    "    archive_path = \"/home/andbro/freenas/\"\n",
    "elif os.uname().nodename == \"kilauea\":\n",
    "    root_path = \"/home/brotzer/\"\n",
    "    data_path = \"/import/kilauea-data/\"\n",
    "    archive_path = \"/import/freenas-ffb-01-data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-throat",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de01887f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:14.067764Z",
     "start_time": "2023-01-16T16:30:14.051831Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __makeplot(pt, bt, config):\n",
    "    \n",
    "    fig, axes = plt.subplots(3,2, figsize=(15,5), sharex=True)\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        axes[i,0].plot(pt[i].times()/60, pt[i].data)\n",
    "        axes[i,1].plot(bt[i].times()/60, bt[i].data)\n",
    "        \n",
    "        axes[i,0].grid()\n",
    "        axes[i,1].grid()\n",
    "        \n",
    "    axes[2,0].set_xlabel(\"Time (min)\")\n",
    "    axes[2,1].set_xlabel(\"Time (min)\")\n",
    "    \n",
    "    axes[0,0].set_ylabel(\"$\\Omega$ (rad)\")\n",
    "    axes[1,0].set_ylabel(\"$\\Omega$ (rad)\")\n",
    "    axes[2,0].set_ylabel(\"Temp (째C)\")\n",
    "    \n",
    "    axes[0,1].set_ylabel(\"$\\Omega$ (rad)\")\n",
    "    axes[1,1].set_ylabel(\"$\\Omega$ (rad)\")\n",
    "    axes[2,1].set_ylabel(\"Temp (째C)\")\n",
    "    \n",
    "    return fig "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-hacker",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "superior-memorial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:14.130686Z",
     "start_time": "2023-01-16T16:30:14.068983Z"
    }
   },
   "outputs": [],
   "source": [
    "## configurations\n",
    "config={}\n",
    "\n",
    "path = \"/home/andbro/Desktop/tiltmeter/\"\n",
    "# path2 = '/home/andbro/Desktop/tiltmeter/WETTER/*ex'\n",
    "\n",
    "config['save'] = False\n",
    "\n",
    "config['tbeg'] = UTCDateTime(\"2022-12-20 00:00\")\n",
    "config['tend'] = UTCDateTime(\"2023-01-15 00:00\")\n",
    "\n",
    "\n",
    "# config['seed_id'] = [\"BW.TROMY..MA*\", \"BW.ROMYT..MA*\", \"BW.DROMY..LA*\"]\n",
    "\n",
    "config['repository'] = 'george'\n",
    "config['datapath'] =  None\n",
    "\n",
    "config['name'] = 'tiltmeter'\n",
    "config['set_filter'] = 'n'\n",
    "\n",
    "## specify path to SDS data archive\n",
    "config['path_to_data'] = \"/import/freenas-ffb-01-data/romy_archive/\"\n",
    "\n",
    "## specify path to wromy data\n",
    "# config['path_to_wromy'] = f\"{data_path}wromy/\"\n",
    "config['path_to_wromy'] = f\"{archive_path}romy_archive/2022/BW/WROMY/\"\n",
    "\n",
    "## tiltmeter configurations\n",
    "confTilt = __readYaml(f\"{root_path}Documents/ROMY/tiltmeter/\",\"tiltmeter.conf\")\n",
    "\n",
    "## correction of offset (e.g. reset mass)\n",
    "offset_correction = __readYaml(f\"{root_path}Documents/ROMY/tiltmeter/\", \"tiltmeter_steps.yml\")\n",
    "\n",
    "## correction for temperature trends\n",
    "## based on MAT\n",
    "temperature_correction = __readYaml(f\"{root_path}Documents/ROMY/tiltmeter/\",\"tiltmeter_temperature_correction.yml\")\n",
    "## based on WSX\n",
    "# temperature_correction = __readYaml(f\"{root_path}Documents/ROMY/tiltmeter/\",\"temperature_correction_new.yml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60789a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:29:32.010154Z",
     "start_time": "2023-01-16T16:29:32.001448Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __plot_all_tilt(st1, st2, st3):\n",
    "\n",
    "    from datetime import datetime\n",
    "    \n",
    "    NN=3\n",
    "    \n",
    "    fig, ax = plt.subplots(NN,1, figsize=(15,8), sharex=True)\n",
    "\n",
    "    font = 14\n",
    "    \n",
    "    tilt_scaling, tilt_unit = 1e-6, r\"$\\mu$rad\"\n",
    "    time_scaling, time_unit = 86400, \"days\"\n",
    "    \n",
    "    ax[0].plot(st1.select(channel=\"*N\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st1.select(channel=\"*N\")[0].data/tilt_scaling, label=\"TROMY\")\n",
    "    ax[0].plot(st2.select(channel=\"*N\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st2.select(channel=\"*N\")[0].data/tilt_scaling, label=\"ROMYT\")\n",
    "    ax[0].plot(st3.select(channel=\"*N\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st3.select(channel=\"*N\")[0].data/tilt_scaling, label=\"BROMY\")\n",
    "\n",
    "    ax[1].plot(st1.select(channel=\"*E\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st1.select(channel=\"*E\")[0].data/tilt_scaling)\n",
    "    ax[1].plot(st2.select(channel=\"*E\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st2.select(channel=\"*E\")[0].data/tilt_scaling)\n",
    "    ax[1].plot(st3.select(channel=\"*E\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st3.select(channel=\"*E\")[0].data/tilt_scaling)\n",
    "\n",
    "    ax[2].plot(st1.select(channel=\"*T\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st1.select(channel=\"*T\")[0].data)\n",
    "    ax[2].plot(st2.select(channel=\"*T\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st2.select(channel=\"*T\")[0].data)\n",
    "    ax[2].plot(st3.select(channel=\"*T\")[0].times(reftime=UTCDateTime(\"2019-01-01T00\"))/time_scaling, \n",
    "               st3.select(channel=\"*T\")[0].data)\n",
    "\n",
    "    ax[0].set_ylabel(f\"N ({tilt_unit})\", fontsize=font)\n",
    "    ax[1].set_ylabel(f\"E ({tilt_unit})\", fontsize=font)\n",
    "    ax[2].set_ylabel(f\"T (째C)\", fontsize=font)\n",
    "#     ax[2].set_xlabel(f\"Time ({time_unit})\", fontsize=font)\n",
    "    \n",
    "    for o in range(3):\n",
    "        ax[o].grid()\n",
    "    \n",
    "    ax[0].legend(loc=1, fontsize=font-2, bbox_to_anchor=(0.7, 1.1), ncol=3, framealpha=1)\n",
    "    \n",
    "    tcks= ax[NN-1].get_xticks()\n",
    "    tcklbls = [datetime.fromtimestamp(t*time_scaling+datetime(2019,1,1).timestamp()).strftime(\"%Y-%m-%d\") for t in tcks]\n",
    "    ax[NN-1].set_xticklabels(tcklbls)\n",
    "    \n",
    "    plt.show();\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-shuttle",
   "metadata": {},
   "source": [
    "### Load Tiltmeter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07660d7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:01.649068Z",
     "start_time": "2023-01-16T16:24:01.589217Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __load_local(config, seed_id):\n",
    "    \n",
    "    from tqdm.notebook import tqdm\n",
    "    from obspy.clients.filesystem.sds import Client\n",
    "    \n",
    "    net, sta, loc, cha = seed_id.split(\".\")\n",
    "    \n",
    "    tbeg, tend = config['tbeg'], config['tend']\n",
    "\n",
    "    st0 = Client(config['path_to_data'], fileborder_samples=1000).get_waveforms(net, sta, loc, cha, tbeg, tend)\n",
    "    \n",
    "    st0.merge()\n",
    "    \n",
    "    return st0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca469b47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:03.005777Z",
     "start_time": "2023-01-16T16:24:01.650043Z"
    }
   },
   "outputs": [],
   "source": [
    "# ROMYT0, inv0 = __querrySeismoData(    \n",
    "#                                 seed_id=f\"BW.ROMYT..MA*\",\n",
    "#                                 starttime=config.get(\"tbeg\"),\n",
    "#                                 endtime=config.get(\"tend\"),\n",
    "#                                 repository=config.get(\"repository\"),\n",
    "#                                 path=None,\n",
    "#                                 restitute=False,\n",
    "#                                 detail=None,\n",
    "#                                 fill_value=-9999, \n",
    "#                                 )\n",
    "\n",
    "ROMYT0 = __load_local(config, \"BW.ROMYT..MA*\")\n",
    "\n",
    "ROMYT0.sort()\n",
    "ROMYT0.merge()\n",
    "# ROMYT0.resample(1.0, no_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-tower",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:04.041950Z",
     "start_time": "2023-01-16T16:24:03.007527Z"
    }
   },
   "outputs": [],
   "source": [
    "# TROMY0, inv0 = __querrySeismoData(    \n",
    "#                                 seed_id=f\"BW.TROMY..MA*\",\n",
    "#                                 starttime=config.get(\"tbeg\"),\n",
    "#                                 endtime=config.get(\"tend\"),\n",
    "#                                 repository=config.get(\"repository\"),\n",
    "#                                 path=None,\n",
    "#                                 restitute=False,\n",
    "#                                 detail=None,\n",
    "#                                 fill_value=-9999, \n",
    "#                                 )\n",
    "\n",
    "TROMY0 = __load_local(config, \"BW.TROMY..MA*\")\n",
    "\n",
    "TROMY0.sort()\n",
    "TROMY0.merge()\n",
    "# TROMY0.resample(1.0, no_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-timeline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:04.611039Z",
     "start_time": "2023-01-16T16:24:04.043210Z"
    }
   },
   "outputs": [],
   "source": [
    "# BROMY0, inv0 = __querrySeismoData(    \n",
    "#                                 seed_id=\"BW.DROMY..LA*\",\n",
    "#                                 starttime=config.get(\"tbeg\"),\n",
    "#                                 endtime=config.get(\"tend\"),\n",
    "#                                 repository=config.get(\"repository\"),\n",
    "#                                 path=None,\n",
    "#                                 restitute=False,\n",
    "#                                 detail=None,\n",
    "#                                 fill_value=-9999, \n",
    "#                                 )\n",
    "\n",
    "BROMY0 = __load_local(config, \"BW.DROMY..LA*\")\n",
    "\n",
    "BROMY0.sort()\n",
    "BROMY0.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de84c04",
   "metadata": {},
   "source": [
    "## Correct for known offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1c21b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:04.622436Z",
     "start_time": "2023-01-16T16:24:04.612334Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __correct_offsets(st, offset_correction, plot=False):\n",
    "    \n",
    "    from numpy import nanmedian, nanmean\n",
    "    from obspy import UTCDateTime, Stream\n",
    "    \n",
    "    st_out = Stream()\n",
    "    \n",
    "    for cc in [\"N\", \"E\", \"T\"]:\n",
    "\n",
    "        if cc not in offset_correction.keys():\n",
    "            st_out += st.select(channel=f\"*{cc}\").copy()\n",
    "            continue\n",
    "        \n",
    "        st0 = st.select(channel=f\"*{cc}\").copy()\n",
    "\n",
    "        tbeg, tend = st0[0].stats.starttime, st0[0].stats.endtime\n",
    "        \n",
    "        for nn in range(len(offset_correction[cc])):\n",
    "            nn +=1\n",
    "\n",
    "            if offset_correction[cc][nn]['time_reset'] < tbeg or offset_correction[cc][nn]['time_reset'] > tend:\n",
    "                continue\n",
    "                        \n",
    "            step_time = UTCDateTime(offset_correction[cc][nn]['time_reset'])\n",
    "            offset_time_before = offset_correction[cc][nn]['time_before']\n",
    "            offset_time_after = offset_correction[cc][nn]['time_after']\n",
    "\n",
    "            st0_before = st0.copy()\n",
    "            st0_before.trim(tbeg, step_time-offset_time_before)\n",
    "\n",
    "            st0_after  = st0.copy()\n",
    "            st0_after.trim(step_time+offset_time_after, tend)    \n",
    "\n",
    "            median_before = nanmean(st0_before[0].data[-100:])\n",
    "            median_after  = nanmean(st0_after[0].data[:100]) \n",
    "            \n",
    "            \n",
    "            if (median_after - median_before) < 0: \n",
    "                st0_after[0].data += abs(median_after - median_before)\n",
    "            elif (median_after - median_before) >= 0: \n",
    "                st0_after[0].data -= abs(median_after - median_before)\n",
    "\n",
    "            st0_before += st0_after\n",
    "            \n",
    "            st0 = st0_before.merge(fill_value=nan)\n",
    "\n",
    "        st_out += st0\n",
    "        \n",
    "#     st_out.trim(tbeg, tend, nearest_sample=False)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(3,1, figsize=(15,8), sharex=True)\n",
    "\n",
    "        ax[0].plot(st.select(channel=\"*N\")[0].times()/86400, st.select(channel=\"*N\")[0].data)\n",
    "        ax[0].plot(st_out.select(channel=\"*N\")[0].times()/86400, st_out.select(channel=\"*N\")[0].data)\n",
    "\n",
    "        ax[1].plot(st.select(channel=\"*E\")[0].times()/86400, st.select(channel=\"*E\")[0].data)\n",
    "        ax[1].plot(st_out.select(channel=\"*E\")[0].times()/86400, st_out.select(channel=\"*E\")[0].data)\n",
    "\n",
    "        ax[2].plot(st.select(channel=\"*T\")[0].times()/86400, st.select(channel=\"*T\")[0].data)\n",
    "        ax[2].plot(st_out.select(channel=\"*T\")[0].times()/86400, st_out.select(channel=\"*T\")[0].data)\n",
    "\n",
    "        ax[0].set_ylabel(\"MAN (counts)\")\n",
    "        ax[1].set_ylabel(\"MAE (counts)\")\n",
    "        ax[2].set_ylabel(\"MAT (counts)\")\n",
    "        ax[2].set_xlabel(\"Time (days)\")\n",
    "        \n",
    "        plt.show();\n",
    "\n",
    "\n",
    "    return st_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dee195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:04.704122Z",
     "start_time": "2023-01-16T16:24:04.623730Z"
    }
   },
   "outputs": [],
   "source": [
    "TROMY = __correct_offsets(TROMY0, offset_correction['TROMY'], plot=False)\n",
    "ROMYT = __correct_offsets(ROMYT0, offset_correction['ROMYT'], plot=False)\n",
    "BROMY = __correct_offsets(BROMY0, offset_correction['BROMY'], plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cf787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:04.707396Z",
     "start_time": "2023-01-16T16:24:04.705204Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig = __plot_all_tilt(TROMY, ROMYT, BROMY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96ad7e",
   "metadata": {},
   "source": [
    "## Covert Data Counts to Rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f0ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:04.740177Z",
     "start_time": "2023-01-16T16:24:04.708628Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __conversion(st, conf):\n",
    "\n",
    "    st0 = st.copy()\n",
    "    \n",
    "    def convertTemp(trace):\n",
    "        Tvolt = trace.data * conf.get('gainTemp')\n",
    "        coeff = conf.get('calcTempCoefficients')\n",
    "        return coeff[0] + coeff[1]*Tvolt + coeff[2]*Tvolt**2 + coeff[3]*Tvolt**3\n",
    "    \n",
    "    def convertTilt(trace, conversion, sensitivity):\n",
    "        return trace.data * conversion * sensitivity\n",
    "\n",
    "    for tr in st0:\n",
    "        if tr.stats.channel[-1] == 'T':\n",
    "            tr.data = convertTemp(tr)\n",
    "        elif tr.stats.channel[-1] == 'N':\n",
    "            tr.data = convertTilt(tr, conf['convTN'], conf['gainTilt'])\n",
    "        elif tr.stats.channel[-1] == 'E':\n",
    "            tr.data = convertTilt(tr, conf['convTE'], conf['gainTilt'])\n",
    "        else:\n",
    "            print(\"no match\")\n",
    "            \n",
    "    print(f\"  -> converted data of {st[0].stats.station}\")\n",
    "    return st0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513fce1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:05.581141Z",
     "start_time": "2023-01-16T16:24:04.741155Z"
    }
   },
   "outputs": [],
   "source": [
    "TROMY = __conversion(TROMY0, confTilt['TROMY'])\n",
    "ROMYT = __conversion(ROMYT0, confTilt['ROMYT'])\n",
    "BROMY = __conversion(BROMY0, confTilt['BROMY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f99e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:05.583664Z",
     "start_time": "2023-01-16T16:24:05.582075Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig = __plot_all_tilt(TROMY, ROMYT, BROMY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28e898",
   "metadata": {},
   "source": [
    "## Tilt Reset at Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ebc72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:05.640456Z",
     "start_time": "2023-01-16T16:24:05.584564Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reset start to Zero\n",
    "for st in [TROMY, ROMYT, BROMY]:\n",
    "    for tr in st:\n",
    "        if not tr.stats.channel[-1] == \"T\" or tr.stats.channel[0] == \"W\":\n",
    "            tr.data -= tr.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188a6f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:12.006496Z",
     "start_time": "2023-01-16T16:24:05.641407Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = __plot_all_tilt(TROMY, ROMYT, BROMY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535803cb",
   "metadata": {},
   "source": [
    "## Correct for Linear Temperature Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5a906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:12.009814Z",
     "start_time": "2023-01-16T16:24:12.007363Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __correct_temperature_trend(st, correction):\n",
    "    \n",
    "    st0 = st.copy()\n",
    "    temperature = st0.select(channel=\"*T\")[0].data\n",
    "    \n",
    "#     st0.select(channel=\"*N\")[0].data -= (correction['N_slope']* temperature + correction['N_intercept'])\n",
    "#     st0.select(channel=\"*E\")[0].data -= (correction['E_slope']* temperature + correction['N_intercept'])\n",
    "    st0.select(channel=\"*N\")[0].data -= (correction['N_slope']* temperature)\n",
    "    st0.select(channel=\"*E\")[0].data -= (correction['E_slope']* temperature)\n",
    "    \n",
    "    return st0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd87faaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:12.026819Z",
     "start_time": "2023-01-16T16:24:12.010644Z"
    }
   },
   "outputs": [],
   "source": [
    "## apply correction model\n",
    "# TROMY = __correct_temperature_trend(TROMY, temperature_correction['TROMY'])\n",
    "# ROMYT = __correct_temperature_trend(ROMYT, temperature_correction['ROMYT'])\n",
    "# BROMY = __correct_temperature_trend(BROMY, temperature_correction['BROMY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9fe97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:17.446706Z",
     "start_time": "2023-01-16T16:24:12.027711Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = __plot_all_tilt(TROMY, ROMYT, BROMY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e0233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.223693Z",
     "start_time": "2023-01-16T16:24:17.447613Z"
    }
   },
   "outputs": [],
   "source": [
    "ROMYT.plot(equal_scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5bbb70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T11:02:30.748219Z",
     "start_time": "2022-12-08T11:02:30.746440Z"
    }
   },
   "source": [
    "## Add WROMY Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b35de8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:17.258986Z",
     "start_time": "2023-01-16T16:30:17.255389Z"
    }
   },
   "outputs": [],
   "source": [
    "from andbro__load_WROMY_stream import __load_wromy_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8972a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:17.924352Z",
     "start_time": "2023-01-16T16:30:17.389884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7e54f17fba40df8bc8b55bccd65194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: BW.WROMY.WS5.D.2022.361, does not exists!\n",
      "File: BW.WROMY.WS5.D.2022.362, does not exists!\n",
      "File: BW.WROMY.WS5.D.2022.363, does not exists!\n",
      "File: BW.WROMY.WS5.D.2022.364, does not exists!\n",
      "File: BW.WROMY.WS5.D.2022.365, does not exists!\n",
      "Path: /import/freenas-ffb-01-data/romy_archive/2023/BW/WROMY/WS5.D/, does not exists!\n"
     ]
    }
   ],
   "source": [
    "ws5 = __load_wromy_stream(config, config['path_to_wromy'], \"BW.WROMY..WS5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c92b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:17.977495Z",
     "start_time": "2023-01-16T16:30:17.925527Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a39d2b4af885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mws5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*T\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# arr = array([1,2,3,nan,3,4])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# mask = isfinite(arr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "from numpy import isfinite, array\n",
    "import numpy.ma as ma\n",
    "\n",
    "arr = ws5.select(channel=\"*T\")[0].data\n",
    "# arr = array([1,2,3,nan,3,4])\n",
    "# mask = isfinite(arr)\n",
    "# ma_arr = ma.masked_array(arr, mask=mask)\n",
    "\n",
    "ma_arr = ma.masked_invalid(arr)\n",
    "ws5.select(channel=\"*T\")[0].data = ma.masked_invalid(arr)\n",
    "\n",
    "plt.plot(ma_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-imaging",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T08:42:57.050040Z",
     "start_time": "2021-02-23T08:42:57.046253Z"
    }
   },
   "source": [
    "### Load FURT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd52d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:37.958284Z",
     "start_time": "2023-01-16T16:30:37.925240Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '__load_furt_stream' from 'andbro__load_FURT_stream' (/home/brotzer/anaconda3/lib/python3.7/site-packages/andbro__load_FURT_stream.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eb1964bbedeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mandbro__load_FURT_stream\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__load_furt_stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '__load_furt_stream' from 'andbro__load_FURT_stream' (/home/brotzer/anaconda3/lib/python3.7/site-packages/andbro__load_FURT_stream.py)"
     ]
    }
   ],
   "source": [
    "from andbro__load_FURT_stream import __load_furt_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8df4c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:30:38.209127Z",
     "start_time": "2023-01-16T16:30:38.192724Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __load_furt_stream(config, show_raw=False, path_to_archive = '/bay200/gif_online/FURT/WETTER/'):\n",
    "    \n",
    "    '''\n",
    "    Load a selection of data of FURT weather station for certain times and return an obspy stream\n",
    "    \n",
    "    \n",
    "    PARAMETERS:\n",
    "        - config:    configuration dictionary\n",
    "        - show_raw:  bool (True/False) -> shows raw data FURT head\n",
    "\n",
    "\n",
    "    RETURN:\n",
    "        - stream\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    from pathlib import Path\n",
    "    from obspy import UTCDateTime\n",
    "    from tqdm.notebook import tqdm_notebook\n",
    "    from numpy import arange\n",
    "    from obspy import Stream\n",
    "    \n",
    "    def __add_trace(cha, tbeg, dat, dt=1):\n",
    "\n",
    "        from obspy import Trace, UTCDateTime\n",
    "        from numpy import array\n",
    "\n",
    "        tr = Trace()\n",
    "        tr.stats.station = 'FURT'\n",
    "        tr.stats.channel = str(cha)\n",
    "        tr.stats.sampling_rate = 1/dt\n",
    "        tr.stats.starttime = UTCDateTime(tbeg)\n",
    "        tr.data = array(dat)\n",
    "\n",
    "        return tr\n",
    "    \n",
    "    \n",
    "    def __resample(df, freq='1S'):\n",
    "\n",
    "        ## make column with datetime\n",
    "        df['datetime'] = df['date'].astype(str).str.rjust(6,\"0\")+\" \"+df['time'].astype(str).str.rjust(6,\"0\")\n",
    "\n",
    "        ## drop datetime duplicates\n",
    "        df = df[df.duplicated(\"datetime\", keep=\"first\") != True]\n",
    "\n",
    "        ## convert to pandas datetime object\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], format=\"%d%m%y %H%M%S\", errors=\"coerce\")\n",
    "\n",
    "        ## set datetime column as index\n",
    "        df.set_index('datetime', inplace=True)\n",
    "\n",
    "        ## remove duplicates\n",
    "        df = df[~df.index.duplicated()]\n",
    "\n",
    "        ## resample\n",
    "        df = df.asfreq(freq=freq)\n",
    "\n",
    "        return df \n",
    "    \n",
    "\n",
    "    \n",
    "    config['tbeg'] = UTCDateTime(config['tbeg'])\n",
    "    config['tend'] = UTCDateTime(config['tend'])\n",
    "    \n",
    "    output_text = []\n",
    "    \n",
    "    new_delta = 10\n",
    "    \n",
    "    if not Path(path_to_archive).exists():\n",
    "        output_text.append(f\"  -> Path: {path_to_archive}, does not exists!\")\n",
    "#         print(f\"  -> Path: {path_to_archive}, does not exists!\")\n",
    "        return    \n",
    "    \n",
    "    \n",
    "    ## list of parameters requried in configurations\n",
    "    params = ['tbeg', 'tend']\n",
    "    for param in params:\n",
    "        if not param in config.keys():\n",
    "            output_text.append(f\"ERROR: {param} not in config but required!\")\n",
    "#             print(f\"ERROR: {param} not in config but required!\")\n",
    "            return\n",
    "    \n",
    "    \n",
    "    ## declare empyt dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i, date in enumerate(tqdm_notebook(arange(config['tbeg'].date, (config['tend']+86410).date))):\n",
    "        \n",
    "        date = UTCDateTime(str(date)).date\n",
    "        filename = f'FURT.WSX.D.{str(date.day).rjust(2,\"0\")}{str(date.month).rjust(2,\"0\")}{str(date.year).rjust(2,\"0\")[-2:]}.0000'\n",
    "        \n",
    "#         print(f'   reading {filename} ...')\n",
    "\n",
    "        try:\n",
    "            if show_raw:\n",
    "                df0 = pd.read_csv(path_to_archive+filename)            \n",
    "                print(df0.columns.tolist())\n",
    "                return\n",
    "            else:\n",
    "                df0 = pd.read_csv(path_to_archive+filename, usecols=[0,1,10,12,13,14], names=['date', 'time', 'T', 'H', 'P','Rc'])            \n",
    "            \n",
    "            ## substitute strings with floats\n",
    "            df0['T']  = df0['T'].str.split(\"=\", expand=True)[1].str.split(\"C\", expand=True)[0].astype(float)\n",
    "            df0['P']  = df0['P'].str.split(\"=\", expand=True)[1].str.split(\"H\", expand=True)[0].astype(float)\n",
    "            df0['H']  = df0['H'].str.split(\"=\", expand=True)[1].str.split(\"P\", expand=True)[0].astype(float)\n",
    "            df0['Rc'] = df0['Rc'].str.split(\"=\", expand=True)[1].str.split(\"M\", expand=True)[0].astype(float)\n",
    "           \n",
    "            \n",
    "            ## replace error indicating values (-9999, 999.9) with NaN values\n",
    "#             df0.replace(to_replace=-9999, value=nan, inplace=True)\n",
    "#             df0.replace(to_replace=999.9, value=nan, inplace=True)\n",
    "            \n",
    "            \n",
    "            if df.empty:\n",
    "                df = df0\n",
    "            else: \n",
    "                df = pd.concat([df, df0])\n",
    "        except:\n",
    "            output_text.append(f\"  -> File: {filename}, does not exists!\")\n",
    "#             print(f\"  -> File: {filename}, does not exists!\")\n",
    "   \n",
    "    ## reset the index for the joined frame\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    \n",
    "    ## resample dataframe and avoid data gaps\n",
    "    df = __resample(df, freq=f'{new_delta}S')\n",
    "\n",
    "    \n",
    "    for text in output_text:\n",
    "        print(text)    \n",
    "\n",
    "    df_starttime = UTCDateTime(df.index[0])\n",
    "    \n",
    "    ## create stream and attach traces\n",
    "    st0 = Stream()\n",
    "    st0 += __add_trace(\"LAT\", df_starttime, df['T'], dt=new_delta)\n",
    "    st0 += __add_trace(\"LAP\", df_starttime, df['P'], dt=new_delta)\n",
    "    st0 += __add_trace(\"LAH\", df_starttime, df['H'], dt=new_delta)\n",
    "    st0 += __add_trace(\"LAR\", df_starttime, df['Rc'], dt=new_delta)\n",
    "        \n",
    "    ## trim to specfied time period\n",
    "    st0.trim(config['tbeg'], config['tend'])\n",
    "        \n",
    "    print(f\"Specified end: {config['tend']} \\nTrace end:     {st0.select(channel='LAT')[0].stats.endtime}\")\n",
    "    \n",
    "    return st0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ab9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.342025Z",
     "start_time": "2023-01-16T16:23:58.270Z"
    }
   },
   "outputs": [],
   "source": [
    "furt = __read_furt_stream(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a6846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T13:54:26.985141Z",
     "start_time": "2023-01-16T13:54:26.973413Z"
    }
   },
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba3b39",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tilt Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-eating",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.342740Z",
     "start_time": "2023-01-16T16:23:58.273Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def __get_vector(N, E, Twin=3600):\n",
    "\n",
    "    from numpy import median, sqrt, arctan, degrees, mod, array, append, rad2deg\n",
    "\n",
    "    \n",
    "    dt = N[0].stats.delta\n",
    "    t1 = N[0].stats.starttime\n",
    "    t1 = 0\n",
    "\n",
    "    Ndata = N[0].data\n",
    "    Edata = E[0].data\n",
    "\n",
    "    vnorm, vdir, timeline = [], [], []\n",
    "    while (t1 + Twin*dt) < N[0].stats.npts:\n",
    "\n",
    "\n",
    "        Nmed = median(Ndata[int(t1*dt):int((t1+Twin)*dt)])\n",
    "        Emed = median(Edata[int(t1*dt):int((t1+Twin)*dt)])\n",
    "\n",
    "        vnorm.append(sqrt(Nmed**2 + Emed**2))\n",
    "    #     vdir.append(mod(degrees(arctan(Nmed/Emed)), 360))\n",
    "        vdir.append(rad2deg(arctan(Nmed/Emed)))\n",
    "\n",
    "        t1 += Twin/2*dt\n",
    "    \n",
    "        timeline.append(t1*dt)\n",
    "    \n",
    "    \n",
    "    time_offset = N[0].stats.starttime.hour*3600+ N[0].stats.starttime.minute*60 + N[0].stats.starttime.second\n",
    "    timeline = ( array(timeline) + time_offset ) / 3600 /24 # in hours\n",
    "    \n",
    "    return timeline, array(vdir), array(vnorm)\n",
    "\n",
    "bt_vtimeline, bt_vdir, bt_vnorm = __get_vector(bt.select(channel=\"*N\"), bt.select(channel=\"*E\"), Twin=3600)\n",
    "pt_vtimeline, pt_vdir, pt_vnorm = __get_vector(pt.select(channel=\"*N\"), pt.select(channel=\"*E\"), Twin=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ef632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.343292Z",
     "start_time": "2023-01-16T16:23:58.274Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def __get_movement(N, E, Twin=3600):\n",
    "\n",
    "    from numpy import median, sqrt, arctan, degrees, mod, array, append, rad2deg, nan\n",
    "    from numpy import ma\n",
    "    \n",
    "    dt = N[0].stats.delta\n",
    "#     t1 = N[0].stats.starttime\n",
    "    t1 = 0\n",
    "\n",
    "    Ndata = N[0].data\n",
    "    Edata = E[0].data\n",
    "\n",
    "    if ma.is_masked(Ndata):\n",
    "        Ndata = ma.filled(Ndata, fill_value=nan)\n",
    "    if ma.is_masked(Edata):\n",
    "        Edata = ma.filled(Edata, fill_value=nan)\n",
    "        \n",
    "    vnorm, vdir, timeline = [], [], []\n",
    "    while (t1 + Twin) < N[0].stats.npts*dt:\n",
    "        \n",
    "        Nmed = median(Ndata[int(t1/dt):int((t1+Twin)/dt)])\n",
    "        Emed = median(Edata[int(t1/dt):int((t1+Twin)/dt)])\n",
    "\n",
    "        \n",
    "        vnorm.append(sqrt(Nmed**2 + Emed**2))\n",
    "        \n",
    "        if Nmed > 0 and Emed > 0:\n",
    "            vdir.append(90-abs(rad2deg(arctan(abs(Nmed/Emed)))))\n",
    "        \n",
    "        elif Nmed < 0 and Emed > 0:\n",
    "            vdir.append(90+abs(rad2deg(arctan(abs(Nmed/Emed)))))\n",
    "        \n",
    "        elif Nmed < 0 and Emed < 0:\n",
    "            vdir.append(270-abs(rad2deg(arctan(abs(Nmed/Emed)))))\n",
    "        \n",
    "        elif Nmed > 0 and Emed < 0:\n",
    "            vdir.append(270+abs(rad2deg(arctan(abs(Nmed/Emed)))))\n",
    "        \n",
    "        else:\n",
    "            vdir.append(nan)\n",
    "            \n",
    "        t1 += Twin/2\n",
    "    \n",
    "        timeline.append(t1)\n",
    "    \n",
    "    time_offset = N[0].stats.starttime.julday\n",
    "    timeline = array(timeline)/3600 /24 + time_offset# in days\n",
    "    \n",
    "    return timeline, array(vdir), array(vnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193ee68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.343890Z",
     "start_time": "2023-01-16T16:23:58.276Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def __makeplot_normal_vector_movement(vdirH, vnormH, vdirV, vnormV, vtimelineH, vtimelineV):\n",
    "    \n",
    "    #-- Plot... ------------------------------------------------\n",
    "    fig, ax = plt.subplots(1, 2, subplot_kw=dict(projection='polar'), figsize=(15,5))\n",
    "\n",
    "    font=12\n",
    "\n",
    "\n",
    "    p1 = ax[0].scatter(deg2rad(vdirH), vnormH, c=vtimelineH, cmap='plasma', alpha=0.75, s=4, zorder=2)\n",
    "    p2 = ax[1].scatter(deg2rad(vdirV), vnormV, c=vtimelineV, cmap='plasma', alpha=0.75, s=4, zorder=2)\n",
    "\n",
    "    cbar1 = plt.colorbar(p1, ax=ax[0], pad=0.1)\n",
    "    cbar1.set_label('Time in days', rotation=270, fontsize=font, labelpad=18)\n",
    "\n",
    "    cbar2 = plt.colorbar(p2, ax=ax[1],  pad=0.1)\n",
    "    cbar2.set_label('Time in days of 2021', rotation=270, fontsize=font, labelpad=18)\n",
    "\n",
    "\n",
    "#     ax[0].set_ylim(min(vnormH)-0.1*min(vnormH), max(vnormH)+0.05*max(vnormH))\n",
    "\n",
    "#     ax[1].set_ylim(min(vnormV)-0.05*min(vnormV), max(vnormV)+0.01*max(vnormV))\n",
    "\n",
    "    ax[0].set_ylim(0.15, 0.18)\n",
    "    ax[1].set_ylim(0.2, 0.24)\n",
    "\n",
    "    ax[0].set_theta_zero_location('N')\n",
    "    ax[0].set_theta_direction(-1)\n",
    "\n",
    "    ax[1].set_theta_zero_location('N')\n",
    "    ax[1].set_theta_direction(-1)\n",
    "    \n",
    "    ax[0].text(deg2rad(25),93,r\"$\\mu$rad\")\n",
    "    ax[1].text(deg2rad(25),93,r\"$\\mu$rad\")\n",
    "    \n",
    "#     ax[0].set_rgrids(arange(15, 50, 5), angle=60., zorder=0)\n",
    "#     ax[1].set_rgrids(arange(22.5, 40.0, 2.5), angle=60., zorder=0)\n",
    "\n",
    "    ax[0].set_title(\"Platform Tiltmeter\",fontsize=font)\n",
    "    ax[1].set_title(\"Borehole Tiltmeter\",fontsize=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f534e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.344389Z",
     "start_time": "2023-01-16T16:23:58.278Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def __makeplot_vector(vdirH, vnormH, vdirV, vnormV, vtimelineH, vtimelineV):\n",
    "    \n",
    "    N = 2\n",
    "    font = 12\n",
    " \n",
    "    fig, ax = plt.subplots(N, 2, figsize=(15,6), sharex=True)\n",
    "    \n",
    "#     ax[0][0].plot(vtimelineH, vnormH)\n",
    "    ax[0][0].scatter(vtimelineH, vnormH, c=vtimelineH, cmap=\"plasma\", s=0.7)\n",
    "    \n",
    "#     ax[0][1].plot(vtimelineV, vnormV)\n",
    "    ax[0][1].scatter(vtimelineV, vnormV, c=vtimelineH, cmap=\"plasma\", s=0.7)\n",
    "    \n",
    "#     ax[1][0].plot(vtimelineH, vdirH)\n",
    "    ax[1][0].scatter(vtimelineH, vdirH, c=vtimelineH, cmap=\"plasma\", s=0.7)\n",
    "\n",
    "#     ax[1][1].plot(vtimelineV, vdirV)\n",
    "    ax[1][1].scatter(vtimelineV, vdirV, c=vtimelineH, cmap=\"plasma\", s=0.7)\n",
    "   \n",
    "    ax[0][0].grid(zorder=0, alpha=0.7, color=\"grey\", ls=\":\")\n",
    "    ax[0][1].grid(zorder=0, alpha=0.7, color=\"grey\", ls=\":\")\n",
    "    ax[1][0].grid(zorder=0, alpha=0.7, color=\"grey\", ls=\":\")\n",
    "    ax[1][1].grid(zorder=0, alpha=0.7, color=\"grey\", ls=\":\")\n",
    "    \n",
    "    ax[0][0].set_title('Platform Tiltmeter', fontsize=font)\n",
    "    ax[0][1].set_title('Borehole Tiltmeter', fontsize=font)\n",
    "    \n",
    "    ax[0][0].set_ylabel(\"Vector Norm (mrad)\", fontsize=font)\n",
    "    ax[1][0].set_ylabel(\"Degrees (째)\", fontsize=font)\n",
    "    \n",
    "    ax[N-1][0].set_xlabel(\"Day of Year\", fontsize=font)\n",
    "    ax[N-1][1].set_xlabel(\"Day of Year\", fontsize=font)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a9348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.345158Z",
     "start_time": "2023-01-16T16:23:58.280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from numpy import deg2rad\n",
    "\n",
    "vtimelineH, vdirH, vnormH = __get_movement(pt.select(channel=\"*N\"), pt.select(channel=\"*E\"), Twin=3600)\n",
    "vtimelineV, vdirV, vnormV = __get_movement(bt.select(channel=\"*N\"), bt.select(channel=\"*E\"), Twin=3600)\n",
    "\n",
    "vnormH *= 1e3 # convert to milli rad\n",
    "vnormV *= 1e3 # convert to milli rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86cc8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.345779Z",
     "start_time": "2023-01-16T16:23:58.281Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "__makeplot_normal_vector_movement(vdirH, vnormH, vdirV, vnormV, vtimelineH, vtimelineV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b5ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.346398Z",
     "start_time": "2023-01-16T16:23:58.283Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "__makeplot_vector(vdirH, vnormH, vdirV, vnormV, vtimelineH, vtimelineV);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f4b70",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abe021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2773285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.347064Z",
     "start_time": "2023-01-16T16:23:58.286Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __read_furt_data(config, show_raw=False):\n",
    "    '''\n",
    "    Load a selection of data of FURT weather station for time period\n",
    "    \n",
    "    \n",
    "    PARAMETERS:\n",
    "        - config:    configuration dictionary\n",
    "        - show_raw:  bool (True/False) -> shows raw data FURT head\n",
    "\n",
    "\n",
    "    RETURN:\n",
    "        - dataframe\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    from numpy import arange\n",
    "        \n",
    "        \n",
    "    ## define path_to_archive -> directory with data\n",
    "    if 'path_to_archive' in config.keys():\n",
    "        path_to_archive = config['path_to_archive']\n",
    "    else:\n",
    "        path_to_archive = '/bay200/gif_online/FURT/WETTER/'\n",
    "        \n",
    "    ## check if path with data exists\n",
    "    if not Path(path_to_archive).exists():\n",
    "        print(f\"  -> Path: {path_to_archive}, does not exists!\")\n",
    "        return    \n",
    "    \n",
    "    \n",
    "    ## list of parameters requried in configurations\n",
    "    params = ['tbeg', 'tend']\n",
    "    for param in params:\n",
    "        if not param in config.keys():\n",
    "            print(f\"ERROR: {param} not in config but required!\")\n",
    "            return\n",
    "    \n",
    "    \n",
    "    ## declare empyt dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    ## loop over day files and load data\n",
    "    for i, date in tqdm(enumerate(arange(config['tbeg'].date, (config['tend']+86400).date))):\n",
    "        \n",
    "        date = UTCDateTime(str(date)).date\n",
    "        filename = f'FURT.WSX.D.{str(date.day).rjust(2,\"0\")}{str(date.month).rjust(2,\"0\")}{str(date.year).rjust(2,\"0\")[-2:]}.0000'\n",
    "        \n",
    "#         print(f'   reading {filename} ...')\n",
    "\n",
    "        try:\n",
    "            if show_raw:\n",
    "                df0 = pd.read_csv(path_to_archive+filename)            \n",
    "                print(df0.columns.tolist())\n",
    "                return\n",
    "            else:\n",
    "                df0 = pd.read_csv(path_to_archive+filename, usecols=[0,1,10,12,13,14], names=['date', 'time', 'T', 'H', 'P','Rc'])            \n",
    "            \n",
    "            ## substitute strings with floats\n",
    "            df0['T']  = df0['T'].str.split(\"=\", expand=True)[1].str.split(\"C\", expand=True)[0].astype(float)\n",
    "            df0['P']  = df0['P'].str.split(\"=\", expand=True)[1].str.split(\"H\", expand=True)[0].astype(float)\n",
    "            df0['H']  = df0['H'].str.split(\"=\", expand=True)[1].str.split(\"P\", expand=True)[0].astype(float)\n",
    "            df0['Rc'] = df0['Rc'].str.split(\"=\", expand=True)[1].str.split(\"M\", expand=True)[0].astype(float)\n",
    "           \n",
    "            \n",
    "            ## replace error indicating values (-9999, 999.9) with NaN values\n",
    "            df0.replace(to_replace=-9999, value=nan, inplace=True)\n",
    "            df0.replace(to_replace=999.9, value=nan, inplace=True)\n",
    "            \n",
    "            \n",
    "            if df.empty:\n",
    "                df = df0\n",
    "            else: \n",
    "                df = pd.concat([df, df0])\n",
    "        except:\n",
    "            print(f\"  -> File: {filename}, does not exists!\")\n",
    "   \n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86915748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.347603Z",
     "start_time": "2023-01-16T16:23:58.288Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __processing_FURT(data, config):\n",
    "    \n",
    "    filter_length = 10*config['resample']\n",
    "    \n",
    "    data.iloc[:,3:6] = data.iloc[:,3:6].rolling(filter_length).mean() \n",
    "    print(f\"Filter: rooling mean {filter_length}!\")\n",
    "    \n",
    "    data = data[data.index % config['resample'] == 0]\n",
    "    print(f\"Resampling: keep every {config['resample']}nth sample!\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12174f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.348161Z",
     "start_time": "2023-01-16T16:23:58.289Z"
    }
   },
   "outputs": [],
   "source": [
    "FURT = __read_furt_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90604e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.348738Z",
     "start_time": "2023-01-16T16:23:58.291Z"
    }
   },
   "outputs": [],
   "source": [
    "## set column headers\n",
    "FURT = FURT[['date', 'time', 'T', 'P', 'H', 'Rc']]\n",
    "\n",
    "## resampling \n",
    "config['resample'] = 10\n",
    "FURT = __processing_FURT(FURT, config)\n",
    "\n",
    "\n",
    "## check if date column consists of integers\n",
    "if str(FURT['date'].dtype) == 'float64':\n",
    "    FURT['date'] = FURT['date'].astype('int')\n",
    "\n",
    "    \n",
    "## add a column with day of year\n",
    "FURT['doy'] = [int(UTCDateTime(f'20{str(int(dat)).rjust(6,\"0\")[-2:]}-{str(int(dat)).rjust(6,\"0\")[-4:-2]}-{str(int(dat)).rjust(6,\"0\")[-6:-4]}').julday) for dat in FURT.date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a3a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.349228Z",
     "start_time": "2023-01-16T16:23:58.292Z"
    }
   },
   "outputs": [],
   "source": [
    "from obspy.signal.freqattributes import spectrum\n",
    "from numpy import hanning\n",
    "from andbro__fft import __fft\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8137664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44870862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.349803Z",
     "start_time": "2023-01-16T16:23:58.294Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "datapath = f\"/home/andbro/freenas/romy_archive/2022/BW/ROMYT/MAN.D/*\"\n",
    "\n",
    "N = obspy.read(datapath);\n",
    "N.merge(fill_value='interpolate')\n",
    "\n",
    "datapath = f\"/home/andbro/freenas/romy_archive/2022/BW/ROMYT/MAE.D/*\"\n",
    "\n",
    "E = obspy.read(datapath);\n",
    "E.merge(fill_value='interpolate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71443161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.350333Z",
     "start_time": "2023-01-16T16:23:58.296Z"
    }
   },
   "outputs": [],
   "source": [
    "TRII = obspy.Stream()\n",
    "TRII += N\n",
    "TRII += E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19dfc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.350907Z",
     "start_time": "2023-01-16T16:23:58.298Z"
    }
   },
   "outputs": [],
   "source": [
    "TRII.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c0714",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.351416Z",
     "start_time": "2023-01-16T16:23:58.299Z"
    }
   },
   "outputs": [],
   "source": [
    "TRII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955c30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.352002Z",
     "start_time": "2023-01-16T16:23:58.301Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __makeplotStreamPSD(st, config):\n",
    "\n",
    "    from scipy import fftpack\n",
    "    from numpy import abs\n",
    "    from scipy.signal import welch, hann\n",
    "\n",
    "\n",
    "    nblock =  4096*100\n",
    "    overlap = 1028\n",
    "    win = hann(nblock, True)\n",
    "\n",
    "    fig, axes = plt.subplots(len(st),2,figsize=(15,10), sharex='col')\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    ## _______________________________________________\n",
    "\n",
    "    st.sort(keys=['channel'], reverse=True)\n",
    "    \n",
    "    for i, tr in enumerate(st):\n",
    "\n",
    "        ff, Pxx = welch(tr.data, fs=tr.stats.sampling_rate, \n",
    "                        window=win, noverlap=overlap, nfft=nblock,\n",
    "                        scaling=\"density\",\n",
    "                        return_onesided=True)\n",
    "\n",
    "        ## _________________________________________________________________\n",
    "        axes[i,0].plot(\n",
    "                    tr.times(),\n",
    "                    tr.data,\n",
    "                    color='black',\n",
    "                    label='{} {}'.format(tr.stats.station, tr.stats.channel),\n",
    "                    lw=1.0,\n",
    "                    )\n",
    "\n",
    "\n",
    "        ## _________________________________________________________________\n",
    "        axes[i,1].loglog(\n",
    "                    ff,\n",
    "                    Pxx,\n",
    "                    color='black',\n",
    "                    lw=1.0,\n",
    "                    )\n",
    "\n",
    "\n",
    "        \n",
    "        axes[i,0].set_ylabel(r'$\\Omega$ (rad/s)')    \n",
    "        axes[i,1].set_ylabel(r'PSD (rad$^2$/Hz)')        \n",
    "        axes[i,0].legend(loc='upper left',bbox_to_anchor=(0.8, 1.10), framealpha=1.0)\n",
    "        \n",
    "#         axes[i,0].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "#         axes[i,1].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "\n",
    "        axes[i,1].set_xlim(1e-7,0.25)\n",
    "#         axes[i,1].set_ylim(1e-12,1e-9)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0ce3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T16:24:18.352607Z",
     "start_time": "2023-01-16T16:23:58.302Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "__makeplotStreamPSD(TRII, config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab28b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T01:10:31.639543Z",
     "start_time": "2022-09-14T01:10:31.156989Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcbcea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
