{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7eada23-d642-46ff-9255-39d3e37d8dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/bin/python3\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from obspy import UTCDateTime, read_inventory\n",
    "\n",
    "from functions.rotate_romy_ZUV_ZNE import __rotate_romy_ZUV_ZNE\n",
    "from functions.get_time_intervals import __get_time_intervals\n",
    "from functions.compute_beamforming_ROMY import __compute_beamforming_ROMY\n",
    "from functions.compute_backazimuth_and_velocity_noise import __compute_backazimuth_and_velocity_noise\n",
    "\n",
    "from andbro__read_sds import __read_sds\n",
    "from andbro__save_to_pickle import __save_to_pickle\n",
    "\n",
    "## ---------------------------------------\n",
    "\n",
    "\n",
    "if os.uname().nodename == 'lighthouse':\n",
    "    root_path = '/home/andbro/'\n",
    "    data_path = '/home/andbro/kilauea-data/'\n",
    "    archive_path = '/home/andbro/freenas/'\n",
    "    bay_path = '/home/andbro/bay200/'\n",
    "elif os.uname().nodename == 'kilauea':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/bay200/'\n",
    "elif os.uname().nodename == 'lin-ffb-01':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/bay200/'\n",
    "\n",
    "\n",
    "## ---------------------------------------\n",
    "\n",
    "config = {}\n",
    "\n",
    "# config['station1'] = \"BW.ROMY.10.BJZ\"\n",
    "# config['station2'] = \"GR.FUR..BHN\"\n",
    "\n",
    "# if len(sys.argv) > 1:\n",
    "#     config['tbeg'] = UTCDateTime(sys.argv[1])\n",
    "#     config['tend'] = config['tbeg'] + 86400\n",
    "\n",
    "config['tbeg'] = UTCDateTime(\"2023-09-20 21:00\")\n",
    "config['tend'] = UTCDateTime(\"2023-09-20 22:00\")\n",
    "\n",
    "## test marocco earthquake\n",
    "config['tbeg'] = UTCDateTime(\"2023-09-08 22:00\")\n",
    "config['tend'] = UTCDateTime(\"2023-09-08 23:00\")\n",
    "\n",
    "config['path_to_sds1'] = archive_path+\"romy_archive/\"\n",
    "\n",
    "config['path_to_sds2'] = bay_path+f\"mseed_online/archive/\"\n",
    "\n",
    "config['path_to_figures'] = data_path+f\"VelocityChanges/figures/autoplots/\"\n",
    "\n",
    "config['path_to_inv'] = root_path+\"Documents/ROMY/stationxml_ringlaser/\"\n",
    "\n",
    "config['path_to_data_out'] = data_path+f\"VelocityChanges/data/\"\n",
    "\n",
    "## set maximum number of MLTI in time interval. Otherwise skip interval.\n",
    "config['num_mlti'] = 3\n",
    "\n",
    "config['fmin'], config['fmax'] = 1/10, 1/5\n",
    "\n",
    "config['cc_threshold'] = 0.5\n",
    "\n",
    "config['interval_seconds'] = 3600\n",
    "\n",
    "config['window_overlap'] = 90\n",
    "\n",
    "config['window_length_sec'] = 2/config['fmin']\n",
    "\n",
    "## ---------------------------------------\n",
    "\n",
    "def __load_mlti(tbeg, tend, ring, path_to_archive):\n",
    "\n",
    "    from obspy import UTCDateTime\n",
    "    from pandas import read_csv\n",
    "\n",
    "    tbeg, tend = UTCDateTime(tbeg), UTCDateTime(tend)\n",
    "\n",
    "    year = tbeg.year\n",
    "\n",
    "    rings = {\"U\":\"03\", \"Z\":\"01\", \"V\":\"02\", \"W\":\"04\"}\n",
    "\n",
    "    path_to_mlti = path_to_archive+f\"romy_archive/{year}/BW/CROMY/{year}_romy_{rings[ring]}_mlti.log\"\n",
    "\n",
    "    mlti = read_csv(path_to_mlti, names=[\"time_utc\",\"Action\",\"ERROR\"])\n",
    "\n",
    "    mlti = mlti[(mlti.time_utc > tbeg) & (mlti.time_utc < tend)]\n",
    "\n",
    "    return mlti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7f0ae-abf5-489d-a83a-f72d7a6dc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_time_intervals(tbeg, tend, interval_seconds, interval_overlap):\n",
    "\n",
    "    from obspy import UTCDateTime\n",
    "\n",
    "    tbeg, tend = UTCDateTime(tbeg), UTCDateTime(tend)\n",
    "\n",
    "    times = []\n",
    "    # t1, t2 = tbeg - interval_overlap, tbeg + interval_seconds + interval_overlap\n",
    "    t1, t2 = tbeg, tbeg + interval_seconds\n",
    "    while t2 <= tend:\n",
    "        times.append((t1, t2))\n",
    "        t1 = t1 + interval_overlap\n",
    "        t2 = t2 + interval_overlap\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4aec3-0bd7-417c-9798-498ededb3d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ---------------------------------------\n",
    "\n",
    "times = __get_time_intervals(config['tbeg'], config['tend'], interval_seconds=config['interval_seconds'], interval_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76d88c-0338-4b28-bb1f-c859c320a4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(times)\n",
    "\n",
    "baz_tangent = []\n",
    "baz_rayleigh = []\n",
    "baz_love = []\n",
    "\n",
    "baz_tangent_std = []\n",
    "baz_rayleigh_std = []\n",
    "baz_love_std = []\n",
    "\n",
    "baz_tangent_all = []\n",
    "baz_rayleigh_all = []\n",
    "baz_love_all = []\n",
    "baz_bf_all = []\n",
    "\n",
    "cc_tangent_all = []\n",
    "cc_rayleigh_all = []\n",
    "cc_love_all = []\n",
    "\n",
    "vel_love_max = []\n",
    "vel_love_std = []\n",
    "vel_rayleigh_max = []\n",
    "vel_rayleigh_std = []\n",
    "\n",
    "vel_rayleigh_all = []\n",
    "vel_love_all = []\n",
    "vel_bf_all = []\n",
    "\n",
    "times_relative = []\n",
    "times_all = []\n",
    "\n",
    "baz_bf = []\n",
    "baz_bf_std = []\n",
    "\n",
    "vel_bf = []\n",
    "time_bf = []\n",
    "\n",
    "ttime = []\n",
    "\n",
    "num_stations_used = []\n",
    "\n",
    "status = np.zeros((2, len(times)))\n",
    "\n",
    "nan_dummy = np.ones(90)*np.nan\n",
    "\n",
    "for _n, (t1, t2) in enumerate(tqdm(times)):\n",
    "\n",
    "    mltiU = __load_mlti(t1, t2, \"U\", archive_path)\n",
    "    mltiV = __load_mlti(t1, t2, \"V\", archive_path)\n",
    "    mltiZ = __load_mlti(t1, t2, \"Z\", archive_path)\n",
    "\n",
    "    try:\n",
    "        # inv1 = read_inventory(config['path_to_inv']+\"dataless/dataless.seed.BW_ROMY\")\n",
    "        # inv2 = read_inventory(config['path_to_inv']+\"dataless/dataless.seed.GR_FUR\")\n",
    "\n",
    "        inv1 = read_inventory(config['path_to_inv']+\"station_BW_ROMY.xml\")\n",
    "        inv2 = read_inventory(config['path_to_inv']+\"station_GR_FUR.xml\")\n",
    "\n",
    "        st1 =  __read_sds(config['path_to_sds1'], \"BW.ROMY.10.BJZ\", t1, t2);\n",
    "        st1 += __read_sds(config['path_to_sds1'], \"BW.ROMY..BJU\", t1, t2);\n",
    "        st1 += __read_sds(config['path_to_sds1'], \"BW.ROMY..BJV\", t1, t2);\n",
    "\n",
    "\n",
    "        st2 =  __read_sds(config['path_to_sds2'], \"GR.FUR..BHZ\", t1, t2);\n",
    "        st2 += __read_sds(config['path_to_sds2'], \"GR.FUR..BHN\", t1, t2);\n",
    "        st2 += __read_sds(config['path_to_sds2'], \"GR.FUR..BHE\", t1, t2);\n",
    "\n",
    "        st1.remove_sensitivity(inv1);\n",
    "        st2.remove_response(inv2, output=\"ACC\", water_level=60);\n",
    "\n",
    "        levels = {}\n",
    "        for tr in st1:\n",
    "            ring = tr.stats.channel[-1]\n",
    "            levels[ring] = np.percentile(abs(tr.data), 90)\n",
    "\n",
    "        st1 = __rotate_romy_ZUV_ZNE(st1, inv1, keep_z=True);\n",
    "\n",
    "    except:\n",
    "        print(f\" -> data loading failed !\")\n",
    "        pass\n",
    "\n",
    "## ---------------------------------------\n",
    "\n",
    "    try:\n",
    "        st1.detrend(\"linear\");\n",
    "        st2.detrend(\"linear\");\n",
    "\n",
    "        acc = st2.copy();\n",
    "        rot = st1.copy();\n",
    "\n",
    "        acc = acc.detrend(\"linear\");\n",
    "        acc = acc.taper(0.01);\n",
    "        acc = acc.filter(\"bandpass\", freqmin=config['fmin'], freqmax=config['fmax'], corners=8, zerophase=True);\n",
    "\n",
    "        rot = rot.detrend(\"linear\");\n",
    "        rot = rot.taper(0.01);\n",
    "        rot = rot.filter(\"bandpass\", freqmin=config['fmin'], freqmax=config['fmax'], corners=8, zerophase=True);\n",
    "\n",
    "    except:\n",
    "        print(f\" -> processing failed !\")\n",
    "        pass\n",
    "\n",
    "## ---------------------------------------\n",
    "\n",
    "    conf = {}\n",
    "\n",
    "    conf['eventtime'] = config['tbeg']\n",
    "\n",
    "    conf['tbeg'] = t1\n",
    "    conf['tend'] = t2\n",
    "\n",
    "    conf['station_longitude'] = 11.275501\n",
    "    conf['station_latitude']  = 48.162941\n",
    "\n",
    "    ## specify window length for baz estimation in seconds\n",
    "    conf['win_length_sec'] = config['window_length_sec']\n",
    "\n",
    "    ## define an overlap for the windows in percent (50 -> 50%)\n",
    "    conf['overlap'] = config['window_overlap']\n",
    "\n",
    "    ## specify steps for degrees of baz\n",
    "    conf['step'] = 1\n",
    "\n",
    "    conf['path_to_figs'] = config['path_to_figures']\n",
    "\n",
    "    conf['cc_thres'] = config['cc_threshold']\n",
    "\n",
    "    try:\n",
    "        print(f\" computing backazimuth estimation\")\n",
    "        out = __compute_backazimuth_and_velocity_noise(conf, rot, acc, config['fmin'], config['fmax'], plot=False, save=True);\n",
    "\n",
    "\n",
    "        if mltiU.size > config['num_mlti'] or mltiV.size > config['num_mlti'] or levels[\"U\"] > 1e-6 or levels[\"V\"] > 1e-6:\n",
    "            print(\" -> to many MLTI (horizontal)\")\n",
    "\n",
    "            out['baz_tangent_max'], out['baz_tangent_std'], out['baz_tangent_all'] = np.nan, np.nan, nan_dummy\n",
    "\n",
    "            out['baz_rayleigh_max'], out['baz_rayleigh_std'], out['baz_rayleigh_all'] = np.nan, np.nan, nan_dummy\n",
    "\n",
    "            out['vel_rayleigh_max'], out['vel_rayleigh_std'], out['vel_rayleigh_all'] = np.nan, np.nan, nan_dummy\n",
    "\n",
    "            out['cc_rayleigh_all'], out['cc_tangent_all'] = nan_dummy, nan_dummy\n",
    "\n",
    "        if mltiZ.size > config['num_mlti'] or mltiZ.size > config['num_mlti'] or levels[\"Z\"] > 1e-6:\n",
    "            print(\" -> to many MLTI (vertical)\")\n",
    "\n",
    "            out['baz_love_max'], out['baz_love_std'], out['baz_love_all'] = np.nan, np.nan, nan_dummy\n",
    "\n",
    "            out['vel_love_max'], out['vel_love_std'], out['vel_love_all'] = np.nan, np.nan, nan_dummy\n",
    "\n",
    "            out['cc_love_all'] = nan_dummy\n",
    "\n",
    "        baz_tangent.append(out['baz_tangent_max'])\n",
    "        baz_tangent_std.append(out['baz_tangent_std'])\n",
    "        baz_tangent_all.append(out['baz_tangent_all'])\n",
    "\n",
    "        baz_rayleigh.append(out['baz_rayleigh_max'])\n",
    "        baz_rayleigh_std.append(out['baz_rayleigh_std'])\n",
    "        baz_rayleigh_all.append(out['baz_rayleigh_all'])\n",
    "\n",
    "        vel_rayleigh_max.append(out['vel_rayleigh_max'])\n",
    "        vel_rayleigh_std.append(out['vel_rayleigh_std'])\n",
    "        vel_rayleigh_all.append(out['vel_rayleigh_all'])\n",
    "\n",
    "        cc_rayleigh_all.append(out['cc_rayleigh_all'])\n",
    "        cc_tangent_all.append(out['cc_tangent_all'])\n",
    "\n",
    "        baz_love.append(out['baz_love_max'])\n",
    "        baz_love_std.append(out['baz_love_std'])\n",
    "\n",
    "        baz_love_all.append(out['baz_love_all'])\n",
    "\n",
    "        vel_love_max.append(out['vel_love_max'])\n",
    "        vel_love_std.append(out['vel_love_std'])\n",
    "        vel_love_all.append(out['vel_love_all'])\n",
    "\n",
    "        cc_love_all.append(out['cc_love_all'])\n",
    "\n",
    "        times_relative.append(out['times_relative'])\n",
    "        times_absolute = [t1 + float(_t) for _t in out['times_relative']]\n",
    "        times_all.append(times_absolute)\n",
    "\n",
    "        ttime.append(t1)\n",
    "\n",
    "        ## store plot\n",
    "        t1_t2 = f\"{t1.date}_{str(t1.time).split('.')[0]}_{t2.date}_{str(t2.time).split('.')[0]}\"\n",
    "        out['fig3'].savefig(config['path_to_figures']+f\"VC_BAZ_{t1_t2}.png\", format=\"png\", dpi=150, bbox_inches='tight')\n",
    "        print(f\" -> stored: {config['path_to_figures']}VC_BAZ_{t1_t2}.png\")\n",
    "\n",
    "        ## change status to success\n",
    "        status[0, _n] = 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\" -> baz computation failed!\")\n",
    "\n",
    "        baz_tangent.append(np.nan)\n",
    "        baz_rayleigh.append(np.nan)\n",
    "        baz_love.append(np.nan)\n",
    "\n",
    "        baz_tangent_std.append(np.nan)\n",
    "        baz_rayleigh_std.append(np.nan)\n",
    "        baz_love_std.append(np.nan)\n",
    "\n",
    "        vel_love_max.append(np.nan)\n",
    "        vel_love_std.append(np.nan)\n",
    "        vel_rayleigh_max.append(np.nan)\n",
    "        vel_rayleigh_std.append(np.nan)\n",
    "\n",
    "        baz_tangent_all.append(nan_dummy)\n",
    "        baz_rayleigh_all.append(nan_dummy)\n",
    "        baz_love_all.append(nan_dummy)\n",
    "\n",
    "        cc_tangent_all.append(nan_dummy)\n",
    "        cc_rayleigh_all.append(nan_dummy)\n",
    "        cc_love_all.append(nan_dummy)\n",
    "\n",
    "        vel_rayleigh_all.append(nan_dummy)\n",
    "        vel_love_all.append(nan_dummy)\n",
    "\n",
    "        times_relative.append(nan_dummy)\n",
    "        times_all.append(nan_dummy)\n",
    "\n",
    "        ttime.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        print(f\" computing beamforming\")\n",
    "        out_bf = __compute_beamforming_ROMY(\n",
    "                                            conf['tbeg'],\n",
    "                                            conf['tend'],\n",
    "                                            submask=None,\n",
    "                                            fmin=config['fmin'],\n",
    "                                            fmax=config['fmax'],\n",
    "                                            component=\"Z\",\n",
    "                                            bandpass=True,\n",
    "                                            plot=False\n",
    "                                           )\n",
    "\n",
    "        baz_bf.append(out_bf['baz_bf_max'])\n",
    "        baz_bf_std.append(out_bf['baz_bf_std'])\n",
    "        vel_bf_all.append(out_bf['slow'])\n",
    "        baz_bf_all.append(out_bf['baz'])\n",
    "\n",
    "        num_stations_used.append(out_bf['num_stations_used'])\n",
    "\n",
    "        times_abs = np.array([t1 + int(_t) for _t in out_bf['time']])\n",
    "        time_bf.append(times_abs)\n",
    "\n",
    "        ## change status to success\n",
    "        status[1, _n] = 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\" -> beamforming computation failed!\")\n",
    "\n",
    "        baz_bf.append(np.nan)\n",
    "        baz_bf_std.append(np.nan)\n",
    "        vel_bf_all.append(np.nan)\n",
    "        time_bf.append(np.nan)\n",
    "        baz_bf_all.append(np.nan)\n",
    "\n",
    "\n",
    "## ---------------------------------------\n",
    "def __to_array(arr_in):\n",
    "    arr_out = []\n",
    "    for _t in arr_in:\n",
    "        _t = np.array(_t)\n",
    "        if _t.size > 1:\n",
    "            for _x in _t:\n",
    "                arr_out.append(_x)\n",
    "        elif _t.size == 1:\n",
    "            arr_out.append(np.nan)\n",
    "\n",
    "\n",
    "    return np.array(arr_out)\n",
    "\n",
    "\n",
    "## prepare output dictionary\n",
    "output = {}\n",
    "\n",
    "output['time'] = np.array(ttime)\n",
    "output['baz_tangent'] = np.array(baz_tangent)\n",
    "output['baz_rayleigh'] = np.array(baz_rayleigh)\n",
    "output['baz_love'] = np.array(baz_love)\n",
    "output['baz_tangent_std'] = np.array(baz_tangent_std)\n",
    "output['baz_rayleigh_std'] = np.array(baz_rayleigh_std)\n",
    "output['baz_love_std'] = np.array(baz_love_std)\n",
    "output['baz_bf'] = np.array(baz_bf)\n",
    "output['baz_bf_std'] = np.array(baz_bf_std)\n",
    "\n",
    "output['vel_bf'] = np.array(vel_bf)\n",
    "output['vel_love_max'] = np.array(vel_love_max)\n",
    "output['vel_rayleigh_max'] = np.array(vel_rayleigh_max)\n",
    "\n",
    "output['vel_love_std'] = np.array(vel_love_std)\n",
    "output['vel_rayleigh_std'] = np.array(vel_rayleigh_std)\n",
    "\n",
    "output['num_stations_used'] = num_stations_used\n",
    "\n",
    "\n",
    "## store output to file\n",
    "print(f\"-> store: {config['path_to_data_out']}statistics/VC_BAZ_{config['tbeg'].date}.pkl\")\n",
    "# __save_to_pickle(output, config['path_to_data_out']+\"statistics/\", f\"VC_BAZ_{config['tbeg'].date}\")\n",
    "\n",
    "\n",
    "## prepare output dictionary\n",
    "output1 = {}\n",
    "\n",
    "output1['time'] = __to_array(times_all)\n",
    "output1['time_bf'] = __to_array(time_bf)\n",
    "\n",
    "output1['baz_tangent_all'] = __to_array(baz_tangent_all)\n",
    "output1['baz_rayleigh_all'] = __to_array(baz_rayleigh_all)\n",
    "output1['baz_love_all'] = __to_array(baz_love_all)\n",
    "output1['baz_bf_all'] = __to_array(baz_bf_all)\n",
    "\n",
    "output1['cc_tangent_all'] = __to_array(cc_tangent_all)\n",
    "output1['cc_rayleigh_all'] = __to_array(cc_rayleigh_all)\n",
    "output1['cc_love_all'] = __to_array(cc_love_all)\n",
    "\n",
    "output1['vel_rayleigh_all'] = __to_array(vel_rayleigh_all)\n",
    "output1['vel_love_all'] = __to_array(vel_love_all)\n",
    "output1['vel_bf_all'] = __to_array(vel_bf_all)\n",
    "\n",
    "\n",
    "\n",
    "## store output to file\n",
    "print(f\"-> store: {config['path_to_data_out']}all/VC_BAZ_{config['tbeg'].date}_all.pkl\")\n",
    "# __save_to_pickle(output1, config['path_to_data_out']+\"all/\", f\"VC_BAZ_{config['tbeg'].date}_all\")\n",
    "\n",
    "\n",
    "## status plot\n",
    "import matplotlib.colors\n",
    "cmap = matplotlib.colors.ListedColormap(['red', 'green'])\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "c = plt.pcolormesh(np.arange(0, status.shape[1]), [\"BAZ\", \"BF\"], status, edgecolors='k', linewidths=1, cmap=cmap)\n",
    "\n",
    "\n",
    "fig.savefig(config['path_to_figures']+f\"status/VC_BAZ_{config['tbeg'].date}_status.png\", format=\"png\", dpi=100, bbox_inches='tight')\n",
    "print(f\" -> stored: {config['path_to_figures']}status/VC_BAZ_{config['tbeg'].date}.png\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "## End of File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43524c8f-7e43-414f-a368-49405a5b5d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f397d98-a9c9-4a51-abfe-2e952761cd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
