{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Filename: main.py\n",
    "#  Purpose: Main scripts to do the processing of the data\n",
    "#           uses preprocessed data to calculate estimations of\n",
    "#           phase velocities and backazimuths, write results\n",
    "#           plotting figures, writing results to a file. Uses\n",
    "#           the module \"rolode\" which can be found in the file \"rolode.py\"\n",
    "#   Author: Alexander Wietek\n",
    "#   Email:  alexander.wietek@mytum.de\n",
    "#\n",
    "# Copyright (C) 2013 Alexander Wietek\n",
    "# -------------------------------------------------------------------------\n",
    "#\n",
    "#  I modify the main program such that we do the preprocessing via SeisHub\n",
    "#  and use the results directly\n",
    "#\n",
    "#  Author: Joachim Wassermann (2013)\n",
    "# -------------------------------------------------------------------------\n",
    "#\n",
    "#  I simply prettified the code and cleared some bugs for the current python3\n",
    "#  version in rolode2.py\n",
    "#\n",
    "#  Author: Andreas Brotzer (2024)\n",
    "# -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import rochade_v3 as rochade\n",
    "import pickle\n",
    "\n",
    "from obspy.signal import array_analysis as AA\n",
    "from obspy import read, read_inventory, UTCDateTime\n",
    "from obspy.clients.filesystem.sds import Client\n",
    "from obspy.core import AttribDict\n",
    "from obspy.signal.rotate import rotate2zne\n",
    "\n",
    "#from obspy.clients.fdsn import Client\n",
    "#import gaussianfilt\n",
    "#import tilt\n",
    "# import matplotlib\n",
    "\n",
    "#matplotlib.use('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.get_time_intervals import __get_time_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def notch(trace, f_cut):\n",
    "    wn = f_cut/trace.stats.sampling_rate\n",
    "    r = 0.99\n",
    "    B, A = np.zeros(3), np.zeros(3)\n",
    "    A[0], A[1], A[2] = 1.0, -2.0*r*np.cos(2*np.pi*wn), r*r\n",
    "    B[0], B[1], B[2] = 1.0, -2.0*np.cos(2*np.pi*wn), 1.0\n",
    "    trace.data = sp.signal.lfilter(B, A, trace.data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __read_from_sds(path_to_archive, seed, tbeg, tend, data_format=\"MSEED\"):\n",
    "    \"\"\"\n",
    "    VARIABLES:\n",
    "     - path_to_archive\n",
    "     - seed\n",
    "     - tbeg, tend\n",
    "     - data_format\n",
    "\n",
    "    DEPENDENCIES:\n",
    "     - from obspy.core import UTCDateTime\n",
    "     - from obspy.clients.filesystem.sds import Client\n",
    "\n",
    "    OUTPUT:\n",
    "     - stream\n",
    "\n",
    "    EXAMPLE:\n",
    "    >>> st = __read_sds(path_to_archive, seed, tbeg, tend, data_format=\"MSEED\")\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    from obspy.core import UTCDateTime, Stream\n",
    "    from obspy.clients.filesystem.sds import Client\n",
    "\n",
    "    tbeg, tend = UTCDateTime(tbeg), UTCDateTime(tend)\n",
    "\n",
    "    if not os.path.exists(path_to_archive):\n",
    "        print(f\" -> {path_to_archive} does not exist!\")\n",
    "        return\n",
    "\n",
    "    ## separate seed id\n",
    "    net, sta, loc, cha = seed.split(\".\")\n",
    "\n",
    "    ## define SDS client\n",
    "    client = Client(path_to_archive, sds_type='D', format=data_format)\n",
    "\n",
    "    ## read waveforms\n",
    "    try:\n",
    "        st = client.get_waveforms(net, sta, loc, cha, tbeg, tend, merge=-1)\n",
    "    except:\n",
    "        print(f\" -> failed to obtain waveforms!\")\n",
    "        st = Stream()\n",
    "\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __postprocessing(config, wave_type=\"love\"):\n",
    "\n",
    "    if wave_type.lower() == \"love\":\n",
    "\n",
    "        # check if love waves were selected and processed\n",
    "        if not config['love_waves']:\n",
    "            print(f\" Love waves not set in configurations\")\n",
    "            return\n",
    "        else:\n",
    "            # define path to save plots and data\n",
    "            save_path = config['save_path_love']\n",
    "\n",
    "            # specify windows file\n",
    "            windows_file = \"windows_l.pkl\"\n",
    "\n",
    "    elif wave_type.lower() == \"rayleigh1\":\n",
    "\n",
    "        # check if love waves were selected and processed\n",
    "        if not config['rayleigh1_waves']:\n",
    "            print(f\" Rayleigh 1 waves not set in configurations\")\n",
    "            return\n",
    "        else:\n",
    "            # define path to save plots and data\n",
    "            save_path = config['save_path_rayleigh1']\n",
    "\n",
    "            # specify windows file\n",
    "            windows_file = \"windows_r.pkl\"\n",
    "\n",
    "    elif wave_type.lower() == \"rayleigh2\":\n",
    "\n",
    "        # check if love waves were selected and processed\n",
    "        if not config['rayleigh2_waves']:\n",
    "            print(f\" Rayleigh 2 waves not set in configurations\")\n",
    "            return\n",
    "        else:\n",
    "            # define path to save plots and data\n",
    "            save_path = config['save_path_rayleigh2']\n",
    "\n",
    "            # specify windows file\n",
    "            windows_file = \"windows_r2.pkl\"\n",
    "\n",
    "    # load data\n",
    "    print(f\"-> load data: {save_path}{windows_file}\")\n",
    "    with open(save_path+windows_file, \"rb\") as winfile:\n",
    "        windows = pickle.load(winfile)\n",
    "\n",
    "    if config['verbose']:\n",
    "        print(f\"-> loaded {winfile}\")\n",
    "\n",
    "    # set windows interval\n",
    "    windows.wineval = True\n",
    "\n",
    "    # Calculate means, modes, medians, standard deviations, and set weights\n",
    "    windows.set_weights(method=config['wghtmethod'], exp=config['exponent'])\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    try:\n",
    "        windows.calc_mean_std()\n",
    "    except:\n",
    "        print(f\"-> failed to calculate mean\")\n",
    "        pass\n",
    "\n",
    "    # Calculate KDE for mode\n",
    "    try:\n",
    "        windows.calc_kde_mode()\n",
    "    except:\n",
    "        print(f\"-> failed to calculate kde\")\n",
    "        pass\n",
    "\n",
    "    # Calculate median\n",
    "    try:\n",
    "        windows.calc_median()\n",
    "    except:\n",
    "        print(f\"-> failed to calculate median\")\n",
    "        pass\n",
    "\n",
    "    # Plot all the histograms for the individual frequencies\n",
    "    try:\n",
    "        windows.plot_histograms(savepath=save_path)\n",
    "    except:\n",
    "        print(f\"-> failed to plot histograms\")\n",
    "        pass\n",
    "\n",
    "    # Plot the slowness and backazimuth distribution for all frequencies\n",
    "    try:\n",
    "        windows.plot_polar(savepath=save_path)\n",
    "    except:\n",
    "        print(f\"-> failed to plot slowness and backazimuth distribution\")\n",
    "        pass\n",
    "\n",
    "    # Plot the dispersion curves with errorbars\n",
    "    try:\n",
    "        windows.plot_errorbar(savepath=save_path)\n",
    "    except:\n",
    "        print(f\"-> failed to plot dispersion curves with errorbars\")\n",
    "        pass\n",
    "\n",
    "    # Write results to a file\n",
    "    try:\n",
    "        windows.writeresults(savepath=save_path)\n",
    "    except:\n",
    "        print(f\"-> failed to write results\")\n",
    "        pass\n",
    "\n",
    "    print(f\"\\n Done for {wave_type.upper()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Set configuration parameters\n",
    "###################################################################\n",
    "\n",
    "config = {}\n",
    "\n",
    "# Data structure has to be:\n",
    "# /<STATIONNAME>/<YEAR>/<NETWORK>/<STATION>/<COMPONENT>.D/<mseed_data_files>\n",
    "#\n",
    "# Example: /FINM1/2023/XX/FINM1/HHZ.D/XX.FINM1..HHZ.D.2023.041\n",
    "\n",
    "# config['client'] = Client('/home/andbro/kilauea-data/VelocityChanges/data/VROMY/sds/', sds_type='D', format='MSEED',)\n",
    "\n",
    "config['path_to_sds'] = \"/home/andbro/kilauea-data/VelocityChanges/data/VROMY/sds/\"\n",
    "# config['path_to_sds'] = \"/import/kilauea-data/VelocityChanges/data/VROMY/sds/\"\n",
    "\n",
    "# specify directory for output data files\n",
    "config['path_to_outdata'] = \"/home/andbro/kilauea-data/VelocityChanges/data/VROMY/\"\n",
    "# config['path_to_outdata'] = \"/import/kilauea-data/VelocityChanges/data/VROMY/\"\n",
    "\n",
    "# specify response information file\n",
    "config['path_to_inv_rot'] = '/home/andbro/Documents/ROMY/stationxml_ringlaser/station_GR_FUR.xml' #seismometer\n",
    "config['path_to_inv_tra'] = '/home/andbro/Documents/ROMY/stationxml_ringlaser/station_BW_ROMY.xml' #blueSeis\n",
    "# config['path_to_inv_rot'] = '/home/brotzer/Documents/ROMY/stationxml_ringlaser/station_GR_FUR.xml' #seismometer\n",
    "# config['path_to_inv_tra'] = '/home/brotzer/Documents/ROMY/stationxml_ringlaser/station_BW_ROMY.xml' #blueSeis\n",
    "\n",
    "# client2 = Client(\"IRIS\")\n",
    "config['tra_seed'] = 'XX.VROMY..BH*' # seed of translational data\n",
    "config['rot_seed'] = 'XX.VROMY..BJ*' # seed of rotational data\n",
    "\n",
    "# specify velocity limits\n",
    "config['vmin'] = 50\n",
    "config['vmax'] = 4000\n",
    "\n",
    "# define start and end time of your data\n",
    "config['tbeg'] = UTCDateTime(\"2024-02-25T00:00:00\")\n",
    "config['tend'] = UTCDateTime(\"2024-02-26T00:00:00\")\n",
    "\n",
    "# config['tbeg'] = UTCDateTime(\"2023-12-25T12:00:00\")\n",
    "# config['tend'] = UTCDateTime(\"2023-12-26T00:00:00\")\n",
    "\n",
    "# morocco quake\n",
    "# config['tbeg'] = UTCDateTime(\"2023-09-08T22:00:00\")\n",
    "# config['tend'] = UTCDateTime(\"2023-09-09T01:00:00\")\n",
    "\n",
    "# montenegro quake\n",
    "config['tbeg'] = UTCDateTime(\"2024-03-14 03:00\")\n",
    "config['tend'] = UTCDateTime(\"2024-03-14 04:00\")\n",
    "\n",
    "\n",
    "config['interval_seconds'] = 600 # seconds\n",
    "config['interval_overlap'] = 0 # seconds\n",
    "\n",
    "\n",
    "# specify translational output\n",
    "config['tra_output'] = \"VEL\"\n",
    "\n",
    "# select methods to compute\n",
    "config['love_waves'] = True\n",
    "config['rayleigh1_waves'] = True\n",
    "config['rayleigh2_waves'] = False\n",
    "\n",
    "config['periods_per_window'] = 10. # 8\n",
    "\n",
    "# Specify frequency bands here\n",
    "config['f_min'] = 0.05 # smallest frequency to process\n",
    "config['f_max'] = 8.0 # highest frequency to process\n",
    "config['f_space'] = 0.1 # frequency steps\n",
    "config['bandwidth'] = 0.1  # Bandwidth of bandpass filter\n",
    "\n",
    "\n",
    "# Set method for weighing the time windows. Can be one of\n",
    "#    \"standard\" ... wght = np.sum(rotrate**2)/(err)\n",
    "#    \"normed\"   ... wght = (1 - err/np.sum(rotrate**2)^exp)\n",
    "#    \"uniform\"  ... wght = 1\n",
    "config['wghtmethod'] = \"normed\"\n",
    "\n",
    "# specify mask value\n",
    "config['mvalue'] = 3e-10 # mvalue=-1\n",
    "\n",
    "# exponent of normed weights\n",
    "config['exponent'] = 0.3\n",
    "# exp = 0.3 # exponent of normed weights\n",
    "\n",
    "# common sampling rate to resample the data\n",
    "config['sampling_rate'] = 20.\n",
    "\n",
    "\n",
    "config['body'] = False\n",
    "\n",
    "# set trigger\n",
    "config['detrigger'] = False\n",
    "\n",
    "# parameters for trigger, if detrigger = True\n",
    "tsta = 1.5\n",
    "tlta = 10.\n",
    "thres1 = 2.8\n",
    "thres2 = 0.5\n",
    "pre = 2.\n",
    "post = 10.\n",
    "\n",
    "config['trigger_params'] = {\"sta\": tsta,\"lta\": tlta,\"thres_1\":thres1,\"thres_2\": thres2,\"pre_t\":pre,\"post_t\":post}\n",
    "\n",
    "# set flag for first iteration\n",
    "config['firstRun'] = True\n",
    "\n",
    "# set if details are printed\n",
    "config['verbose'] = False\n",
    "\n",
    "# # store configurations\n",
    "# with open(config['path_to_sds']+'config.yml', 'w') as outfile:\n",
    "#     yaml.dump(config, outfile, default_flow_style=False, sort_keys=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.get_octave_bands import __get_octave_bands\n",
    "\n",
    "f_lower, f_higher, f_center = __get_octave_bands(config['f_min'], config['f_max'], faction_of_octave=2, plot=False)\n",
    "\n",
    "# cut first and last\n",
    "f_lower, f_higher = f_lower[1:-1], f_higher[1:-1]\n",
    "\n",
    "# reverse sorting\n",
    "f_lower, f_higher = f_lower[::-1], f_higher[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1d88229a414d2cb8534bdaed9e08ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 136\u001b[0m\n\u001b[1;32m    133\u001b[0m rot \u001b[38;5;241m=\u001b[39m rot\u001b[38;5;241m.\u001b[39mtrim(t1, t2)\n\u001b[1;32m    134\u001b[0m tra \u001b[38;5;241m=\u001b[39m tra\u001b[38;5;241m.\u001b[39mtrim(t1, t2)\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtra\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mendtime \u001b[38;5;241m>\u001b[39m rot[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mendtime:\n\u001b[1;32m    137\u001b[0m     rot \u001b[38;5;241m=\u001b[39m rot\u001b[38;5;241m.\u001b[39mtrim(t1\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, rot[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mendtime)\n\u001b[1;32m    138\u001b[0m     tra \u001b[38;5;241m=\u001b[39m tra\u001b[38;5;241m.\u001b[39mtrim(t1\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, rot[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mendtime)\n",
      "File \u001b[0;32m~/anaconda3/envs/obs2/lib/python3.10/site-packages/obspy/core/stream.py:643\u001b[0m, in \u001b[0;36mStream.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraces\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(index))\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# pre-calculate time intervals for loop based on starttime, endtime and specified time intervals\n",
    "times = __get_time_intervals(config['tbeg'], config['tend'], config['interval_seconds'], config['interval_overlap'])\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# get the relevant information\n",
    "for t1, t2 in tqdm(times):\n",
    "\n",
    "    tsz = []\n",
    "    tsn = []\n",
    "    tse = []\n",
    "    coo = []\n",
    "    first = True\n",
    "\n",
    "\n",
    "    # ____________________________________________\n",
    "    # load translational data\n",
    "\n",
    "    net, sta, loc, cha = config['tra_seed'].split(\".\")\n",
    "\n",
    "    # read translational data\n",
    "    try:\n",
    "        try:\n",
    "            tra = __read_from_sds(config['path_to_sds'], config['tra_seed'], t1-1, t2+1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            tra = read(config['path_to_sds']+f\"{config['tbeg'].year}/{net}/{sta}/{cha}.D/*\",\n",
    "                       starttime=t1-1,\n",
    "                       endtime=t2+1,\n",
    "                      )\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if config['verbose']:\n",
    "        print(tra)\n",
    "\n",
    "    # tra.plot(equal_scale=False);\n",
    "\n",
    "    # ____________________________________________\n",
    "    # load rotational data\n",
    "\n",
    "    net, sta, loc, cha = config['rot_seed'].split(\".\")\n",
    "\n",
    "    # read rotational data\n",
    "    try:\n",
    "        try:\n",
    "            rot = __read_from_sds(config['path_to_sds'], config['rot_seed'], t1-1, t2+1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            rot = read(config['path_to_sds']+f\"{config['tbeg'].year}/{net}/{sta}/{cha}.D/*\",\n",
    "                       starttime=t1-1,\n",
    "                       endtime=t2+1,\n",
    "                       )\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if config['verbose']:\n",
    "        print(rot)\n",
    "\n",
    "    # rot.plot(equal_scale=False);\n",
    "\n",
    "\n",
    "    # ____________________________________________\n",
    "    # pre-process data\n",
    "\n",
    "    rot_inv = read_inventory(config['path_to_inv_rot'])\n",
    "    tra_inv = read_inventory(config['path_to_inv_tra'])\n",
    "\n",
    "    # sort stream\n",
    "    tra = tra.sort()\n",
    "    tra = tra.reverse()\n",
    "\n",
    "    # remove trend\n",
    "    tra = tra.detrend(\"linear\")\n",
    "\n",
    "    # processing stream\n",
    "    tra = tra.merge(method=1, fill_value='latest')\n",
    "    # tra = tra.attach_response(tra_inv)\n",
    "    # tra = tra.resample(sampling_rate=df, no_filter=False)\n",
    "    # tra = tra.rotate(method='->ZNE', inventory=inv, components=['ZNE'])\n",
    "\n",
    "    tra = tra.detrend(\"linear\")\n",
    "\n",
    "    tra = tra.filter('highpass', freq=0.005, zerophase=True)\n",
    "\n",
    "    # tra =tra.remove_response(config['inv_tra'], water_level=10, output=config['tra_output'])\n",
    "\n",
    "    tra = tra.detrend(\"linear\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    rot = rot.sort()\n",
    "    rot = rot.reverse()\n",
    "\n",
    "    rot = rot.merge(method=1, fill_value='latest')\n",
    "    # rot = rot.attach_response(rot_inv)\n",
    "    # rot = rot.rotate(method='->ZNE', inventory=inv2, components=['321'])\n",
    "\n",
    "    # print(\"Offset vertical: %f\"%(rot.select(component=\"*Z\")[0].data.mean()) )\n",
    "    # print(\"Offset East:     %f\"%(rot.select(component=\"*E\")[0].data.mean()) )\n",
    "    # print(\"Offset North:    %f\"%(rot.select(component=\"*N\")[0].data.mean()) )\n",
    "\n",
    "    # rot = rot.remove_sensitivity(config['inv_rot'])\n",
    "\n",
    "    rot = rot.detrend(\"linear\")\n",
    "\n",
    "    rot = rot.filter('highpass', freq=0.005, zerophase=True)\n",
    "\n",
    "    # rot = rot.resample(sampling_rate=df,no_filter=False)\n",
    "    # rot = rot.interpolate(sampling_rate=df,starttime=start+1)\n",
    "\n",
    "    rot = rot.sort()\n",
    "    rot = rot.reverse()\n",
    "\n",
    "    rot = rot.detrend(\"linear\")\n",
    "\n",
    "    # rot.plot(equal_scale=False);\n",
    "\n",
    "\n",
    "###############################\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "###############################\n",
    "\n",
    "    rot = rot.trim(t1, t2)\n",
    "    tra = tra.trim(t1, t2)\n",
    "\n",
    "    if tra[0].stats.endtime > rot[0].stats.endtime:\n",
    "        rot = rot.trim(t1+1, rot[0].stats.endtime)\n",
    "        tra = tra.trim(t1+1, rot[0].stats.endtime)\n",
    "    else:\n",
    "        rot = rot.trim(t1+1, tra[0].stats.endtime)\n",
    "        tra = tra.trim(t1+1, tra[0].stats.endtime)\n",
    "\n",
    "\n",
    "# in the folowing we are using horizontal components of velocity and acceleration\n",
    "# consequently we have to correct them from local tilt effects before using it\n",
    "# this is done via an estimation of the transferfunction\n",
    "\n",
    "    #sz1.select(component=\"N\")[0].data = tilt.tiltcorrect(sz1.select(component=\"N\")[0],rots.select(component=\"E\")[0])\n",
    "    #sz1.select(component=\"E\")[0].data = tilt.tiltcorrect(sz1.select(component=\"E\")[0],rots.select(component=\"N\")[0])\n",
    "\n",
    "    acc = tra.copy()\n",
    "    acc = acc.differentiate()\n",
    "\n",
    "    if config['verbose']:\n",
    "        print(acc)\n",
    "\n",
    "    # acc.plot(equal_scale=False);\n",
    "\n",
    "    print(rot)\n",
    "    print(tra)\n",
    "    print(acc)\n",
    "\n",
    "###################################################################\n",
    "# Start of calculations ...\n",
    "###################################################################\n",
    "\n",
    "    # and the parameter periods_per_window\n",
    "    windows_l = rochade.rolode_estimator(f_lower, f_higher,\n",
    "                                         config['periods_per_window'],\n",
    "                                         config['vmin'],\n",
    "                                         config['vmax'],\n",
    "                                         config['trigger_params'],\n",
    "                                        )\n",
    "    if config['verbose']:\n",
    "        windows_l.printlog()\n",
    "\n",
    "    rot = rot.copy()\n",
    "\n",
    "    #acc.trim(nstart,nend)\n",
    "    #sz1.trim(nstart,nend)\n",
    "    #rot.trim(nstart,nend)\n",
    "\n",
    "\n",
    "    name = f\"{sta}_{config['tbeg'].date}_{config['tend'].date}\"\n",
    "    config['filename'] = name\n",
    "\n",
    "####################################################################\n",
    "# LOVE WAVES\n",
    "# Main processing step, window_estimation takes the\n",
    "# vertical rotation rate, north acceleration and east acceleration\n",
    "# and calculates the estimations\n",
    "# LOVE WAVES\n",
    "####################################################################\n",
    "\n",
    "    if config['love_waves']:\n",
    "\n",
    "        if config['body']:\n",
    "\n",
    "            irot = rot.copy()\n",
    "            irot.integrate()\n",
    "            print(irot)\n",
    "            windows_l.window_estimation_love(irot[0],\n",
    "                                             tra[1],\n",
    "                                             tra[2],\n",
    "                                             mask_value=config['mvalue'],\n",
    "                                             body=config['body'],\n",
    "                                             trigger=config['detrigger'],\n",
    "                                             verbose=config['verbose'],\n",
    "                                            )\n",
    "\n",
    "            # define path where to save output:\n",
    "            save_path_love = config['path_to_outdata']+f\"ROLODE/VROMY_HH/{name}-SV/\"\n",
    "\n",
    "        else:\n",
    "            windows_l.window_estimation_love(rot.select(component=\"Z\")[0],\n",
    "                                             acc.select(component=\"N\")[0],\n",
    "                                             acc.select(component=\"E\")[0],\n",
    "                                             mask_value=config['mvalue'],\n",
    "                                             trigger=config['detrigger'],\n",
    "                                             verbose=config['verbose'],\n",
    "                                            )\n",
    "\n",
    "            save_path_love = config['path_to_outdata']+f\"ROLODE/VROMY_HH/{name}-Love/\"\n",
    "\n",
    "        # createt directories\n",
    "        if not os.path.exists(save_path_love):\n",
    "            os.makedirs(save_path_love)\n",
    "\n",
    "        # write to file and log\n",
    "        windows_l.write(save_path_love+\"windows_l.pkl\", config['firstRun'])\n",
    "        windows_l.writelog(save_path_love+\"info_l.log\", config['firstRun'])\n",
    "\n",
    "        config['save_path_love'] = save_path_love\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# RAYLEIGH WAVES\n",
    "# Main processing step, window_estimation takes the\n",
    "# vertical acceleration, north and east rotation rate\n",
    "# and calculates the estimations\n",
    "# RAYLEIGH WAVES\n",
    "###################################################################\n",
    "\n",
    "    if config['rayleigh1_waves']:\n",
    "\n",
    "        windows_r = rochade.rolode_estimator(f_lower, f_higher,\n",
    "                                             config['periods_per_window'],\n",
    "                                             config['vmin'],\n",
    "                                             config['vmax'],\n",
    "                                             config['trigger_params'],\n",
    "                                            )\n",
    "        if config['verbose']:\n",
    "            windows_r.printlog()\n",
    "\n",
    "        if config['body']:\n",
    "            irot = rot.copy()\n",
    "            irot.integrate()\n",
    "\n",
    "            windows_r.window_estimation_rayleigh(tra[0],\n",
    "                                                 irot[1],\n",
    "                                                 irot[2],\n",
    "                                                 mask_value=config['mvalue'],\n",
    "                                                 body=config['body'],\n",
    "                                                 trigger=config['detrigger'],\n",
    "                                                 verbose=config['verbose'],\n",
    "                                                )\n",
    "\n",
    "            save_path_ray1 = config['path_to_outdata']+f\"ROLODE/VROMY_HH/{name}-SV1/\"\n",
    "        else:\n",
    "\n",
    "            windows_r.window_estimation_rayleigh(acc.select(component=\"Z\")[0],\n",
    "                                                 rot.select(component=\"N\")[0],\n",
    "                                                 rot.select(component=\"E\")[0],\n",
    "                                                 mask_value=config['mvalue'],\n",
    "                                                 trigger=config['detrigger'],\n",
    "                                                 verbose=config['verbose'],\n",
    "                                                )\n",
    "\n",
    "            save_path_ray1 = config['path_to_outdata']+f\"ROLODE/VROMY_HH/{name}-Rayleigh/\"\n",
    "\n",
    "        # createt directories\n",
    "        if not os.path.exists(save_path_ray1):\n",
    "            os.makedirs(save_path_ray1)\n",
    "\n",
    "        # write to file and log\n",
    "        windows_r.write(save_path_ray1+\"windows_r.pkl\", config['firstRun'])\n",
    "        windows_r.writelog(save_path_ray1+\"info_r.log\", config['firstRun'])\n",
    "\n",
    "        config['save_path_rayleigh1'] = save_path_ray1\n",
    "\n",
    "##################################################################\n",
    "# RAYLEIGH WAVES\n",
    "# Main processing step, window_estimation takes the\n",
    "# vertical acceleration, north and east rotation rate\n",
    "# and calculates the estimations\n",
    "# RAYLEIGH WAVES\n",
    "###################################################################\n",
    "\n",
    "    if config['rayleigh2_waves']:\n",
    "\n",
    "        windows_r2 = rochade.rolode_estimator(f_lower, f_higher,\n",
    "                                              config['periods_per_window'],\n",
    "                                              config['vmin'],\n",
    "                                              config['vmax'],\n",
    "                                              config['trigger_params'],\n",
    "                                             )\n",
    "\n",
    "        if config['verbose']:\n",
    "            windows_r2.printlog()\n",
    "\n",
    "        if config['body']:\n",
    "            irot = rot.copy()\n",
    "            irot.integrate()\n",
    "\n",
    "            save_path_ray2 = config['path_to_outdata']+f\"ROLODE/VROMY_HH/{name}-SV2/\"\n",
    "\n",
    "            windows_r2.window_estimation_rayleigh2(tra,\n",
    "                                                   irot.select(component=\"N\")[0],\n",
    "                                                   irot.select(component=\"E\")[0],\n",
    "                                                   body=config['body'],\n",
    "                                                   mask_value=config['mvalue'],\n",
    "                                                   trigger=config['detrigger'],\n",
    "                                                   verbose=config['verbose'],\n",
    "                                                  )\n",
    "\n",
    "        else:\n",
    "\n",
    "            save_path_ray2 = config['path_to_outdata']+f\"ROLODE/VROMY_HH/{name}-Rayleigh2/\"\n",
    "\n",
    "            windows_r2.window_estimation_rayleigh2(acc,\n",
    "                                                   rot.select(component=\"N\")[0],\n",
    "                                                   rot.select(component=\"E\")[0],\n",
    "                                                   body=config['body'],\n",
    "                                                   mask_value=config['mvalue'],\n",
    "                                                   trigger=config['detrigger'],\n",
    "                                                   verbose=config['verbose'],\n",
    "                                                  )\n",
    "\n",
    "        # createt directories\n",
    "        if not os.path.exists(save_path_ray2):\n",
    "            os.makedirs(save_path_ray2)\n",
    "\n",
    "        # write to file and log\n",
    "        windows_r2.write(save_path_ray2+\"windows_r2.pkl\", config['firstRun'])\n",
    "        windows_r2.writelog(save_path_ray2+\"info_r2.log\", config['firstRun'])\n",
    "\n",
    "        config['save_path_rayleigh2'] = save_path_ray2\n",
    "\n",
    "\n",
    "    config['firstRun'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Postprocessing\n",
    "##################################################################\n",
    "\n",
    "if config['love_waves']:\n",
    "\n",
    "    __postprocessing(config, wave_type=\"love\")\n",
    "\n",
    "if config['rayleigh1_waves']:\n",
    "\n",
    "    __postprocessing(config, wave_type=\"rayleigh1\")\n",
    "\n",
    "if config['rayleigh2_waves']:\n",
    "\n",
    "    __postprocessing(config, wave_type=\"rayleigh2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_dump = config\n",
    "\n",
    "config_dump['tbeg'] = str(config_dump['tbeg'])\n",
    "config_dump['tend'] = str(config_dump['tend'])\n",
    "\n",
    "# store configurations\n",
    "with open(config['path_to_sds']+f\"{config['filename']}_config.yml\", \"w\") as outfile:\n",
    "    yaml.dump(config, outfile, default_flow_style=False, sort_keys=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
