{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b508642b-9d43-409f-88dd-604ddd7a9524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import obspy as obs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from functions.request_data import __request_data\n",
    "from functions.add_distances_and_backazimuth import __add_distances_and_backazimuth\n",
    "from functions.compute_adr_pfo import __compute_adr_pfo\n",
    "from functions.add_radial_and_transverse_channel import __add_radial_and_transverse_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0a0f70-fdf7-453f-ad8e-a44e8eb4c265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == 'lighthouse':\n",
    "    root_path = '/home/andbro/'\n",
    "    data_path = '/home/andbro/kilauea-data/'\n",
    "    archive_path = '/home/andbro/freenas/'\n",
    "elif os.uname().nodename == 'kilauea':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf69abb5-7b95-4a14-985a-8964b1bf7eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __makeplot(config, st):\n",
    "\n",
    "\n",
    "    st_in = st.copy()\n",
    "\n",
    "    fig, ax = plt.subplots(6,1, figsize=(15,10), sharex=True)\n",
    "\n",
    "    font = 14\n",
    "\n",
    "    time_scaling, time_unit = 1, \"sec\"\n",
    "    rot_scaling = 1e9\n",
    "    trans_scaling = 1e6\n",
    "\n",
    "    for i, tr in enumerate(st_in):\n",
    "\n",
    "        if i in [0,1,2]:\n",
    "            ax[i].set_ylabel(r\"$\\omega$ (nrad/s)\", fontsize=font)\n",
    "            ax[i].plot(tr.times()/time_scaling, tr.data*rot_scaling, 'k', label=tr.stats.station+\".\"+tr.stats.channel)\n",
    "\n",
    "        elif i in [3,4,5]:\n",
    "            ax[i].set_ylabel(r\"u ($\\mu$m/s)\", fontsize=font)\n",
    "            ax[i].plot(tr.times()/time_scaling, tr.data*trans_scaling, 'k', label=tr.stats.station+\".\"+tr.stats.channel)\n",
    "\n",
    "        ax[i].legend(loc=1)\n",
    "\n",
    "    ax[5].set_xlabel(f\"Time ({time_unit}) from {st[0].stats.starttime.date} {str(st[0].stats.starttime.time).split('.')[0]} UTC\", fontsize=font)\n",
    "    ax[0].set_title(config['title']+f\" | {config['fmin']} - {config['fmax']} Hz\", fontsize=font, pad=10)\n",
    "\n",
    "    plt.show();\n",
    "    del st_in\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b7556a-9916-4482-959d-2198980b84fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __empty_stream(reference_stream):\n",
    "\n",
    "    from numpy import ones\n",
    "    from obspy import Stream, Trace\n",
    "\n",
    "    t_ref = reference_stream[0]\n",
    "\n",
    "    empty = Stream()\n",
    "\n",
    "    for cha in [\"BHZ\", \"BHN\", \"BHE\"]:\n",
    "        t = Trace()\n",
    "        t.data = ones(len(t_ref))\n",
    "        t.stats.sampling_rate = t_ref.stats.sampling_rate\n",
    "        t.stats.starttime = t_ref.stats.starttime\n",
    "        t.stats.network, t.stats.station, t.stats.channel = \"PY\", \"RPFO\", cha\n",
    "        empty += t\n",
    "\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bcf6d96-9275-4abc-956d-90e50e2d5530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __stream_to_dataframe(st):\n",
    "\n",
    "    dff = pd.DataFrame()\n",
    "\n",
    "    for tr in st:\n",
    "        name = f\"{tr.stats.station}_{tr.stats.location}_{tr.stats.channel}\"\n",
    "        dff[name] = tr.data\n",
    "\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742dcc54-84e1-43b4-9db7-79b76259bf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "## location of BSPF\n",
    "config['BSPF_lon'] = -116.455439\n",
    "config['BSPF_lat'] = 33.610643\n",
    "\n",
    "## path for figures to store\n",
    "config['outpath_figs'] = data_path+\"BSPF/figures/SNR/\"\n",
    "\n",
    "##\n",
    "config['translation_type'] = \"ACC\"  ## ACC / DISP\n",
    "\n",
    "## path for output data\n",
    "config['outpath_data'] = data_path+\"BSPF/data/\"\n",
    "\n",
    "config['path_to_mseed'] = data_path+f\"BSPF/data/waveforms/{config['translation_type'].upper()}/\"\n",
    "\n",
    "## blueSeis sensor (@200Hz)\n",
    "# config['seed_blueseis'] = \"PY.BSPF..HJ*\"\n",
    "\n",
    "## Trillium 240 next to BlueSeis on Pier (@40Hz)\n",
    "# config['seed_seismometer1'] = \"II.PFO.10.BH*\"\n",
    "\n",
    "## STS2 next to BlueSeis (@200Hz)\n",
    "# config['seed_seismometer2'] = \"PY.PFOIX..HH*\"\n",
    "\n",
    "config['path_to_catalog'] = data_path+\"BSPF/data/catalogs/\"\n",
    "\n",
    "config['catalog'] = \"BSPF_catalog_20221001_20230930_triggered.pkl\"\n",
    "# config['catalog'] = \"BSPF_catalog_20221001_20231001_triggered.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d9f8a1-6ca4-4424-aa8d-c5653d1a6367",
   "metadata": {},
   "source": [
    "## Event Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8c725-d4c4-420b-a1d3-f5ea51a70349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## read data frame of selected triggered events\n",
    "events = pd.read_pickle(config['path_to_catalog']+config['catalog'])\n",
    "\n",
    "## add column for hypocenter distance\n",
    "events['Hdistance_km'] = np.sqrt(events['distances_km']**2 + (events['depth']/1000)**2)\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836c5fb-8b16-4408-9253-56d051542eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf745c-72ad-4021-98e7-f8bec49af451",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RUN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e731d-eadc-4f2f-af68-cc6ae540f2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __compute_Amax(header, st_in, out_lst, trigger_time, win_length_sec):\n",
    "\n",
    "    from numpy import ones, nan, nanargmax, argmax\n",
    "    from obspy import UTCDateTime\n",
    "\n",
    "    st_in = st_in.sort()\n",
    "\n",
    "    st_in = st_in.detrend(\"demean\")\n",
    "    st_in = st_in.taper(0.01)\n",
    "    st_in = st_in.filter(\"bandpass\", freqmin=1.0, freqmax=12.0, corners=4, zerophase=True)\n",
    "\n",
    "\n",
    "    ## get relative samples of signal window\n",
    "    t_rel_sec = abs(UTCDateTime(trigger_time)-st[0].stats.starttime)\n",
    "\n",
    "    df = st[0].stats.sampling_rate  ## sampling rate\n",
    "\n",
    "    NN = int(df * win_length_sec) ## samples\n",
    "\n",
    "    n_rel_spl = t_rel_sec * df ## samples\n",
    "\n",
    "    n_signal_1, n_signal_2 = int(n_rel_spl), int(n_rel_spl+NN)\n",
    "\n",
    "    ## find index of maximum for PFO Z\n",
    "    tr_ = st_in.select(station=\"PFO*\", location=\"10\", channel=f\"*R\")[0]\n",
    "    max_idx = argmax(abs(tr_.data[n_signal_1:n_signal_2]))\n",
    "\n",
    "    ## samples offset around maximum\n",
    "    n_off = int(0.1 * df)\n",
    "\n",
    "    out = {}\n",
    "    for ii, h in enumerate(header):\n",
    "        sta, loc, cha = h.split(\"_\")[0], h.split(\"_\")[1], h.split(\"_\")[2]\n",
    "        try:\n",
    "            tr = st_in.select(station=sta, location=loc, channel=f\"*{cha}\")[0]\n",
    "            out[h+\"_amax\"] = max(abs(tr.data[n_signal_1+max_idx-n_off:n_signal_1+max_idx+n_off]))\n",
    "            # out[h+\"_amax\"] = max(abs(tr.data[n_signal_1+max_idx]))\n",
    "        except:\n",
    "            out[h+\"_amax\"] = nan\n",
    "            print(f\" -> amax: {h} adding nan\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8b5b2-7bd3-4b8f-9c7c-1962db87f132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __compute_SNR(header, st_in, out_lst, trigger_time, win_length_sec=10, plot=False, plot_save=False):\n",
    "\n",
    "    from numpy import nanmean, sqrt, isnan, ones, nan, nanpercentile, nanargmax, argmax\n",
    "    from obspy import UTCDateTime\n",
    "\n",
    "    st_in = st_in.sort()\n",
    "    st_in = st_in.detrend(\"demean\")\n",
    "    # st_in = st_in.taper(0.01)\n",
    "    # st_in = st_in.filter(\"bandpass\", freqmin=1.0, freqmax=6.0, corners=4, zerophase=True)\n",
    "\n",
    "    if plot or plot_save:\n",
    "        fig, ax = plt.subplots(len(st_in), 1, figsize=(15, 15), sharex=True)\n",
    "\n",
    "    out = {}\n",
    "    for ii, h in enumerate(header):\n",
    "\n",
    "        sta, loc, cha = h.split(\"_\")[0], h.split(\"_\")[1], h.split(\"_\")[2]\n",
    "\n",
    "        try:\n",
    "            tr = st_in.select(station=sta, location=loc, channel=f\"*{cha}\")[0]\n",
    "        except:\n",
    "            out[h+\"_snr\"] = nan\n",
    "\n",
    "        t_rel_sec = abs(UTCDateTime(trigger_time)-tr.stats.starttime)\n",
    "\n",
    "        df = tr.stats.sampling_rate\n",
    "\n",
    "        NN = int(df * win_length_sec) ## samples\n",
    "\n",
    "        n_rel_spl = t_rel_sec * df ## samples\n",
    "\n",
    "        n_offset = df * 2 ## samples\n",
    "\n",
    "        n_noise_1, n_noise_2 = int(n_rel_spl-NN-n_offset), int(n_rel_spl-n_offset)\n",
    "        n_signal_1, n_signal_2 = int(n_rel_spl), int(n_rel_spl+NN)\n",
    "\n",
    "        ## noise, signal and ratio using mean\n",
    "        # noise = nanmean(tr.data[n_noise_1:n_noise_2]**2)\n",
    "        # signal = nanmean(tr.data[n_signal_1:n_signal_2]**2)\n",
    "        # out[h+\"_snr\"] = sqrt(signal/noise)\n",
    "\n",
    "        ## find index of maximum for PFO Z\n",
    "        tr_ = st_in.select(station=\"PFO*\", location=\"10\", channel=f\"*R\")[0]\n",
    "        max_idx = argmax(abs(tr_.data[n_signal_1:n_signal_2]))\n",
    "\n",
    "        ## samples offset around maximum\n",
    "        n_off = int(1 * df)\n",
    "\n",
    "\n",
    "        ## noise, signal and ratio using percentile\n",
    "        try:\n",
    "            noise = nanpercentile(abs(tr.data[n_noise_1:n_noise_2]), 99.9)\n",
    "            signal = nanpercentile(abs(tr.data[n_signal_1:n_signal_2]), 99.9)\n",
    "            out[h+\"_snr\"] = signal/noise\n",
    "        except:\n",
    "            out[h+\"_snr\"] = nan\n",
    "            print(f\" -> snr: {h} adding nan\")\n",
    "\n",
    "\n",
    "        if plot or plot_save:\n",
    "\n",
    "            if ii < len(st_in):\n",
    "\n",
    "                scaling = 1\n",
    "\n",
    "\n",
    "                ax[ii].plot(abs(tr.data)*scaling, label=f\"{tr.stats.station}.{tr.stats.location}.{tr.stats.channel}\")\n",
    "\n",
    "                ax[ii].legend(loc=1)\n",
    "\n",
    "                ## signal period\n",
    "                ax[ii].axvline(n_rel_spl, color=\"g\")\n",
    "                ax[ii].axvline(n_rel_spl+NN, color=\"g\")\n",
    "\n",
    "                # ax[ii].axhline(signal*scaling, n_rel_spl, n_rel_spl+NN, color=\"g\", ls=\"--\", zorder=3)\n",
    "\n",
    "                ## noise period\n",
    "                ax[ii].axvline(n_rel_spl-n_offset, color=\"r\")\n",
    "                ax[ii].axvline(n_rel_spl-NN-n_offset, color=\"r\")\n",
    "\n",
    "                # ax[ii].axhline(noise*scaling, n_rel_spl-n_offset, n_rel_spl-NN-n_offset, color=\"r\", ls=\"--\", zorder=3)\n",
    "\n",
    "                maximal_value = abs(tr.data[n_signal_1+max_idx])\n",
    "                ax[ii].scatter(n_signal_1+max_idx, maximal_value*scaling, color=\"tab:orange\", alpha=0.7)\n",
    "\n",
    "\n",
    "                ## OLD window picking\n",
    "                # maximal_idx = nanargmax(abs(tr.data[n_signal_1+max_idx-n_off:n_signal_1+max_idx+n_off]))\n",
    "                # maximal_value = abs(tr.data[n_signal_1+max_idx-n_off+maximal_idx])\n",
    "                # ax[ii].scatter(maximal_idx+n_signal_1+max_idx-n_off, maximal_value*scaling, color=\"tab:orange\", alpha=0.7)\n",
    "\n",
    "                # ax[ii].axvline(n_signal_1+max_idx-n_off, color=\"orange\")\n",
    "                # ax[ii].axvline(n_signal_1+max_idx+n_off, color=\"orange\")\n",
    "                # ax[ii].axvline(n_signal_1+max_idx-n_off+maximal_idx, color=\"orange\", ls=\"--\")\n",
    "\n",
    "                ax[ii].set_ylim(bottom=-0)\n",
    "\n",
    "    if plot:\n",
    "        plt.show();\n",
    "\n",
    "    if plot_save:\n",
    "        fig.savefig(config['outpath_figs']+f\"SNR_{st_in[0].stats.starttime}.png\", format=\"png\", dpi=200, bbox_inches='tight')\n",
    "        plt.close();\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed421c4-1b11-4137-99ec-146e1329a9ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __compute_adr_max(header, st_in, out_lst, trigger_time, win_length_sec):\n",
    "\n",
    "    from numpy import ones, nan, argmax\n",
    "    from obspy import UTCDateTime\n",
    "\n",
    "    st_in = st_in.copy().sort()\n",
    "\n",
    "    st_in = st_in.detrend(\"linear\")\n",
    "\n",
    "    bspf_i = st_in.select(station=\"BSPF\").copy()\n",
    "    bspf_a = st_in.select(station=\"BSPF\").copy()\n",
    "    bspf_m = st_in.select(station=\"BSPF\").copy()\n",
    "    adr_i = st_in.select(station=\"RPFO\", location=\"in\").copy()\n",
    "    adr_a = st_in.select(station=\"RPFO\", location=\"al\").copy()\n",
    "    adr_m = st_in.select(station=\"RPFO\", location=\"mi\").copy()\n",
    "\n",
    "    bspf_a = bspf_a.filter(\"bandpass\", freqmin=0.1, freqmax=0.5, corners=8, zerophase=True)\n",
    "    adr_a = adr_a.filter(\"bandpass\", freqmin=0.1, freqmax=0.5, corners=8, zerophase=True)\n",
    "\n",
    "    bspf_i = bspf_i.filter(\"bandpass\", freqmin=1.0, freqmax=6.0, corners=8, zerophase=True)\n",
    "    adr_i = adr_i.filter(\"bandpass\", freqmin=1.0, freqmax=6.0, corners=8, zerophase=True)\n",
    "\n",
    "    bspf_m = bspf_m.filter(\"bandpass\", freqmin=0.5, freqmax=1.0, corners=8, zerophase=True)\n",
    "    adr_m = adr_m.filter(\"bandpass\", freqmin=0.5, freqmax=1.0, corners=8, zerophase=True)\n",
    "\n",
    "    for tr in bspf_a:\n",
    "        tr.stats.location = \"al\"\n",
    "    for tr in bspf_m:\n",
    "        tr.stats.location = \"mi\"\n",
    "    for tr in bspf_i:\n",
    "        tr.stats.location = \"in\"\n",
    "\n",
    "    bspf_a.detrend(\"linear\")\n",
    "    adr_a.detrend(\"linear\")\n",
    "\n",
    "    bspf_i.detrend(\"linear\")\n",
    "    adr_i.detrend(\"linear\")\n",
    "\n",
    "    adr_m.detrend(\"linear\")\n",
    "    adr_m.detrend(\"linear\")\n",
    "\n",
    "    st0 = adr_i\n",
    "    st0 += bspf_i\n",
    "\n",
    "    st0 += bspf_a\n",
    "    st0 += adr_a\n",
    "\n",
    "    st0 += bspf_m\n",
    "    st0 += adr_m\n",
    "\n",
    "\n",
    "    ## get relative samples of signal window\n",
    "    t_rel_sec = abs(UTCDateTime(trigger_time)-st[0].stats.starttime)\n",
    "\n",
    "    df = st[0].stats.sampling_rate  ## sampling rate\n",
    "\n",
    "    NN = int(df * win_length_sec) ## samples\n",
    "\n",
    "    n_rel_spl = t_rel_sec * df ## samples\n",
    "\n",
    "    n_signal_1, n_signal_2 = int(n_rel_spl), int(n_rel_spl+NN)\n",
    "\n",
    "\n",
    "    ## find index of maximum for PFO Z\n",
    "    tr_ = st_in.select(station=\"PFO*\", location=\"10\", channel=f\"*T\")[0]\n",
    "    max_idx = argmax(abs(tr_.data[n_signal_1:n_signal_2]))\n",
    "\n",
    "    ## samples offset around maximum\n",
    "    n_off = int(0.1 * df)\n",
    "\n",
    "\n",
    "    out = {}\n",
    "    for ii, h in enumerate(header):\n",
    "\n",
    "        if h == \"origin\":\n",
    "            continue\n",
    "\n",
    "        sta, loc, cha = h.split(\"_\")[0], h.split(\"_\")[1], h.split(\"_\")[2]\n",
    "        try:\n",
    "            tr = st0.select(station=sta, location=loc, channel=f\"*{cha}\")[0]\n",
    "            out[h] = max(abs(tr.data[n_signal_1+max_idx-n_off:n_signal_1+max_idx+n_off]))\n",
    "        except Exception as e:\n",
    "            out[h] = nan\n",
    "            print(f\" -> adr: {h} adding nan\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec40daf-671f-45a2-aea7-495df779febe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __compute_adr_cc(header, st_in, out_lst, trigger_time, win_length_sec):\n",
    "\n",
    "    from numpy import ones, nan, argmax\n",
    "    from obspy import UTCDateTime\n",
    "    from obspy.signal.cross_correlation import correlate\n",
    "\n",
    "    st_in = st_in.copy().sort()\n",
    "\n",
    "    st_in = st_in.detrend(\"linear\")\n",
    "\n",
    "    bspf_i = st_in.select(station=\"BSPF\").copy()\n",
    "    bspf_a = st_in.select(station=\"BSPF\").copy()\n",
    "    bspf_m = st_in.select(station=\"BSPF\").copy()\n",
    "    adr_i = st_in.select(station=\"RPFO\", location=\"in\").copy()\n",
    "    adr_a = st_in.select(station=\"RPFO\", location=\"al\").copy()\n",
    "    adr_m = st_in.select(station=\"RPFO\", location=\"mi\").copy()\n",
    "\n",
    "\n",
    "    bspf_a = bspf_a.filter(\"bandpass\", freqmin=0.1, freqmax=0.5, corners=8, zerophase=True)\n",
    "    adr_a = adr_a.filter(\"bandpass\", freqmin=0.1, freqmax=0.5, corners=8, zerophase=True)\n",
    "\n",
    "    bspf_i = bspf_i.filter(\"bandpass\", freqmin=1.0, freqmax=6.0, corners=8, zerophase=True)\n",
    "    adr_i = adr_i.filter(\"bandpass\", freqmin=1.0, freqmax=6.0, corners=8, zerophase=True)\n",
    "\n",
    "    bspf_m = bspf_m.filter(\"bandpass\", freqmin=0.5, freqmax=1.0, corners=8, zerophase=True)\n",
    "    adr_m = adr_m.filter(\"bandpass\", freqmin=0.5, freqmax=1.0, corners=8, zerophase=True)\n",
    "\n",
    "    for tr in bspf_a:\n",
    "        tr.stats.location = \"al\"\n",
    "    for tr in bspf_m:\n",
    "        tr.stats.location = \"mi\"\n",
    "    for tr in bspf_i:\n",
    "        tr.stats.location = \"in\"\n",
    "\n",
    "    bspf_a.detrend(\"linear\")\n",
    "    adr_a.detrend(\"linear\")\n",
    "\n",
    "    bspf_i.detrend(\"linear\")\n",
    "    adr_i.detrend(\"linear\")\n",
    "\n",
    "    adr_m.detrend(\"linear\")\n",
    "    adr_m.detrend(\"linear\")\n",
    "\n",
    "    st0 = adr_i\n",
    "    st0 += bspf_i\n",
    "\n",
    "    st0 += bspf_a\n",
    "    st0 += adr_a\n",
    "\n",
    "    st0 += bspf_m\n",
    "    st0 += adr_m\n",
    "\n",
    "\n",
    "    ## get relative samples of signal window\n",
    "    t_rel_sec = abs(UTCDateTime(trigger_time)-st[0].stats.starttime)\n",
    "\n",
    "    df = st[0].stats.sampling_rate  ## sampling rate\n",
    "\n",
    "    NN = int(df * win_length_sec) ## samples\n",
    "\n",
    "    n_rel_spl = t_rel_sec * df ## samples\n",
    "\n",
    "    n_signal_1, n_signal_2 = int(n_rel_spl), int(n_rel_spl+NN)\n",
    "\n",
    "\n",
    "    ## find index of maximum for PFO\n",
    "    tr_ = st_in.select(station=\"PFO*\", location=\"10\", channel=f\"*T\")[0]\n",
    "    max_idx = argmax(abs(tr_.data[n_signal_1:n_signal_2]))\n",
    "\n",
    "    ## samples offset around maximum\n",
    "    n_off = int(1 * df)\n",
    "\n",
    "    _i1, _i2 = n_signal_1+max_idx-n_off, n_signal_1+max_idx+n_off\n",
    "\n",
    "    # print(st0.__str__(extended=True))\n",
    "\n",
    "    out = {}\n",
    "    for ii, h in enumerate(header):\n",
    "\n",
    "        if h == \"origin\":\n",
    "            continue\n",
    "\n",
    "        sta, loc, cha = h.split(\"_\")[0], h.split(\"_\")[1], h.split(\"_\")[2]\n",
    "\n",
    "        try:\n",
    "            tr_ref = st0.select(station=\"BSPF\", location=loc, channel=f\"*{cha}\")[0]\n",
    "            tr = st0.select(station=sta, location=loc, channel=f\"*{cha}\")[0]\n",
    "            # out[h] = round(max(correlate(tr_ref.data[n_signal_1:n_signal_2], tr.data[n_signal_1:n_signal_2], 0)), 1)\n",
    "            out[h] = round(max(correlate(tr_ref.data[_i1:_i2], tr.data[_i1:_i2], 0)), 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(\"cc error:\" + e)\n",
    "            out[h] = nan\n",
    "            print(f\" -> cc: {h} adding nan\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9bd0d-7c37-481e-b137-99009ebd6465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['mseed_files'] = sorted([file for file in os.listdir(config['path_to_mseed'])])\n",
    "\n",
    "len(config['mseed_files'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5e348-724f-4a43-a937-d166a25e9cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create dataframe for output\n",
    "out_df = pd.DataFrame()\n",
    "\n",
    "out_df[\"Torigin\"] = events.origin\n",
    "out_df[\"Magnitude\"] = events.magnitude\n",
    "out_df[\"CoincidenceSum\"] = events.cosum\n",
    "out_df[\"Mag_type\"] = events.type\n",
    "out_df[\"BAZ\"] = events.backazimuth\n",
    "out_df[\"Edistance_km\"] = events.distances_km\n",
    "out_df[\"Hdistance_km\"] = events.Hdistance_km\n",
    "\n",
    "tmp_events = [str(ee).split(\".\")[0] for ee in events.origin]\n",
    "\n",
    "data_amax, data_snr, data_adr, skipped, nan_row = [], [], [], 0, 0\n",
    "\n",
    "## pre-define header for data frames\n",
    "header = ['BSPF__E','BSPF__N','BSPF__R','BSPF__T','BSPF__Z',\n",
    "          'PFO_10_E','PFO_10_N','PFO_10_R','PFO_10_T','PFO_10_Z',\n",
    "          'RPFO_al_E','RPFO_al_N','RPFO_al_Z',\n",
    "          'RPFO_in_E','RPFO_in_N','RPFO_in_Z',\n",
    "          'RPFO_mi_E','RPFO_mi_N','RPFO_mi_Z'\n",
    "         ]\n",
    "\n",
    "## prepare dataframes\n",
    "header_amax = [h+\"_amax\" for h in header]\n",
    "header_amax.insert(0, \"origin\")\n",
    "df_amax = pd.DataFrame(columns=header_amax)\n",
    "\n",
    "header_snr = [h+\"_snr\" for h in header]\n",
    "header_snr.insert(0, \"origin\")\n",
    "df_snr = pd.DataFrame(columns=header_snr)\n",
    "\n",
    "\n",
    "header_adr = []\n",
    "for hh in [\"BSPF_al_N_adr\", \"BSPF_al_E_adr\", \"BSPF_al_Z_adr\", \"BSPF_al_T_adr\", \"BSPF_al_R_adr\",\n",
    "           \"BSPF_mi_N_adr\", \"BSPF_mi_E_adr\", \"BSPF_mi_Z_adr\", \"BSPF_mi_T_adr\", \"BSPF_mi_R_adr\",\n",
    "           \"BSPF_in_N_adr\", \"BSPF_in_E_adr\", \"BSPF_in_Z_adr\", \"BSPF_in_T_adr\", \"BSPF_in_R_adr\",\n",
    "           \"RPFO_in_N_adr\", \"RPFO_in_E_adr\", \"RPFO_in_Z_adr\",\n",
    "           \"RPFO_al_N_adr\", \"RPFO_al_E_adr\", \"RPFO_al_Z_adr\",\n",
    "           \"RPFO_mi_N_adr\", \"RPFO_mi_E_adr\", \"RPFO_mi_Z_adr\"]:\n",
    "    header_adr.append(hh)\n",
    "\n",
    "# header_adr = [h+\"_adr\" for h in header]\n",
    "header_adr.insert(0,\"origin\")\n",
    "df_adr = pd.DataFrame(columns=header_adr)\n",
    "\n",
    "df_adr_cc = pd.DataFrame(columns=header_adr)\n",
    "\n",
    "\n",
    "for event in tqdm(config['mseed_files'][:50]):\n",
    "\n",
    "    yy = int(event.replace(\".\",\"_\").split(\"_\")[1][:4])\n",
    "    mm = int(event.replace(\".\",\"_\").split(\"_\")[1][4:6])\n",
    "    dd = int(event.replace(\".\",\"_\").split(\"_\")[1][6:8])\n",
    "    h = int(event.replace(\".\",\"_\").split(\"_\")[2][0:2])\n",
    "    m = int(event.replace(\".\",\"_\").split(\"_\")[2][2:4])\n",
    "    s = int(event.replace(\".\",\"_\").split(\"_\")[2][4:6])\n",
    "\n",
    "    otime = f\"{yy}-{mm:02d}-{dd:02d} {h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "\n",
    "    if otime not in tmp_events:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    else:\n",
    "        jj = tmp_events.index(otime)\n",
    "\n",
    "#     print(f\"\\n -> {jj} {events.origin[jj]} \")\n",
    "\n",
    "    event_name = str(events.origin[jj]).replace(\"-\",\"\").replace(\":\",\"\").replace(\" \", \"_\").split(\".\")[0]\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        st = obs.read(config['path_to_mseed']+event)\n",
    "\n",
    "        ## resample all to 40 Hz\n",
    "        st = st.resample(40)\n",
    "\n",
    "        st = st.sort();\n",
    "\n",
    "        ## rename PFOIX events to make compatible\n",
    "        for tr in st:\n",
    "            if \"PFOIX\" in tr.stats.station:\n",
    "                tr.stats.station = \"PFO\"\n",
    "                tr.stats.location = \"10\"\n",
    "\n",
    "\n",
    "        ## add radial and transverse channels\n",
    "        st = __add_radial_and_transverse_channel(st, \"PFO*\", events.backazimuth[jj])\n",
    "        st = __add_radial_and_transverse_channel(st, \"BSPF\", events.backazimuth[jj])\n",
    "\n",
    "        if len(st) != 19:\n",
    "            print(f\"{len(st)} is not 19\")\n",
    "\n",
    "        ## processing data stream\n",
    "        st = st.detrend(\"linear\")\n",
    "        st = st.taper(0.01)\n",
    "        st = st.filter(\"highpass\", freq=0.01, corners=4, zerophase=True)\n",
    "\n",
    "        ## compute maximal amplitude values (PGA and PGR)\n",
    "        data_amax = __compute_Amax(header, st, data_amax, events.trigger_time[jj], win_length_sec=15)\n",
    "        row = {**{\"origin\":events.origin[jj]}, **data_amax}\n",
    "        df_amax.loc[len(df_amax)] = row\n",
    "\n",
    "        ## compute signal-to-noise ratios\n",
    "        data_snr = __compute_SNR(header, st, data_snr, events.trigger_time[jj], win_length_sec=15, plot=False, plot_save=True)\n",
    "        row = {**{\"origin\":events.origin[jj]}, **data_snr}\n",
    "        df_snr.loc[len(df_snr)] = row\n",
    "\n",
    "        ## compute adr maxima\n",
    "        data_adr = __compute_adr_max(header_adr, st, data_adr, events.trigger_time[jj], win_length_sec=15)\n",
    "        row = {**{\"origin\":events.origin[jj]}, **data_adr}\n",
    "        df_adr.loc[len(df_adr)] = row\n",
    "\n",
    "        ## compute bspf vs adr cross correlation coefficients\n",
    "        data_adr_cc = __compute_adr_cc(header_adr, st, data_adr, events.trigger_time[jj], win_length_sec=15)\n",
    "        row = {**{\"origin\":events.origin[jj]}, **data_adr_cc}\n",
    "        df_adr_cc.loc[len(df_adr)] = row\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\" -> failed for {event}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "## _______________________________________\n",
    "\n",
    "out_df['origin'] = out_df['Torigin']\n",
    "\n",
    "df_amax_out = pd.merge(out_df, df_amax, on=[\"origin\"])\n",
    "\n",
    "df_amax_out.to_pickle(config['outpath_data']+f\"bspf_analysisdata_amax_{config['translation_type']}.pkl\")\n",
    "print(f\"\\n -> writing: {config['outpath_data']}bspf_analysisdata_amax_{config['translation_type']}.pkl\")\n",
    "\n",
    "# ## _______________________________________\n",
    "\n",
    "df_snr_out = pd.merge(out_df, df_snr, on=[\"origin\"])\n",
    "\n",
    "df_snr_out.to_pickle(config['outpath_data']+f\"bspf_analysisdata_snr_{config['translation_type']}.pkl\")\n",
    "print(f\"\\n -> writing: {config['outpath_data']}bspf_analysisdata_snr_{config['translation_type']}.pkl\")\n",
    "\n",
    "# ## _______________________________________\n",
    "\n",
    "df_adr_out = pd.merge(out_df, df_adr, on=[\"origin\"])\n",
    "\n",
    "df_adr_out.to_pickle(config['outpath_data']+f\"bspf_analysisdata_adr_{config['translation_type']}.pkl\")\n",
    "print(f\"\\n -> writing: {config['outpath_data']}bspf_analysisdata_adr_{config['translation_type']}.pkl\")\n",
    "\n",
    "# ## _______________________________________\n",
    "\n",
    "df_adr_cc_out = pd.merge(out_df, df_adr_cc, on=[\"origin\"])\n",
    "\n",
    "df_adr_cc_out.to_pickle(config['outpath_data']+f\"bspf_analysisdata_adr_cc_{config['translation_type']}.pkl\")\n",
    "print(f\"\\n -> writing: {config['outpath_data']}bspf_analysisdata_adr_cc_{config['translation_type']}.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n -> skipped: {skipped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edeee21-47c3-4a9d-90fa-43738da96160",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Signal-to-Noise ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f92ccc-d9b2-49de-bed4-ba2227aa38a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __compute_SNR(header, st_in, out_lst, trigger_time, win_length_sec=10, plot=False, plot_save=False):\n",
    "\n",
    "    from numpy import nanmean, sqrt, isnan, ones, nan, nanpercentile, nanargmax, argmax\n",
    "    from obspy import UTCDateTime\n",
    "\n",
    "    st_in = st_in.sort()\n",
    "    # st_in = st_in.detrend(\"demean\").taper(0.01).filter(\"bandpass\", freqmin=0.5, freqmax=15.0, corners=4, zerophase=True)\n",
    "\n",
    "    if plot or plot_save:\n",
    "        fig, ax = plt.subplots(len(st_in), 1, figsize=(15, 15), sharex=True)\n",
    "\n",
    "    out = {}\n",
    "    for ii, h in enumerate(header):\n",
    "\n",
    "        sta, loc, cha = h.split(\"_\")[0], h.split(\"_\")[1], h.split(\"_\")[2]\n",
    "\n",
    "        try:\n",
    "            tr = st_in.select(station=sta, location=loc, channel=f\"*{cha}\")[0]\n",
    "        except:\n",
    "            out[h+\"_snr\"] = nan\n",
    "\n",
    "        t_rel_sec = abs(UTCDateTime(trigger_time)-tr.stats.starttime)\n",
    "\n",
    "        df = tr.stats.sampling_rate\n",
    "\n",
    "        NN = int(df * win_length_sec) ## samples\n",
    "\n",
    "        n_rel_spl = t_rel_sec * df ## samples\n",
    "\n",
    "        n_offset = df * 2 ## samples\n",
    "\n",
    "        n_noise_1, n_noise_2 = int(n_rel_spl-NN-n_offset), int(n_rel_spl-n_offset)\n",
    "        n_signal_1, n_signal_2 = int(n_rel_spl), int(n_rel_spl+NN)\n",
    "\n",
    "        ## noise, signal and ratio using mean\n",
    "        # noise = nanmean(tr.data[n_noise_1:n_noise_2]**2)\n",
    "        # signal = nanmean(tr.data[n_signal_1:n_signal_2]**2)\n",
    "        # out[h+\"_snr\"] = sqrt(signal/noise)\n",
    "\n",
    "        ## find index of maximum for PFO Z\n",
    "        tr_ = st_in.select(station=\"PFO*\", location=\"10\", channel=f\"*R\")[0]\n",
    "        max_idx = argmax(abs(tr_.data[n_signal_1:n_signal_2]))\n",
    "\n",
    "        ## samples offset around maximum\n",
    "        n_off = int(0.1 * df)\n",
    "\n",
    "\n",
    "        ## noise, signal and ratio using percentile\n",
    "        try:\n",
    "            noise = nanpercentile(abs(tr.data[n_noise_1:n_noise_2]), 99.9)\n",
    "            signal = nanpercentile(abs(tr.data[n_signal_1:n_signal_2]), 99.9)\n",
    "            out[h+\"_snr\"] = signal/noise\n",
    "        except:\n",
    "            out[h+\"_snr\"] = nan\n",
    "            print(f\" -> snr: {h} adding nan\")\n",
    "\n",
    "\n",
    "        if plot or plot_save:\n",
    "\n",
    "            if ii < len(st_in):\n",
    "\n",
    "                scaling = 1\n",
    "\n",
    "\n",
    "                ax[ii].plot(abs(tr.data)*scaling, label=f\"{tr.stats.station}.{tr.stats.location}.{tr.stats.channel}\")\n",
    "\n",
    "                ax[ii].legend(loc=1)\n",
    "\n",
    "                ## signal period\n",
    "                ax[ii].axvline(n_rel_spl, color=\"g\")\n",
    "                ax[ii].axvline(n_rel_spl+NN, color=\"g\")\n",
    "\n",
    "                # ax[ii].axhline(signal*scaling, n_rel_spl, n_rel_spl+NN, color=\"g\", ls=\"--\", zorder=3)\n",
    "\n",
    "                ## noise period\n",
    "                ax[ii].axvline(n_rel_spl-n_offset, color=\"r\")\n",
    "                ax[ii].axvline(n_rel_spl-NN-n_offset, color=\"r\")\n",
    "\n",
    "                # ax[ii].axhline(noise*scaling, n_rel_spl-n_offset, n_rel_spl-NN-n_offset, color=\"r\", ls=\"--\", zorder=3)\n",
    "\n",
    "                ## New direct picking\n",
    "                # maximal_value = abs(tr.data[n_signal_1+max_idx])\n",
    "                # ax[ii].scatter(n_signal_1+max_idx, maximal_value*scaling, color=\"tab:orange\", alpha=0.7, zorder=4)\n",
    "\n",
    "\n",
    "                ## OLD window picking\n",
    "                maximal_idx = nanargmax(abs(tr.data[n_signal_1+max_idx-n_off:n_signal_1+max_idx+n_off]))\n",
    "                maximal_value = abs(tr.data[n_signal_1+max_idx-n_off+maximal_idx])\n",
    "                ax[ii].scatter(maximal_idx+n_signal_1+max_idx-n_off, maximal_value*scaling, color=\"tab:orange\", alpha=0.7)\n",
    "\n",
    "                ax[ii].axvline(n_signal_1+max_idx-n_off, color=\"orange\")\n",
    "                ax[ii].axvline(n_signal_1+max_idx+n_off, color=\"orange\")\n",
    "                ax[ii].axvline(n_signal_1+max_idx-n_off+maximal_idx, color=\"orange\", ls=\"--\")\n",
    "\n",
    "                ax[ii].set_ylim(bottom=-0)\n",
    "\n",
    "    if plot:\n",
    "        plt.show();\n",
    "\n",
    "    if plot_save:\n",
    "        fig.savefig(config['outpath_figs']+f\"SNR_{st_in[0].stats.starttime}.png\", format=\"png\", dpi=200, bbox_inches='tight')\n",
    "        plt.close();\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7b56f-b56a-4ddd-8899-26cbf75e5056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create dataframe for output\n",
    "out_df = pd.DataFrame()\n",
    "\n",
    "out_df[\"Torigin\"] = events.origin\n",
    "out_df[\"Magnitude\"] = events.magnitude\n",
    "out_df[\"CoincidenceSum\"] = events.cosum\n",
    "out_df[\"Mag_type\"] = events.type\n",
    "out_df[\"BAZ\"] = events.backazimuth\n",
    "out_df[\"Edistance_km\"] = events.distances_km\n",
    "out_df[\"Hdistance_km\"] = events.Hdistance_km\n",
    "\n",
    "tmp_events = [str(ee).split(\".\")[0] for ee in events.origin]\n",
    "\n",
    "data_amax, data_snr, data_adr, skipped, nan_row = [], [], [], 0, 0\n",
    "\n",
    "## pre-define header for data frames\n",
    "header = ['BSPF__E','BSPF__N','BSPF__R','BSPF__T','BSPF__Z',\n",
    "          'PFO_10_E','PFO_10_N','PFO_10_R','PFO_10_T','PFO_10_Z',\n",
    "          'RPFO_al_E','RPFO_al_N','RPFO_al_Z',\n",
    "          'RPFO_in_E','RPFO_in_N','RPFO_in_Z',\n",
    "          'RPFO_mi_E','RPFO_mi_N','RPFO_mi_Z'\n",
    "         ]\n",
    "\n",
    "## prepare dataframes\n",
    "header_amax = [h+\"_amax\" for h in header]\n",
    "header_amax.insert(0,\"origin\")\n",
    "df_amax = pd.DataFrame(columns=header_amax)\n",
    "\n",
    "header_snr = [h+\"_snr\" for h in header]\n",
    "header_snr.insert(0,\"origin\")\n",
    "df_snr = pd.DataFrame(columns=header_snr)\n",
    "\n",
    "\n",
    "header_adr = []\n",
    "for hh in [\"BSPF_a_N_adr\", \"BSPF_a_E_adr\", \"BSPF_a_Z_adr\", \"BSPF_a_T_adr\", \"BSPF_a_R_adr\",\n",
    "           \"BSPF_m_N_adr\", \"BSPF_m_E_adr\", \"BSPF_m_Z_adr\", \"BSPF_m_T_adr\", \"BSPF_m_R_adr\",\n",
    "           \"BSPF_i_N_adr\", \"BSPF_i_E_adr\", \"BSPF_i_Z_adr\", \"BSPF_i_T_adr\", \"BSPF_i_R_adr\",\n",
    "           \"RPFO_in_N_adr\", \"RPFO_in_E_adr\", \"RPFO_in_Z_adr\",\n",
    "           \"RPFO_al_N_adr\", \"RPFO_al_E_adr\", \"RPFO_al_Z_adr\",\n",
    "           \"RPFO_mi_N_adr\", \"RPFO_mi_E_adr\", \"RPFO_mi_Z_adr\"]:\n",
    "    header_adr.append(hh)\n",
    "\n",
    "# header_adr = [h+\"_adr\" for h in header]\n",
    "header_adr.insert(0, \"origin\")\n",
    "df_adr = pd.DataFrame(columns=header_adr)\n",
    "\n",
    "\n",
    "\n",
    "for event in tqdm(config['mseed_files'][200:201]):\n",
    "\n",
    "    yy = int(event.replace(\".\",\"_\").split(\"_\")[1][:4])\n",
    "    mm = int(event.replace(\".\",\"_\").split(\"_\")[1][4:6])\n",
    "    dd = int(event.replace(\".\",\"_\").split(\"_\")[1][6:8])\n",
    "    h = int(event.replace(\".\",\"_\").split(\"_\")[2][0:2])\n",
    "    m = int(event.replace(\".\",\"_\").split(\"_\")[2][2:4])\n",
    "    s = int(event.replace(\".\",\"_\").split(\"_\")[2][4:6])\n",
    "\n",
    "    otime = f\"{yy}-{mm:02d}-{dd:02d} {h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "\n",
    "    if otime not in tmp_events:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    else:\n",
    "        jj = tmp_events.index(otime)\n",
    "\n",
    "#     print(f\"\\n -> {jj} {events.origin[jj]} \")\n",
    "\n",
    "    event_name = str(events.origin[jj]).replace(\"-\",\"\").replace(\":\",\"\").replace(\" \", \"_\").split(\".\")[0]\n",
    "\n",
    "\n",
    "    try:\n",
    "        st = obs.read(config['path_to_mseed']+event)\n",
    "\n",
    "        st = st.resample(40)\n",
    "\n",
    "        for tr in st:\n",
    "            if \"PFOIX\" in tr.stats.station:\n",
    "                tr.stats.station = \"PFO\"\n",
    "                tr.stats.location = \"10\"\n",
    "\n",
    "\n",
    "        ## add radial and transverse channels\n",
    "        st = __add_radial_and_transverse_channel(st, \"PFO*\", events.backazimuth[jj])\n",
    "        st = __add_radial_and_transverse_channel(st, \"BSPF\", events.backazimuth[jj])\n",
    "\n",
    "        if len(st) != 19:\n",
    "            print(f\"{len(st)} is not 19\")\n",
    "\n",
    "        ## processing data stream\n",
    "        st = st.detrend(\"linear\")\n",
    "        st = st.taper(0.01)\n",
    "        st = st.filter(\"highpass\", freq=0.01, corners=4, zerophase=True)\n",
    "\n",
    "        ## compute maximal amplitude values (PGA and PGR)\n",
    "        data_amax = __compute_Amax(header, st, data_amax, events.trigger_time[jj], win_length_sec=15)\n",
    "        row = {**{\"origin\":events.origin[jj]}, **data_amax}\n",
    "        df_amax.loc[len(df_amax)] = row\n",
    "\n",
    "        ## compute signal-to-noise ratios\n",
    "        data_snr = __compute_SNR(header, st, data_snr, events.trigger_time[jj], win_length_sec=15, plot=True, plot_save=False)\n",
    "        row = {**{\"origin\":events.origin[jj]}, **data_snr}\n",
    "        df_snr.loc[len(df_snr)] = row\n",
    "\n",
    "        # ## compute signal-to-noise ratios\n",
    "        # data_adr = __compute_adr_max(header, st, data_adr, events.trigger_time[jj], win_length_sec=15)\n",
    "        # row = {**{\"origin\":events.origin[jj]}, **data_adr}\n",
    "        # df_adr.loc[len(df_adr)] = row\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\" -> failed for {event}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9def345-6930-4d6f-a4e5-074795b16fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def __cc_in_octaves(st_in, fmin, fmax):\n",
    "\n",
    "#     from pandas import DataFrame\n",
    "#     from functions.get_octave_bands import __get_octave_bands\n",
    "#     from functions.compute_cc_for_fbands import __compute_cc_for_fbands\n",
    "    \n",
    "#     flower, fupper, fcenter = __get_octave_bands(fmin, fmax, fband_type=\"one-third-octave\")\n",
    "\n",
    "#     fbands = [(fl, fu) for fl, fu in zip(flower, fupper)]\n",
    "\n",
    "#     ## _____________________\n",
    "\n",
    "# #     fbands = [(1,5),(2,6),(3,7),(4,8),(5,9),(6,10),(7,11),(8,12),(9,13),(10,14),(11,15),(12,16),(13,17),(14,18)]\n",
    "# #     fbands = [(1,2),(2,4),(3,6),(4,8),(5,10),(6,12),(7,14),(8,16), (9,18), (10,20)]\n",
    "\n",
    "#     df_out = DataFrame()\n",
    "    \n",
    "#     for comp in [\"Z\",\"N\",\"E\"]:\n",
    "\n",
    "#         print(comp)\n",
    "\n",
    "#         plt.figure(figsize=(15,5))\n",
    "\n",
    "#         tr1 = st_in.select(station=\"BSPF\", channel=f'*{comp}')[0]\n",
    "#         tr2 = st_in.select(station=\"RPFO\", location=\"in\", channel=f'*{comp}')[0]\n",
    "#         tr3 = st_in.select(station=\"RPFO\", location=\"al\", channel=f'*{comp}')[0]\n",
    "        \n",
    "        \n",
    "#         ff, cc_t_max, cc_f_max = __compute_cc_for_fbands(tr1, tr2, fbands=fbands, plot=False)\n",
    "        \n",
    "#         df_out[f'{comp}_in_fband'] = ff\n",
    "#         df_out[f'{comp}_in_cc_t'] = cc_t_max\n",
    "#         df_out[f'{comp}_in_cc_f'] = cc_f_max\n",
    "        \n",
    "#         plt.scatter(ff, cc_t_max, color=\"r\")\n",
    "#         plt.scatter(ff, cc_f_max, color=\"r\")\n",
    "\n",
    "#         ff, cc_t_max, cc_f_max = __compute_cc_for_fbands(tr1, tr3, fbands=fbands, plot=False)\n",
    "\n",
    "#         df_out[f'{comp}_al_fband'] = ff\n",
    "#         df_out[f'{comp}_al_cc_t'] = cc_t_max\n",
    "#         df_out[f'{comp}_al_cc_f'] = cc_f_max\n",
    "        \n",
    "#         plt.scatter(ff, cc_t_max)\n",
    "#         plt.scatter(ff, cc_f_max) \n",
    "\n",
    "#     #     plt.xscale(\"log\")\n",
    "#         plt.show()\n",
    "        \n",
    "#     return df_out\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "# def __coherence_in_octaves(st_in, fmin, fmax):\n",
    "\n",
    "#     from numpy import arange, mean\n",
    "#     from pandas import DataFrame\n",
    "#     from functions.get_octave_bands import __get_octave_bands\n",
    "#     from scipy.signal import coherence\n",
    "    \n",
    "#     flower, fupper, fcenter = __get_octave_bands(fmin, fmax, fband_type=\"one-third-octave\")\n",
    "#     fbands = [(fl, fu) for fl, fu in zip(flower, fupper)]\n",
    "\n",
    "#     ## _____________________\n",
    "\n",
    "# #     ddf = 3\n",
    "# #     fcenter = arange(fmin+ddf, fmax-ddf, 1)\n",
    "# #     fbands = [(fc - ddf, fc + ddf) for fc in fcenter] \n",
    "    \n",
    "#     df_out = DataFrame()\n",
    "    \n",
    "#     fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "    \n",
    "#     for ii, comp in enumerate([\"Z\",\"N\",\"E\"]):\n",
    "\n",
    "#         tr1 = st_in.select(station=\"BSPF\", channel=f'*{comp}')[0]\n",
    "#         tr2 = st_in.select(station=\"RPFO\", location=\"in\", channel=f'*{comp}')[0]\n",
    "#         tr3 = st_in.select(station=\"RPFO\", location=\"al\", channel=f'*{comp}')[0]\n",
    "        \n",
    "#         co2, co3 = [],[]\n",
    "#         for (fl, fu) in fbands:\n",
    "#             s1, s2, s3 = tr1.copy(), tr2.copy(), tr3.copy()\n",
    "            \n",
    "#             s1 = s1.filter(\"bandpass\", freqmin=fl, freqmax=fu, corners=8, zerophase=True)\n",
    "#             s2 = s2.filter(\"bandpass\", freqmin=fl, freqmax=fu, corners=8, zerophase=True)\n",
    "#             s3 = s3.filter(\"bandpass\", freqmin=fl, freqmax=fu, corners=8, zerophase=True)\n",
    "            \n",
    "#             s1 = s1.normalize()\n",
    "#             s2 = s2.normalize()\n",
    "#             s3 = s3.normalize()\n",
    "\n",
    "#             s1 = s1.taper(0.1)\n",
    "#             s2 = s2.taper(0.1)\n",
    "#             s3 = s3.taper(0.1)\n",
    "            \n",
    "#             df = s1.stats.sampling_rate\n",
    "#             tseg = 1/fl*20\n",
    "#             nseg = int(df*tseg)\n",
    "            \n",
    "# #             ff2, coh2 = coherence(s1.data, s2.data, fs=df, window='hann',nperseg=nseg, noverlap=int(0.5*nseg))\n",
    "# #             ff3, coh3 = coherence(s1.data, s3.data, fs=df, window='hann',nperseg=nseg, noverlap=int(0.5*nseg))\n",
    "#             ff2, coh2 = coherence(s1.data, s2.data, fs=df, window='hann')\n",
    "#             ff3, coh3 = coherence(s1.data, s3.data, fs=df, window='hann')\n",
    "        \n",
    "#             for i in range(len(ff2)):\n",
    "#                 if ff2[i] < fl or ff2[i] > fu:\n",
    "#                     coh2[i], coh3[i] = 0, 0\n",
    "        \n",
    "# #             plt.figure()\n",
    "# #             plt.plot(ff2, coh2)\n",
    "# #             plt.show()\n",
    "            \n",
    "#             co2.append(max(coh2))\n",
    "#             co3.append(max(coh3))\n",
    "            \n",
    "#         df_out[f'{comp}_in_fc'] = fcenter\n",
    "#         df_out[f'{comp}_in_co']  = co2\n",
    "#         df_out[f'{comp}_al_fc'] = fcenter\n",
    "#         df_out[f'{comp}_al_co']  = co3\n",
    "                 \n",
    "#         ax[ii].scatter(fcenter, co2, s=50, label=\"BSPF-RPFO_inner\")\n",
    "#         ax[ii].plot(fcenter, co2, ls=\"-\")\n",
    "\n",
    "#         ax[ii].scatter(fcenter, co3, s=50, label=\"BSPF-PRFO_all\")\n",
    "#         ax[ii].plot(fcenter, co3, ls=\"-\")\n",
    "\n",
    "#         ax[ii].set_title(f\"max. coherence {comp}\")\n",
    "#         ax[ii].legend()\n",
    "#         ax[ii].set_xscale(\"log\")\n",
    "#         ax[ii].grid(ls=\"--\",zorder=0,alpha=.5, which=\"both\")\n",
    "#     plt.show();\n",
    "        \n",
    "#     return df_out\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Manual Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e1a4f-aa5b-452e-b0cc-1d010b798194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a99a3-4f0d-4ef8-955f-1fe02ded1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = obs.UTCDateTime(\"2023-05-20\")\n",
    "events[(events.origin < str((date+86500).date)) & (events.origin > str((date).date))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24bd93d-d1dd-4cac-885d-b360a014542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_events = [\n",
    "    \"2022-10-03 16:08:09.970\",\n",
    "    \"2022-10-07 22:45:05.470\",\n",
    "    \"2022-10-15 05:17:34.150\",\n",
    "    \"2022-10-23 09:24:58.150\",\n",
    "    \"2022-10-26 08:14:35.080\",\n",
    "    \"2022-12-31 12:12:26.650\",\n",
    "    \"2023-01-09 19:42:56.460\",\n",
    "    \"2023-01-11 18:59:20.030\",\n",
    "    \"2023-01-15 09:58:54.070\",\n",
    "    \"2023-02-01 09:05:02.320\",\n",
    "    \"2023-03-01 22:49:03.580\",\n",
    "    \"2023-03-24 13:45:13.700\",\n",
    "    \"2023-04-10 14:51:00.950\",\n",
    "    \"2023-04-17 18:52:36.930\",\n",
    "    \"2023-04-26 06:46:58.450\",\n",
    "    \"2023-05-03 21:14:20.210\",\n",
    "    \"2023-05-20 08:18:16.240\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['origin_time'] = good_events\n",
    "# df.to_pickle(config['outpath_data']+\"event_selection_good.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80818bb4-b18c-41f6-9e0b-fe076c3d29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "\n",
    "## list of events to reject (manually)\n",
    "no_event = [\"2022-10-05 15:39:13.690\", \n",
    "            \"2022-10-05 15:42:03.610\",\n",
    "            \"2022-10-05 18:35:16.860\",\n",
    "            \"2022-10-10 05:48:52.890\",\n",
    "            \"2022-10-12 19:12:14.670\",\n",
    "            \"2022-10-12 23:08:11.410\",\n",
    "            \"2022-10-12 23:58:00.800\",\n",
    "            \"2022-10-14 03:13:56.380\",\n",
    "            \"2022-10-16 08:42:24.970\",\n",
    "            \"2022-10-26 08:27:09.860\",\n",
    "            \"2022-10-28 12:47:26.910\",\n",
    "            \"2022-11-03 05:53:34.230\",\n",
    "            \"2022-11-09 00:46:57.550\",\n",
    "            \"2022-11-10 16:53:29.940\",\n",
    "            \"2022-11-25 10:45:36.390\",\n",
    "            \"2022-12-06 21:56:31.330\",\n",
    "            \"2022-12-09 06:03:03.220\",\n",
    "            \"2022-12-15 13:55:13.460\",\n",
    "            \"2022-12-17 18:02:34.910\",\n",
    "            \"2022-12-19 15:41:22.380\",\n",
    "            \"2022-12-19 15:41:26.020\",\n",
    "            \"2023-01-05 09:59:04.210\",\n",
    "            \"2023-01-07 12:32:45.250\",\n",
    "            \"2023-01-16 00:00:36.100\",\n",
    "            \"2023-01-29 23:50:47.770\",\n",
    "            \"2023-02-05 23:38:46.670\",\n",
    "            \"2023-02-22 05:09:39.970\",\n",
    "            \"2023-03-09 11:49:06.640\",\n",
    "            \"2023-03-17 07:12:56.970\",\n",
    "            \"2023-03-24 13:59:00.160\",\n",
    "            \"2023-03-29 19:23:29.470\",\n",
    "            \"2023-03-29 19:23:27.460\",\n",
    "            \"2023-04-06 02:42:00.600\",\n",
    "            \"2023-04-13 23:57:53.950\",\n",
    "            \"2023-04-17 15:27:56.450\",\n",
    "            \"2023-05-01 02:52:56.160\",\n",
    "            \"2023-06-02 20:19:46.740\",\n",
    "            \"2023-06-05 07:39:16.650\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ae447-5b01-4394-a8e7-2f33470b9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_event_utc = list(map(UTCDateTime, no_event))\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['origin_time'] = no_event\n",
    "# df.to_pickle(config['outpath_data']+\"event_selection_reject.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
