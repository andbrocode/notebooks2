{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda030d3",
   "metadata": {},
   "source": [
    "# Hourly PSDS -RY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-presentation",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behind-arrangement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:54:03.050940Z",
     "start_time": "2023-08-07T14:54:00.312331Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "from scipy.signal import welch\n",
    "from numpy import log10, zeros, pi, append, linspace, mean, median, array, where, transpose, shape, histogram, arange\n",
    "from numpy import logspace, linspace, log, log10, isinf, ones, nan, count_nonzero, sqrt, isnan\n",
    "from pandas import DataFrame, concat, Series, date_range, read_csv, read_pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import os, sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions.get_fband_average import __get_fband_average\n",
    "from functions.replace_noise_psd_with_nan import __replace_noisy_psds_with_nan\n",
    "from functions.cut_frequencies_array import __cut_frequencies_array\n",
    "from functions.get_fband_averages import __get_fband_averages\n",
    "from functions.replace_noise_psd_with_nan import __replace_noisy_psds_with_nan\n",
    "from functions.get_median_psd import __get_median_psd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f337911b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:54:03.147385Z",
     "start_time": "2023-08-07T14:54:03.133998Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == 'lighthouse':\n",
    "    root_path = '/home/andbro/'\n",
    "    data_path = '/home/andbro/kilauea-data/'\n",
    "    archive_path = '/home/andbro/freenas/'\n",
    "    bay_path = '/home/andbro/bay200/'\n",
    "elif os.uname().nodename == 'kilauea':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/bay200/'\n",
    "elif os.uname().nodename == 'lin-ffb-01':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/bay200/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-expression",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d365e8e0-a71e-4f0b-9961-89d24266d47d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "\n",
    "config['d1'], config['d2'] = \"2023-03-10\", \"2023-03-17\"\n",
    "\n",
    "config['path_to_data'] = archive_path+\"ModalAnalysis/data/PSDS/\"\n",
    "\n",
    "config['outpath_figures'] = data_path+f\"ModalAnalysis/figures/\"\n",
    "\n",
    "config['frequency_limits'] = 1e-2, 1e2\n",
    "\n",
    "config['year'] = config['d1'][:4]\n",
    "\n",
    "config['seed'] = \"BW.FFB1..HH*\"\n",
    "config['seed'] = \"GR.FUR..HH*\"\n",
    "\n",
    "config['components'] = [\"Z\", \"N\", \"E\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-beginning",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aeee3e-9810-4ffa-9db8-eed9e08bb878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __makeplot_colorlines_overview(config, ff, psds, rejected, names, day, show_rejected=True):\n",
    "\n",
    "    from tqdm.notebook import tqdm\n",
    "    from numpy import isnan, median, mean, std, array, zeros\n",
    "    from scipy.stats import median_abs_deviation as mad\n",
    "\n",
    "#     psds_median = __get_median_psd(array(psds))\n",
    "#     psds_minimal = __get_minimal_psd(array(psds))\n",
    "#     psds_minimum = __get_minimum_psd(array(psds), ff)\n",
    "\n",
    "\n",
    "    # ## convert frequencies to periods\n",
    "    # pp=[]\n",
    "    # for mm in range(len(ff)):\n",
    "    #     ppp = zeros(len(ff[mm]))\n",
    "    #     ppp = 1/ff[mm]\n",
    "    #     pp.append(ppp)\n",
    "\n",
    "\n",
    "    ##____________________________\n",
    "\n",
    "    NN = 3\n",
    "\n",
    "    fig, axes = plt.subplots(NN, 1, figsize=(12, 12), sharey=False, sharex=True)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "    font = 14\n",
    "\n",
    "    N = 24\n",
    "\n",
    "    colors = plt.cm.rainbow(linspace(0, 1, N))\n",
    "    cmap = plt.get_cmap('rainbow', 24)\n",
    "\n",
    "\n",
    "    for j in range(NN):\n",
    "\n",
    "        try:\n",
    "            for n, psd in enumerate(psds[j]):\n",
    "                axes[j].loglog(ff[j], psd, color=colors[n], alpha=0.7)\n",
    "                p2 = axes[j].scatter(ff[j][0], psd[0], s=0., c=n/N, cmap=cmap, vmin=0, vmax=N, zorder=3)\n",
    "\n",
    "            if show_rejected:\n",
    "                for reject in rejected[j]:\n",
    "                     axes[j].loglog(ff[j],reject, color='grey', alpha=0.6, zorder=2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        axes[j].loglog(ff[j], __get_median_psd(psds[j]), 'black', zorder=3, alpha=0.6, label=\"Median\")\n",
    "\n",
    "        axes[NN-2].loglog(baro_lnm['frequency'], baro_lnm['nlnm_baro'], color=\"grey\", ls=\"--\", alpha=0.8)\n",
    "        axes[NN-2].loglog(baro_lnm['frequency'], baro_lnm['nhnm_baro'], color=\"grey\", ls=\"--\", alpha=0.8)\n",
    "\n",
    "        axes[NN-1].loglog(baro_lnm['frequency'], baro_lnm['nlnm_baro'], color=\"grey\", ls=\"--\", alpha=0.8)\n",
    "        axes[NN-1].loglog(baro_lnm['frequency'], baro_lnm['nhnm_baro'], color=\"grey\", ls=\"--\", alpha=0.8)\n",
    "\n",
    "        axes[j].set_xlim(1e-3, 2e0)\n",
    "        axes[j].grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "        axes[j].legend(loc='lower left')\n",
    "        axes[j].tick_params(labelsize=font-2)\n",
    "\n",
    "    ## limits of sensor noise\n",
    "    # freq = arange(0.0001, 1, 0.001)\n",
    "    # plim1 = 0.1**2 * ones(len(freq)) / 12 / (0.5*0.1) ## resolution = 0.1 hPa @ 0.1Hz sampling\n",
    "    # plim2 = 0.1**2 * ones(len(freq)) / 12/ (0.5*1.0) ## resolution = 0.1 hPa @ 0.1Hz sampling\n",
    "\n",
    "    # plim1_1 = 0.1**2 * ones(len(freq)) / (0.5*0.1) ## resolution = 0.1 hPa @ 0.1Hz sampling\n",
    "    # plim2_1 = 0.1**2 * ones(len(freq)) / (0.5*1.0) ## resolution = 0.1 hPa @ 0.1Hz sampling\n",
    "\n",
    "    # axes[1].loglog(freq, plim1, color=\"black\", ls=\"--\", zorder=4, alpha=0.7)\n",
    "    # axes[2].loglog(freq, plim2, color=\"black\", ls=\"--\", zorder=4, alpha=0.7)\n",
    "\n",
    "    # axes[1].loglog(freq, plim1_1, color=\"black\", ls=\":\", zorder=4, alpha=0.7)\n",
    "    # axes[2].loglog(freq, plim2_1, color=\"black\", ls=\":\", zorder=4, alpha=0.7)\n",
    "\n",
    "    axes[0].plot(df_models.frequencies, df_models.nlnm_acc, color=\"k\", ls=\"--\", alpha=0.6)\n",
    "    axes[1].plot(df_models.frequencies, df_models.nlnm_acc, color=\"k\", ls=\"--\", alpha=0.6)\n",
    "    axes[2].plot(df_models.frequencies, df_models.nlnm_acc, color=\"k\", ls=\"--\", alpha=0.6)\n",
    "\n",
    "    axes[NN-1].set_xlabel(\"  Frequency (Hz)\", fontsize=font, labelpad=-1)\n",
    "\n",
    "    ## panel labels\n",
    "    axes[0].text(.01, .95, '(a)', ha='left', va='top', transform=axes[0].transAxes, fontsize=font)\n",
    "    axes[1].text(.01, .95, '(b)', ha='left', va='top', transform=axes[1].transAxes, fontsize=font)\n",
    "    axes[2].text(.01, .95, '(c)', ha='left', va='top', transform=axes[2].transAxes, fontsize=font)\n",
    "\n",
    "    sta, cha = names[0].split(\"_\")[-2], names[0].split(\"_\")[-1]\n",
    "    axes[0].text(.05, .95, f'{sta}.{cha}', ha='left', va='top', transform=axes[0].transAxes, fontsize=font)\n",
    "\n",
    "    sta, cha = names[1].split(\"_\")[-2], names[1].split(\"_\")[-1]\n",
    "    axes[1].text(.05, .95, f'{sta}.{cha}', ha='left', va='top', transform=axes[1].transAxes, fontsize=font)\n",
    "\n",
    "    sta, cha = names[2].split(\"_\")[-2], names[2].split(\"_\")[-1]\n",
    "    axes[2].text(.05, .95, f'{sta}.{cha}', ha='left', va='top', transform=axes[2].transAxes, fontsize=font)\n",
    "\n",
    "    axes[0].set_title(day, fontsize=font+2)\n",
    "\n",
    "    axes[0].set_ylim(bottom=1e-20, top=1e-10)\n",
    "    axes[1].set_ylim(bottom=1e-20, top=1e-10)\n",
    "    axes[2].set_ylim(bottom=1e-20, top=1e-10)\n",
    "\n",
    "\n",
    "    axes[0].set_ylabel(r\"PSD (m$^2$/s$^4$/Hz)\", fontsize=font)\n",
    "    axes[1].set_ylabel(r\"PSD (m$^2$/s$^4$/Hz)\", fontsize=font)\n",
    "    axes[2].set_ylabel(r\"PSD (m$^2$/s$^4$/Hz)\", fontsize=font)\n",
    "\n",
    "    ## set colorbar at bottom\n",
    "    cbar = fig.colorbar(p2, orientation='vertical', ax=axes.ravel().tolist(), aspect=50, pad=-1e-5, ticks=arange(1,N,2))\n",
    "\n",
    "\n",
    "    plt.show();\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff2634",
   "metadata": {},
   "source": [
    "## RUN for all files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c824ef59-1498-405d-8dea-2330a5413237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baro_lnm = read_csv(data_path+f\"LNM2/data/\"+\"baro_nlnm_nhnm.csv\")\n",
    "\n",
    "baro_lnm['nlnm_baro'] = 10**(baro_lnm['nlnm_baro_db']/10)\n",
    "baro_lnm['nhnm_baro'] = 10**(baro_lnm['nhnm_baro_db']/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c849ed0-6ec0-4031-986f-1a1fb29a0379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_models = read_csv(data_path+\"LNM/data/FINAL/\"+\"TLNM_to_RLNM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3822839",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T16:31:13.609975Z",
     "start_time": "2023-08-07T16:23:41.306613Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data1\n",
      " -> 0 are all NaN\n",
      " -> 0 rows removed due to mean thresholds (0.0011 and 1.8836 Hz)!\n",
      " -> 24 / 24 psds remain\n",
      "\n",
      "Data2\n",
      " -> 0 are all NaN\n",
      " -> 0 rows removed due to mean thresholds (0.0012 and 1.8836 Hz)!\n",
      " -> 24 / 24 psds remain\n",
      "\n",
      "Data3\n",
      " -> 0 are all NaN\n",
      " -> 0 rows removed due to mean thresholds (0.0012 and 1.8836 Hz)!\n",
      " -> 24 / 24 psds remain\n",
      "name '__makeplot_colorlines_overview' is not defined\n",
      "\n",
      "Data1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "psds_medians_out, times_out = [], []\n",
    "\n",
    "rejected_dat1, rejected_dat2, rejected_dat3, rejected_dat4, rejected_dat5 = [], [], [], [], []\n",
    "\n",
    "net, sta, loc, cha = config['seed'].split(\".\")\n",
    "\n",
    "\n",
    "for _i, day in enumerate(date_range(config['d1'], config['d2'])):\n",
    "\n",
    "    day = str(day).split(\" \")[0].replace(\"-\", \"\")\n",
    "\n",
    "    config['outpath_figname'] = \"joint_\"+day\n",
    "\n",
    "    # if _i > 0:\n",
    "    #     continue\n",
    "\n",
    "    # if os.path.isfile(config['outpath_figures']+config['outpath_figname']):\n",
    "    #     print(f\" -> skipping {config['outpath_figname']} ...\")\n",
    "    #     continue\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        ## Data1 --------------------------\n",
    "        print(\"\\nData1\")\n",
    "        name1 = f\"{sta}/{cha[:-1]}{config['components'][0]}/{config['year']}_{sta}_{cha[:-1]}{config['components'][0]}\"\n",
    "\n",
    "        out = read_pickle(config['path_to_data']+f\"{name1}_{day}_hourly.pkl\")\n",
    "        ff1, dat1 = out['frequencies'], out['psd']\n",
    "\n",
    "        ff1, dat1 = __get_fband_averages(ff1, dat1)\n",
    "\n",
    "        dat1, ff1 = __cut_frequencies_array(dat1, ff1, 1e-3, 2e0)\n",
    "\n",
    "        # dat1, rejected_dat1 = __replace_noisy_psds_with_nan(dat1, ff=ff1, threshold_mean=5e-19, threshold_min=1e-23, flim=[0.002, 0.01])\n",
    "        dat1, rejected_dat1 = __replace_noisy_psds_with_nan(dat1, ff=ff1,\n",
    "                                                            threshold_mean=None,\n",
    "                                                            threshold_min=None,\n",
    "                                                            threshold_max=None,\n",
    "                                                            flim=[None, None],\n",
    "                                                           )\n",
    "\n",
    "        if len(rejected_dat1) > 0:\n",
    "            _, rejected_dat1 = __get_fband_averages(ff1, rejected_dat1)\n",
    "\n",
    "        ## Data2 --------------------------\n",
    "        print(\"\\nData2\")\n",
    "        name2 = f\"{sta}/{cha[:-1]}{config['components'][1]}/{config['year']}_{sta}_{cha[:-1]}{config['components'][1]}\"\n",
    "\n",
    "        out = read_pickle(config['path_to_data']+f\"{name2}_{day}_hourly.pkl\")\n",
    "        ff2, dat2 = out['frequencies'], out['psd']\n",
    "\n",
    "        dat2, ff2 = __cut_frequencies_array(dat2, ff2, 1e-3, 2e0)\n",
    "\n",
    "        ff2, dat2 = __get_fband_averages(ff2, dat2)\n",
    "\n",
    "        # dat2, rejected_dat2 = __replace_noisy_psds_with_nan(dat2, ff=ff2, threshold_mean=1e-18, threshold_min=1e-22, flim=[0.0009, 0.002])\n",
    "        dat2, rejected_dat2 = __replace_noisy_psds_with_nan(dat2, ff=ff2,\n",
    "                                                            threshold_mean=None,\n",
    "                                                            threshold_min=None,\n",
    "                                                            threshold_max=None,\n",
    "                                                            flim=[None, None],\n",
    "                                                           )\n",
    "\n",
    "        if len(rejected_dat2) > 0:\n",
    "            _, rejected_dat2 = __get_fband_averages(ff2, rejected_dat2)\n",
    "\n",
    "\n",
    "        ## Data3 --------------------------\n",
    "        print(\"\\nData3\")\n",
    "        name3 = f\"{sta}/{cha[:-1]}{config['components'][2]}/{config['year']}_{sta}_{cha[:-1]}{config['components'][2]}\"\n",
    "\n",
    "        out = read_pickle(config['path_to_data']+f\"{name3}_{day}_hourly.pkl\")\n",
    "        ff3, dat3 = out['frequencies'], out['psd']\n",
    "\n",
    "        dat3, ff3 = __cut_frequencies_array(dat3, ff3, 1e-3, 2e0)\n",
    "\n",
    "        ff3, dat3 = __get_fband_averages(ff3, dat3)\n",
    "\n",
    "\n",
    "        dat3, rejected_dat3 = __replace_noisy_psds_with_nan(dat3, ff=ff3,\n",
    "                                                            threshold_mean=None,\n",
    "                                                            threshold_min=None,\n",
    "                                                            threshold_max=None,\n",
    "                                                            flim=[None, None],\n",
    "                                                           )\n",
    "        # dat3, rejected_dat3 = __replace_noisy_psds_with_nan(dat3, ff=ff3, threshold_mean=1e-19, threshold_min=1e-22, flim=[0.5, 0.9])\n",
    "\n",
    "        if len(rejected_dat3) > 0:\n",
    "            _, rejected_dat3 = __get_fband_averages(ff3, rejected_dat3)\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\" -> exception !\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        fig = __makeplot_colorlines_overview(config,\n",
    "                                             [ff1, ff2, ff3],\n",
    "                                             [dat1, dat2, dat3],\n",
    "                                             [rejected_dat1, rejected_dat2, rejected_dat3],\n",
    "                                             [name1, name2, name3],\n",
    "                                             day,\n",
    "                                             show_rejected=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    ## define file appendix\n",
    "    app = f\"_{name1[-1]}{name2[-1]}{name3[-1]}\"\n",
    "\n",
    "    # print(f\" -> saving: {config['outpath_figures']}{config['outpath_figname']}.png\")\n",
    "    # fig.savefig(config['outpath_figures']+\"joint_ROMY/\"+config['outpath_figname']+f\"_ROMY{app}.png\", format=\"png\", transparent=False, bbox_inches='tight', dpi=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516868f-9ef6-409a-ad23-fd5377d71264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"\"\"spd-say \"Finished\" \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc99383-16fb-4751-bffa-89656ba9d4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4c381-07bd-43ff-910b-865673b1e6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ded449-1901-4ba4-89ea-9ed5dacfb273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
