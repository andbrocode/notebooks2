


import os
import matplotlib.pyplot as plt

from scipy.signal import coherence, welch
from obspy import read_inventory, UTCDateTime, Stream

from andbro__read_sds import __read_sds


if os.uname().nodename == 'lighthouse':
    root_path = '/home/andbro/'
    data_path = '/home/andbro/kilauea-data/'
    archive_path = '/home/andbro/freenas/'
elif os.uname().nodename == 'kilauea':
    root_path = '/home/brotzer/'
    data_path = '/import/kilauea-data/'
    archive_path = '/import/freenas-ffb-01-data/'


tbeg, tend = UTCDateTime("2023-09-25 11:00"), UTCDateTime("2023-09-25 12:00")

unit = "Pa"


path = root_path+"bay200/"

st1 = __read_sds(path, "BW.FFBI..BDO", tbeg-1, tend+1)

# st1 = st1.resample(20.0)

# st1.trim(tbeg, tend)


path = archive_path+"romy_archive"

st2 = __read_sds(path, "BW.ROMY.10.BJZ", tbeg-1, tend+1)

inv2 = read_inventory(root_path+"Documents/ROMY/stationxml_ringlaser/dataless.seed.BW_ROMY")

# st2.trim(tbeg, tend)


st1.plot();
st2.plot();


## conversion to Pa or hPa
for _st in [st1, st2]:

    if "O" in _st[0].stats.channel:

        if unit == "Pa":
            for tr in _st:
                tr.data = tr.data /1 /6.28099e5 /1e-5   # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity = 1 mV/hPa
                # tr.data = tr.data /1.543 /6.28099e5 /1e-5   # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity = 1 mV/hPa
        elif unit == "hPa":
            for tr in _st:
                tr.data = tr.data /1.543 /6.28099e5 /1e-3   # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity = 1 mV/hPa
    if "F" in _st[0].stats.channel:

        for tr in _st:
            tr.data = tr.data /1.0 /6.28099e5 /0.02  # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity_mb2005=0.02 VPa

    if "J" in _st[0].stats.channel:
        _st = _st.remove_sensitivity(inv2)
        _st = _st.detrend("demean")


st1.plot();
st2.plot();


st1, st2


st = Stream()
st += st1.copy()
st += st2.copy()

st.resample(20.0)
st.trim(tbeg, tend)
# st.detrend("demean")



_N = len(st1[0].data)
df = st[0].stats.sampling_rate

t_seg = 1800
n_seg = int(df*t_seg) if int(df*t_seg) < _N else _N
n_over = int(0.5*n_seg)

ff_coh, coh = coherence(st.select(station="FFBI")[0].data,
                        st.select(station="ROMY")[0].data,
                        fs=df, window='hann', nperseg=n_seg, noverlap=n_over
                       )



def __multitaper_cross_spec(arr1, arr2, dt, n_win=5):

    import multitaper as mt
    import multitaper.utils as utils

    out = {}

    ## Compute multitaper PSDs
    Psd1 = mt.MTSpec(arr1, nw=n_win, kspec=0, dt=dt)
    Psd2 = mt.MTSpec(arr2, nw=n_win, kspec=0, dt=dt)

    ## extract the frequencies and PSDs
    _f1, _psd1 = Psd1.rspec()
    out['f1'], out['psd1'] = _f1.reshape(_f1.size), _psd1.reshape(_psd1.size)

    _f2, _psd2 = Psd2.rspec()
    out['f2'], out['psd2'] = _f2.reshape(_f2.size), _psd2.reshape(_psd2.size)

    ## cross-correlation, coherence, deconvolution
    P12 = mt.MTCross(Psd1, Psd2, wl=0.001)
    out['xcorr'], out['dcohe'], out['dconv'] = P12.mt_corr()

    ## dual frequency coherence
    # out['Sxy'], out['Cxy'], out['Phxy'], out['freq'] = utils.df_spec(Psd1, Psd2)

    return out



# out = __multitaper_cross_spec(st.select(station="FFBI")[0].data,
#                                         st.select(station="ROMY")[0].data,
#                                         st.select(station="ROMY")[0].stats.delta, 
#                                         n_win=4
#                                        )



def __multitaper_psd(arr, dt, n_win=5):

    import multitaper as mt

    out_psd = mt.MTSpec(arr, nw=n_win, kspec=0, dt=dt)

    _f, _psd = out_psd.rspec()

    f = _f.reshape(_f.size)
    psd = _psd.reshape(_psd.size)

    ## 95% confidence interval
    # _psd95 = out_psd.jackspec()
    # psd95_lower, psd95_upper = psd95[::2, 0], psd95[::2, 1]

    return f, psd


_tr = st.select(station="ROMY")[0]

ff_romy, psd_romy = __multitaper_psd(_tr.data, _tr.stats.delta, n_win=10)

ff_romy2, psd_romy2 = welch(
                            st2.select(station="ROMY")[0].data,
                            fs=df, window='hann', nperseg=n_seg, noverlap=n_over,
                            return_onsided=True, scaling="density", average="mean",
                           )


_tr = st.select(station="FFBI")[0]

ff_ffbi, psd_ffbi = __multitaper_psd(_tr.data, _tr.stats.delta, n_win=10)

ff_ffbi2, psd_ffbi2 = welch(
                            st1.select(station="FFBI")[0].data,
                            fs=df, window='hann', nperseg=n_seg, noverlap=n_over,
                            return_onsided=True, scaling="density", average="mean",
                           )





def __makeplot():

    fig, ax = plt.subplots(3, 1, figsize=(15, 8), sharex=True)

    ax[0].loglog(ff_ffbi2, psd_ffbi2, label="welch")
    ax[0].loglog(ff_ffbi, psd_ffbi, label="multitaper")

    ax[1].loglog(ff_romy2, psd_romy2, label="welch")
    ax[1].loglog(ff_romy, psd_romy, label="multitaper")

    ax[2].semilogx(ff_coh, coh)
    # ax[2].loglog(ff_ffbi, psd_romy/psd_ffbi)

    for i in range(3):
        ax[i].set_xlim(5e-4, 1e1)
        ax[i].legend()

    ax[0].set_ylim(1e-4, 1e5)
    ax[1].set_ylim(1e-22, 1e-16)
    ax[2].set_ylim(0, 1.1)


    plt.show();

__makeplot()





from pandas import read_pickle

psds1 = read_pickle("/home/andbro/kilauea-data/LNM2/PSDS/FFBI/2023_FFBI_3600_20231003_hourly.pkl")
psds2 = read_pickle("/home/andbro/kilauea-data/LNM2/PSDS/ROMY/2023_ROMY_3600_20231003_hourly.pkl")
coh = read_pickle("/home/andbro/kilauea-data/LNM2/COH/ROMY/Z/Coherence_20231003_hourly.pkl")


plt.figure()
for psd in psds1:
    plt.loglog(psd)
plt.figure()
for psd in psds2:
    plt.loglog(psd)
plt.figure()
for _coh in coh['coherence']:
    plt.loglog(_coh)









