import os
import matplotlib.pyplot as plt
import numpy as np

from datetime import datetime, date
from pandas import DataFrame, read_pickle, date_range, concat, read_csv
from obspy import UTCDateTime, read
from scipy.signal import hilbert



if os.uname().nodename == 'lighthouse':
    root_path = '/home/andbro/'
    data_path = '/home/andbro/kilauea-data/'
    archive_path = '/home/andbro/freenas/'
elif os.uname().nodename == 'kilauea':
    root_path = '/home/brotzer/'
    data_path = '/import/kilauea-data/'
    archive_path = '/import/freenas-ffb-01-data/'


config = {}

config['ring'] = "U"

config['seed'] = "BW.DROMY..FJU"

config['path_to_sds'] = archive_path+"romy_archive/"


config['tbeg'] = UTCDateTime("2023-09-01 17:00")
config['tend'] = UTCDateTime("2023-09-01 19:00")

# config['f_lower_zoomin'], config['f_upper_zoomin'] = 448-10, 448+10

## path to Sagnac data
config['path_to_autodata'] = archive_path+f"romy_autodata/"

config['path_to_data'] = data_path+"sagnac_frequency/data/"

config['path_to_figs'] = data_path+"sagnac_frequency/figures/"


def __load_romy_raw_data(seed, tbeg, tend, path_to_sds):

    from andbro__read_sds import __read_sds
    from obspy import Stream, UTCDateTime


    print(f" -> loading {seed}...")

    try:
        st00 = __read_sds(path_to_sds, seed, tbeg,tend, data_format='MSEED')
    except:
        print(f" -> failed for {seed}")

    st0 = st00.sort()

    for tr in st0:
        tr.data = tr.data*0.59604645e-6 # V / count  [0.59604645ug  from obsidian]

    return st0


# sagn = __load_romsagn = __load_romy_raw_data("BW.DROMY..FJU", config['tbeg'], config['tend'], config['path_to_sds'])
# mon1 = __load_romy_raw_data("BW.DROMY..F1V", config['tbeg'], config['tend'], config['path_to_sds'])
# mon2 = __load_romy_raw_data("BW.DROMY..F2V", config['tbeg'], config['tend'], config['path_to_sds'])y_raw_data("BW.DROMY..FJU", config['tbeg'], config['tend'], config['path_to_sds'])
# mon1 = __load_romy_raw_data("BW.DROMY..F1V", config['tbeg'], config['tend'], config['path_to_sds'])
# mon2 = __load_romy_raw_data("BW.DROMY..F2V", config['tbeg'], config['tend'], config['path_to_sds'])


sagn = read(root_path+"Downloads/mseed/DROMY_FJU_2023-09-19.mseed")
mon1 = read(root_path+"Downloads/mseed/DROMY_F1V_2023-09-19.mseed")
mon2 = read(root_path+"Downloads/mseed//DROMY_F2V_2023-09-19.mseed")

sagn.trim(config['tbeg'], config['tbeg']+600)
mon1.trim(config['tbeg'], config['tbeg']+600)
mon2.trim(config['tbeg'], config['tbeg']+600)

for tr in sagn:
    tr.data = tr.data*0.59604645e-6 # V / count  [0.59604645ug  from obsidian]
for tr in mon1:
    tr.data = tr.data*0.59604645e-6 # V / count  [0.59604645ug  from obsidian]
for tr in mon2:
    tr.data = tr.data*0.59604645e-6 # V / count  [0.59604645ug  from obsidian]

config['tbeg'], config['tend'] = sagn[0].stats.starttime, sagn[0].stats.endtime


# sagn.plot();
# mon1.plot();
# mon2.plot();


from functions.multitaper_psd import __multitaper_psd
from functions.welch_psd import __welch_psd
from acoustics.signal import phase_spectrum
from functions.get_time_intervals import __get_time_intervals


def __get_fft(signal_in, dt, window=None):

    '''
    Calculating a simple 1D FastFourierSpectrum of a time series.

    RETURN:

    frequencies, spectrum, phase

    TEST:

    >>> spectrum, frequencies, phase = __fft(signal_in, dt ,window=None,normalize=None)
    '''

    from scipy.fft import fft, fftfreq, fftshift
    from scipy import signal
    from numpy import angle, imag
    ## determine length of the input time series
    n = int(len(signal_in))


    ## calculate spectrum (with or without window function applied to time series)
    if window:
        win = signal.get_window(window, n);
        spectrum = fft(signal_in * win)

    else:
        spectrum = fft(signal_in)

    ## calculate frequency array
    frequencies = fftfreq(n, d=dt)


    ## correct amplitudes of spectrum
    magnitude = abs(spectrum) * 2.0 / n


    phase = angle(spectrum, deg=False)
    # phase = imag(spectrum)

    ## return the positive frequencies
    return frequencies[0:n//2], magnitude[0:n//2], phase[0:n//2]


def __welch_psd(arr, dt, twin_sec=60):

    from scipy.signal import welch
    from scipy.signal.windows import hann

    nblock = int(1/dt * twin_sec)
    overlap = int(0.5*nblock)
    win = hann(nblock, True)

    ff, Pxx = welch(arr,
                    fs=1/dt,
                    window=win, noverlap=overlap,
                    nfft=nblock,
                    scaling="spectrum",
                    return_onesided=True)

    return ff, Pxx


def __hilbert_frequency_estimator(st, nominal_sagnac, fband):

    from scipy.signal import hilbert
    import numpy as np

    st0 = st.copy()

    ## extract sampling rate
    df = st0[0].stats.sampling_rate

    ## define frequency band around Sagnac Frequency
    f_lower = nominal_sagnac - fband
    f_upper = nominal_sagnac + fband

    ## bandpass with butterworth around Sagnac Frequency
    # st0.detrend("linear")
    # st0.taper(0.01)
    # st0.filter("bandpass", freqmin=f_lower, freqmax=f_upper, corners=8, zerophase=True)


    ## estimate instantaneous frequency with hilbert
    signal = st0[0].data

    analytic_signal = hilbert(signal)
    amplitude_envelope = np.abs(analytic_signal)
    instantaneous_phase = np.unwrap(np.angle(analytic_signal))
    instantaneous_frequency = (np.diff(instantaneous_phase) / (2.0*np.pi) * df)

    ## cut first and last 5% (corrupted data)
    dd = int(0.05*len(instantaneous_frequency))
    insta_f_cut = instantaneous_frequency[dd:-dd]

    ## get times
    t = st0[0].times()
    t_center = t[int((len(t))/2)]

    ## averaging of frequencies
    insta_f_cut_mean = np.mean(insta_f_cut)
    # insta_f_cut_mean = np.median(insta_f_cut)

    return t_center, insta_f_cut_mean


def __zero_crossing_frequency_estimator(st0, df):

    """
    Estimate frequency by counting zero crossings

    Pros: Fast, accurate (increasing with data length).  Works well for long low-noise sines, square, triangle, etc.
    Cons: Doesn't work if there are multiple zero crossings per cycle, low-frequency baseline shift, noise, etc.

    """

    from numpy import average, diff, where, sign, mean, median, ones, nan

    sig = st0[0].data

    ## remove mean of data
    sig -= mean(sig)

    ## get number samples of set
    Nsamples = sig.size

    ## divide input set into 10 subsets
    dN = int(Nsamples/10)

    over = int(dN*1.0)

    ## prepare array
    _crossings = ones(int(Nsamples/over))*nan

    m1, m2 = 0, dN
    for _i in range(int(Nsamples/over)):
        ## find amount of polarity / sign changes in data subset
        _crossings[_i] = where(diff(sign(sig)))[0].size

        m1, m2 = m1+over, m2+over

    ## compute instantaneous frequency from crossings using mean of found crossings
    f = median(_crossings)*df/Nsamples/2

    ## get center time
    t = st0[0].times()
    t_center = t[int((len(t))/2)]

    return t_center, f


def __zero_crossing_differences_frequency_estimator(st0, df):

    """
    Estimate frequency by counting zero crossings

    Pros: Fast, accurate (increasing with data length).  Works well for long low-noise sines, square, triangle, etc.
    Cons: Doesn't work if there are multiple zero crossings per cycle, low-frequency baseline shift, noise, etc.

    """

    from numpy import average, diff, where, sign, mean, median, ones, nan

    sig = st0[0].data

    ## remove mean of data
    sig -= mean(sig)

    ## get number samples of set
    Nsamples = sig.size

    ## divide input set into 10 subsets
    dN = int(Nsamples/10)

    ## prepare array
    _freqs = ones(int(Nsamples/dN))*nan

    m1, m2 = 0, dN
    for _i in range(int(Nsamples/dN)):
        ## find amount of polarity / sign changes in data subset
        _freqs[_i] = median(df/diff(where(diff(sign(sig)))[0])/2)

        m1, m2 = m1+dN, m2+dN

    ## compute instantaneous frequency from crossings using mean of found crossings
    f = median(_freqs)

    ## get center time
    t = st0[0].times()
    t_center = t[int((len(t))/2)]

    return t_center, f


tbeg, tend = sagn[0].stats.starttime, sagn[0].stats.endtime

interval = 5 ## seconds

over = 0.2

fs0 = 303.05

fband = 30 ## +- df (Hz)

method = "fft" ## welch | multitaper | fft

times = __get_time_intervals(tbeg, tend, interval_seconds=interval, interval_overlap=0)


fs1, fs2 = np.ones(len(times))*np.nan, np.ones(len(times))*np.nan
trelative = np.ones(len(times))*np.nan


out_df = DataFrame()
out_df['time1'] = list(zip(*times))[0]
out_df['time2'] = list(zip(*times))[1]

trel = 0
for _k, _st in enumerate([sagn]):

    print(_k, "...")

    for _n, (t1, t2) in enumerate(times):

        _dat = _st.copy().trim(t1-over, t2+over)
        _dat.detrend("demean")
        _dat.taper(0.01)
        _dat.filter("bandpass", freqmin=fs0-fband, freqmax=fs0+fband, corners=4, zerophase=True)

        _t, fs1[_n] = __hilbert_frequency_estimator(_dat, nominal_sagnac=fs0, fband=fband)

        _, fs2[_n] = __zero_crossing_frequency_estimator(_dat, _dat[0].stats.sampling_rate)

        # _, fs2[_n] = __zero_crossing_differences_frequency_estimator(_dat, _dat[0].stats.sampling_rate)

        trel += _t
        trelative[_n] = trel

out_df['fs1'] = fs1
out_df['fs2'] = fs2
out_df['trelative'] = trelative



# ## store data
# date_str = f"{config['tbeg'].year}{str(config['tbeg'].month).rjust(2,'0')}{str(config['tbeg'].day).rjust(2,'0')}"
# out_df.to_pickle(config['path_to_data']+f"{date_str}_{method}.pkl")
# print(f" -> writing: {config['path_to_data']}{date_str}_{method}.pkl")


plt.figure(figsize=(15,5))

plt.plot(out_df.fs1, label="hilbert")
plt.plot(out_df.fs2, label="zero crossing")
plt.xlabel("Time (s)")
plt.ylabel("$\delta$f (Hz)")
plt.legend()
plt.title(f"T={interval} seconds | overlap={over} seconds")
plt.show();





import statsmodels.api as sm

decomposition = sm.tsa.seasonal_decompose(bromy_tilt, period=60, model='additive')

fig = decomposition.plot()
plt.show()


import emd


raw = read("/home/andbro/Downloads/mseed/30min/DROMY_FJU_2023-09-19.mseed")


data = raw[0].data[:5000*180]
# data = np.array(bs.w_s)


imf = emd.sift.sift(data)

IP, IF, IA = emd.spectra.frequency_transform(imf, 5000, 'hilbert')



N = IF.shape[1]

fig, ax = plt.subplots(N, 1, figsize=(15, 8), sharex=True)

for i in range(N):
    # ax[i].plot(np.unwrap(IP[:, i]))
    ax[i].plot(IF[:, i])


freq_edges, freq_centres = emd.spectra.define_hist_bins(1, 2500, 1000, 'log')

f, spec_weighted = emd.spectra.hilberthuang(IF, IA, freq_edges, sum_imfs=False)

f, spec_unweighted = emd.spectra.hilberthuang(IF, np.ones_like(IA), freq_edges, sum_imfs=False)


plt.figure(figsize=(10, 4))
plt.subplots_adjust(hspace=0.4)
plt.subplot(121)
plt.plot(freq_centres, spec_unweighted)
# plt.xticks(np.arange(10)*10)
plt.xlim(0, 500)
plt.xlabel('Frequency (Hz)')
plt.ylabel('Count')
plt.title('unweighted\nHilbert-Huang Transform')

plt.subplot(122)
plt.plot(freq_centres, spec_weighted)
# plt.xticks(np.arange(10)*10)
plt.xlim(0, 500)
plt.xlabel('Frequency (Hz)')
plt.ylabel('Power')
plt.title('IA-weighted\nHilbert-Huang Transform')
plt.legend(['IMF-1', 'IMF-2', 'IMF-3', 'IMF-4', 'IMF-5'], frameon=False)


plt.plot(IF[:, 0])
plt.ylim(200, 400)

np.mean(IF[:, 0])
