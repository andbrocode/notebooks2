import os
import obspy as obs
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from obspy import read_inventory

from andbro__read_sds import __read_sds


from functions.get_mean_promy_pressure import __get_mean_promy_pressure
from functions.get_mean_rmy_pressure import __get_mean_rmy_pressure


#%matplotlib tk


if os.uname().nodename == 'lighthouse':
    root_path = '/home/andbro/'
    data_path = '/home/andbro/kilauea-data/'
    archive_path = '/home/andbro/freenas/'
    bay_path = '/home/andbro/ontap-ffb-bay200/'
    lamont_path = '/home/andbro/lamont/'
elif os.uname().nodename == 'kilauea':
    root_path = '/home/brotzer/'
    data_path = '/import/kilauea-data/'
    archive_path = '/import/freenas-ffb-01-data/'
    bay_path = '/import/ontap-ffb-bay200/'
    lamont_path = '/lamont/'
elif os.uname().nodename in ['lin-ffb-01', 'ambrym', 'hochfelln']:
    root_path = '/home/brotzer/'
    data_path = '/import/kilauea-data/'
    archive_path = '/import/freenas-ffb-01-data/'
    bay_path = '/import/ontap-ffb-bay200/'
    lamont_path = '/lamont/'


config = {}

# output path for figures
config['path_to_figs'] = data_path+"romy_baro/figures/"

# path to data archive
config['data1'] = "ROMY"
config['path_to_data1'] = data_path+f"romy_baro/data/{config['data1']}/"

config['tbeg'] = obs.UTCDateTime("2024-03-01")
config['tend'] = obs.UTCDateTime("2024-06-30")

# data with regression alternative
config['data2'] = "FUR"
config['path_to_data2'] = data_path+f"romy_baro/data/{config['data2']}/"



def __load_data(tbeg, tend, path_to_data):

    from obspy import UTCDateTime
    from datetime import date
    from pandas import read_pickle, concat, DataFrame, date_range, to_datetime
    from tqdm.notebook import tqdm

    t1 = date.fromisoformat(str(UTCDateTime(tbeg).date))
    t2 = date.fromisoformat(str((UTCDateTime(tend)).date))

    df = DataFrame()
    for dat in tqdm(date_range(t1, t2)):
        # print(str(dat)[:10])
        file = f"RB_statistics_{str(dat)[:10]}.pkl"
        try:
            df0 = read_pickle(path_to_data+file)
            df = concat([df, df0])
        except Exception as e:
            print(e)
            print(f"error for {file}")

    # remove NaN from time column
    # df.dropna(subset=['time'], inplace=True)

    # reset the index column
    df.reset_index(inplace=True, drop=True)

    # add column for relative time in seconds
    df['time_sec'] = [(_t2 - _t1)/2 + _t1 for _t1, _t2 in zip(df.t1, df.t2)]

    return df


df1 = __load_data(config['tbeg'], config['tend'], config['path_to_data1'])

df2 = __load_data(config['tbeg'], config['tend'], config['path_to_data2'])



df1 = df1[df1.status == False]
df2 = df2[df2.status == False]


for k in ["shift_PP_N", "shift_PP_E", "shift_HP_N", "shift_HP_E"]:
    df1[k] = df1[k]/20 # 20 Hz sampling rate
    df2[k] = df2[k]/20 # 20 Hz sampling rate


# select only those with CC > 0.7
cc_threshold = 0.7
df1N = df1[(df1.cmax_PP_N.abs() > cc_threshold) | (df1.cmax_HP_N.abs() > cc_threshold)]
df1E = df1[(df1.cmax_PP_E.abs() > cc_threshold) | (df1.cmax_HP_E.abs() > cc_threshold)]
df1Z = df1[(df1.cmax_PP_Z.abs() > cc_threshold) | (df1.cmax_HP_Z.abs() > cc_threshold)]

cc_shift_threshold = 120
df1N = df1N[(df1N.shift_PP_N.abs() < cc_shift_threshold) | (df1N.shift_HP_N.abs() < cc_shift_threshold)]
df1E = df1E[(df1E.shift_PP_E.abs() < cc_shift_threshold) | (df1E.shift_HP_E.abs() < cc_shift_threshold)]
df1Z = df1Z[(df1Z.shift_PP_Z.abs() < cc_shift_threshold) | (df1Z.shift_HP_Z.abs() < cc_shift_threshold)]



# select only those with CC > 0.7
cc_threshold = 0.7
df2N = df2[(df2.cmax_PP_N.abs() > cc_threshold) | (df2.cmax_HP_N.abs() > cc_threshold)]
df2E = df2[(df2.cmax_PP_E.abs() > cc_threshold) | (df2.cmax_HP_E.abs() > cc_threshold)]
df2Z = df2[(df2.cmax_PP_Z.abs() > cc_threshold) | (df2.cmax_HP_Z.abs() > cc_threshold)]

cc_shift_threshold = 120
df2N = df2N[(df2N.shift_PP_N.abs() < cc_shift_threshold) | (df2N.shift_HP_N.abs() < cc_shift_threshold)]
df2E = df2E[(df2E.shift_PP_E.abs() < cc_shift_threshold) | (df2E.shift_HP_E.abs() < cc_shift_threshold)]
df2Z = df2Z[(df2Z.shift_PP_Z.abs() < cc_shift_threshold) | (df2Z.shift_HP_Z.abs() < cc_shift_threshold)]



def __makeplot_reg():

    import matplotlib.pyplot as plt
    from matplotlib.gridspec import GridSpec

    def get_box_plot_data(labels, bp):
        rows_list = []

        for i in range(len(labels)):
            dict1 = {}
            dict1['label'] = labels[i]
            dict1['lower_whisker'] = bp['whiskers'][i*2].get_ydata()[1]
            dict1['lower_quartile'] = bp['boxes'][i].get_ydata()[1]
            dict1['median'] = bp['medians'][i].get_ydata()[1]
            dict1['upper_quartile'] = bp['boxes'][i].get_ydata()[2]
            dict1['upper_whisker'] = bp['whiskers'][(i*2)+1].get_ydata()[1]
            rows_list.append(dict1)

        return pd.DataFrame(rows_list)

    def __get_medians(_dict, _lbls):
        medians = {}
        for _i, _l in enumerate(_lbls):
            medians[str(_l)] = _dict['medians'][_i].get_ydata()[1]
        return medians

    colors = {"Z":"tab:green", "N":"tab:red", "E":"tab:blue"}

    Nrow, Ncol = 2, 1

    font = 12

    ms1, ms2 = 10, 20

    scale, unit = 1e9, "nrad/hPa"

    hil = r"H[P]"

    fig = plt.figure(figsize=(10, 7))

    gs = GridSpec(Nrow, Ncol, figure=fig, hspace=0.25)

    ax1 = fig.add_subplot(gs[0])
    ax2 = fig.add_subplot(gs[1])

    # ___________________________________________________
    a_z, a_n, a_e = abs(df1Z.a_z*scale), abs(df1N.a_n*scale), abs(df1E.a_e*scale)
    b_z, b_n, b_e = abs(df1Z.b_z*scale), abs(df1N.b_n*scale), abs(df1E.b_e*scale)
    arr = [a_z, a_n, a_e, b_z, b_n, b_e]

    bp = ax1.boxplot(arr, showmeans=False)
    meds = __get_medians(bp, ['a_z', 'a_n', 'a_e', 'b_z', 'b_n', 'b_e'])
    lbls = [f"a$_Z$ \n (={int(meds['a_z'])})", f"a$_N$ \n (={int(meds['a_n'])})", f"a$_E$ \n (={int(meds['a_e'])})",
            f"b$_Z$ \n (={int(meds['b_z'])})", f"b$_N$ \n (={int(meds['b_n'])})", f"b$_E$ \n (={int(meds['b_e'])})"]

    ax1.set_xticklabels(lbls, fontsize=font)
    ax1.set_yscale("log")
    ax1.set_ylabel(f"compliance ({unit})", fontsize=font)

    ax1.text(.99, .1, f"{config['data1']}", ha='right', va='top', transform=ax1.transAxes, fontsize=font+2)

    # ___________________________________________________
    a_z, a_n, a_e = abs(df2Z.reg_a_z*0*scale), abs(df2N.reg_a_n*scale), abs(df2E.reg_a_e*scale)
    b_z, b_n, b_e = abs(df2Z.reg_b_z*0*scale), abs(df2N.reg_b_n*scale), abs(df2E.reg_b_e*scale)
    arr = [a_z, a_n, a_e, b_z, b_n, b_e]

    bp = ax2.boxplot(arr, showmeans=False)
    meds = __get_medians(bp, ['a_z', 'a_n', 'a_e', 'b_z', 'b_n', 'b_e'])
    lbls = [f"", f"a$_N$ \n (={int(meds['a_n'])})", f"a$_E$ \n (={int(meds['a_e'])})",
            f"", f"b$_N$ \n (={int(meds['b_n'])})", f"b$_E$ \n (={int(meds['b_e'])})"]

    ax2.set_yscale("log")
    ax2.set_xticklabels(lbls, fontsize=font)
    ax2.set_ylabel(f"compliance ({unit})", fontsize=font)

    ax2.text(.99, .1, f"{config['data2']}", ha='right', va='top', transform=ax2.transAxes, fontsize=font+2)

    # ___________________________________________________

    ax1.text(.005, .97, "(a)", ha='left', va='top', transform=ax1.transAxes, fontsize=font+2)
    ax2.text(.005, .97, "(b)", ha='left', va='top', transform=ax2.transAxes, fontsize=font+2)

    axes = [ax1, ax2]
    for ax in axes:
        ax.grid(ls="--", alpha=0.4, zorder=0)

    print(bp.keys())
    print(get_box_plot_data(["a_z", "a_n", "a_e", "b_z", "b_n", "b_e"], bp))

    plt.show();
    return fig

fig = __makeplot_reg();

fig.savefig(config['path_to_figs']+f"RB_statistic_coeff_{config['tbeg'].date}_{config['tend'].date}_reg.png", format="png", dpi=150, bbox_inches='tight')




