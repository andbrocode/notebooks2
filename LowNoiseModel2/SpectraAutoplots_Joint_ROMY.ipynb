{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda030d3",
   "metadata": {},
   "source": [
    "# Hourly PSDS - FFBI & ROMY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-presentation",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-arrangement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:54:03.050940Z",
     "start_time": "2023-08-07T14:54:00.312331Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "from scipy.signal import welch\n",
    "from numpy import log10, zeros, pi, append, linspace, mean, median, array, where, transpose, shape, histogram, arange\n",
    "from numpy import logspace, linspace, log, log10, isinf, ones, nan, count_nonzero, sqrt, isnan\n",
    "from pandas import DataFrame, concat, Series, date_range, read_csv, read_pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import os, sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions.get_fband_average import __get_fband_average\n",
    "from functions.replace_noise_psd_with_nan import __replace_noisy_psds_with_nan\n",
    "from functions.cut_frequencies_array import __cut_frequencies_array\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337911b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:54:03.147385Z",
     "start_time": "2023-08-07T14:54:03.133998Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == 'lighthouse':\n",
    "    root_path = '/home/andbro/'\n",
    "    data_path = '/home/andbro/kilauea-data/'\n",
    "    archive_path = '/home/andbro/freenas/'\n",
    "    bay_path = '/home/andbro/bay200/'\n",
    "elif os.uname().nodename == 'kilauea':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/bay200/'\n",
    "elif os.uname().nodename == 'lin-ffb-01':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/bay200/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-expression",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d365e8e0-a71e-4f0b-9961-89d24266d47d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['project'] = 2\n",
    "\n",
    "config['d1'], config['d2'] = \"2024-01-01\", \"2024-03-31\"\n",
    "\n",
    "config['path_to_data'] = data_path+f\"LNM2/PSDS{config['project']}/\"\n",
    "\n",
    "config['outpath_figures'] = data_path+f\"LNM2/figures{config['project']}/\"\n",
    "\n",
    "config['frequency_limits'] = 1e-3, 1e1\n",
    "\n",
    "config['year'] = config['d1'][:4]\n",
    "\n",
    "config['code'] = {1:\"B\", 2:\"L\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-beginning",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aeee3e-9810-4ffa-9db8-eed9e08bb878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __makeplot_colorlines_overview(config, ff, psds, rejected, names, day, show_rejected=True):\n",
    "\n",
    "    from tqdm.notebook import tqdm\n",
    "    from numpy import isnan, median, mean, std, array, zeros\n",
    "    from scipy.stats import median_abs_deviation as mad\n",
    "\n",
    "#     psds_median = __get_median_psd(array(psds))\n",
    "#     psds_minimal = __get_minimal_psd(array(psds))\n",
    "#     psds_minimum = __get_minimum_psd(array(psds), ff)\n",
    "\n",
    "\n",
    "    # ## convert frequencies to periods\n",
    "    # pp=[]\n",
    "    # for mm in range(len(ff)):\n",
    "    #     ppp = zeros(len(ff[mm]))\n",
    "    #     ppp = 1/ff[mm]\n",
    "    #     pp.append(ppp)\n",
    "\n",
    "\n",
    "    ##____________________________\n",
    "\n",
    "    NN = 5\n",
    "\n",
    "    fig, axes = plt.subplots(NN, 1, figsize=(12, 12), sharey=False, sharex=True)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "    font = 14\n",
    "\n",
    "    N = 24\n",
    "\n",
    "    colors = plt.cm.rainbow(linspace(0, 1, N))\n",
    "    cmap = plt.get_cmap('rainbow', 24)\n",
    "\n",
    "\n",
    "    for j in range(NN):\n",
    "\n",
    "        try:\n",
    "            for n, psd in enumerate(psds[j]):\n",
    "                if isnan(psd).all():\n",
    "                    continue\n",
    "                axes[j].loglog(ff[j], psd, color=colors[n], alpha=0.7)\n",
    "                p2 = axes[j].scatter(ff[j][0], psd[0], s=0., c=n/N, cmap=cmap, vmin=0, vmax=N, zorder=3)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if show_rejected:\n",
    "            for reject in rejected[j]:\n",
    "                axes[j].loglog(ff[j], reject, color='grey', alpha=0.8, zorder=2)\n",
    "\n",
    "        # axes[j].loglog(ff[j], __get_median_psd(psds[j]), 'black', zorder=3, alpha=0.6, label=\"Median\")\n",
    "\n",
    "        axes[NN-2].loglog(baro_lnm['frequency'], baro_lnm['nlnm_baro'], color=\"grey\", ls=\"--\", alpha=0.8)\n",
    "        axes[NN-2].loglog(baro_lnm['frequency'], baro_lnm['nhnm_baro'], color=\"grey\", ls=\"--\", alpha=0.8)\n",
    "\n",
    "        axes[NN-1].loglog(baro_lnm['frequency'], baro_lnm['nlnm_baro'], color=\"grey\", ls=\"--\", alpha=0.8)\n",
    "        axes[NN-1].loglog(baro_lnm['frequency'], baro_lnm['nhnm_baro'], color=\"grey\", ls=\"--\", alpha=0.8)\n",
    "\n",
    "        axes[j].set_xlim(1e-3, 2e0)\n",
    "        axes[j].grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "        # axes[j].legend(loc='lower left')\n",
    "        axes[j].tick_params(labelsize=font-2)\n",
    "\n",
    "\n",
    "    ## limits of sensor noise\n",
    "    # freq = arange(0.0001, 1, 0.001)\n",
    "    # plim1 = 0.1**2 * ones(len(freq)) / 12 / (0.5*0.1) ## resolution = 0.1 hPa @ 0.1Hz sampling\n",
    "    # plim2 = 0.1**2 * ones(len(freq)) / 12/ (0.5*1.0) ## resolution = 0.1 hPa @ 0.1Hz sampling\n",
    "\n",
    "    # plim1_1 = 0.1**2 * ones(len(freq)) / (0.5*0.1) ## resolution = 0.1 hPa @ 0.1Hz sampling\n",
    "    # plim2_1 = 0.1**2 * ones(len(freq)) / (0.5*1.0) ## resolution = 0.1 hPa @ 0.1Hz sampling\n",
    "\n",
    "    # axes[1].loglog(freq, plim1, color=\"black\", ls=\"--\", zorder=4, alpha=0.7)\n",
    "    # axes[2].loglog(freq, plim2, color=\"black\", ls=\"--\", zorder=4, alpha=0.7)\n",
    "\n",
    "    # axes[1].loglog(freq, plim1_1, color=\"black\", ls=\":\", zorder=4, alpha=0.7)\n",
    "    # axes[2].loglog(freq, plim2_1, color=\"black\", ls=\":\", zorder=4, alpha=0.7)\n",
    "\n",
    "    axes[0].plot(df_models.frequencies, df_models.nlnm_rot_rate, color=\"k\", ls=\"--\", alpha=0.6)\n",
    "    axes[1].plot(df_models.frequencies, df_models.nlnm_rot_rate, color=\"k\", ls=\"--\", alpha=0.6)\n",
    "    axes[2].plot(df_models.frequencies, df_models.nlnm_rot_rate, color=\"k\", ls=\"--\", alpha=0.6)\n",
    "\n",
    "    axes[NN-1].set_xlabel(\"Frequency (Hz)\", fontsize=font, labelpad=-1)\n",
    "\n",
    "    ## panel labels\n",
    "    axes[0].text(.01, .95, '(a)', ha='left', va='top', transform=axes[0].transAxes, fontsize=font)\n",
    "    axes[1].text(.01, .95, '(b)', ha='left', va='top', transform=axes[1].transAxes, fontsize=font)\n",
    "    axes[2].text(.01, .95, '(c)', ha='left', va='top', transform=axes[2].transAxes, fontsize=font)\n",
    "    axes[3].text(.01, .95, '(d)', ha='left', va='top', transform=axes[3].transAxes, fontsize=font)\n",
    "    axes[4].text(.01, .95, '(e)', ha='left', va='top', transform=axes[4].transAxes, fontsize=font)\n",
    "\n",
    "    sta, cha = names[0].split(\"_\")[-2], names[0].split(\"_\")[-1]\n",
    "    axes[0].text(.05, .95, f'{sta}.{cha}', ha='left', va='top', transform=axes[0].transAxes, fontsize=font)\n",
    "\n",
    "    sta, cha = names[1].split(\"_\")[-2], names[1].split(\"_\")[-1]\n",
    "    axes[1].text(.05, .95, f'{sta}.{cha}', ha='left', va='top', transform=axes[1].transAxes, fontsize=font)\n",
    "\n",
    "    sta, cha = names[2].split(\"_\")[-2], names[2].split(\"_\")[-1]\n",
    "    axes[2].text(.05, .95, f'{sta}.{cha}', ha='left', va='top', transform=axes[2].transAxes, fontsize=font)\n",
    "\n",
    "    sta, cha = names[3].split(\"_\")[-2], names[3].split(\"_\")[-1]\n",
    "    axes[3].text(.05, .95, f'{sta}.{cha}', ha='left', va='top', transform=axes[3].transAxes, fontsize=font)\n",
    "\n",
    "    sta, cha = names[4].split(\"_\")[-2], names[4].split(\"_\")[-1]\n",
    "    axes[4].text(.05, .95, f'{sta}.{cha}', ha='left', va='top', transform=axes[4].transAxes, fontsize=font)\n",
    "\n",
    "    axes[0].set_title(day, fontsize=font+2)\n",
    "\n",
    "    axes[0].set_ylim(bottom=1e-23, top=1e-16)\n",
    "    axes[1].set_ylim(bottom=1e-23, top=1e-16)\n",
    "    axes[2].set_ylim(bottom=1e-23, top=1e-16)\n",
    "    axes[3].set_ylim(bottom=1e-6, top=1e6)\n",
    "    axes[4].set_ylim(bottom=1e-6, top=1e6)\n",
    "\n",
    "    axes[0].set_ylabel(r\"PSD (rad$^2$/s$^2$/Hz)\", fontsize=font)\n",
    "    axes[1].set_ylabel(r\"PSD (rad$^2$/s$^2$/Hz)\", fontsize=font)\n",
    "    axes[2].set_ylabel(r\"PSD (rad$^2$/s$^2$/Hz)\", fontsize=font)\n",
    "    axes[3].set_ylabel(r\"PSD (Pa$^2$/Hz)\", fontsize=font)\n",
    "    axes[4].set_ylabel(r\"PSD (Pa$^2$/Hz)\", fontsize=font)\n",
    "\n",
    "    ## set colorbar at bottom\n",
    "    cbar = fig.colorbar(p2, orientation='vertical', ax=axes.ravel().tolist(), aspect=50, pad=-1e-5, ticks=arange(1,N,2))\n",
    "\n",
    "\n",
    "    plt.show();\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbb65f-be14-4a67-b49f-efb2eace1d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.get_fband_averages import __get_fband_averages\n",
    "from functions.replace_noise_psd_with_nan import __replace_noisy_psds_with_nan\n",
    "from functions.get_median_psd import __get_median_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d177db1-2ad6-408a-80e4-b6e1df299360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __replace_noisy_psds_with_nan(arr, ff, threshold_mean=None, flim=[None, None], threshold_min=None, threshold_max=None):\n",
    "\n",
    "    from numpy import delete, shape, sort, array, ones, nan, nanmean, array, isnan\n",
    "\n",
    "    arr = array(arr)\n",
    "\n",
    "    idx_min = 0\n",
    "    idx_max = arr.shape[1]-1\n",
    "\n",
    "    if flim[0] is not None and flim[1] is not None:\n",
    "\n",
    "        flim = array(flim)\n",
    "\n",
    "        for n, f in enumerate(ff):\n",
    "            if f > flim[0]:\n",
    "                if n == 0:\n",
    "                    idx_min = 0\n",
    "                else:\n",
    "                    idx_min = n-1\n",
    "                break\n",
    "        for n, f in enumerate(ff):\n",
    "            if f > flim[1]:\n",
    "                idx_max = n\n",
    "                break\n",
    "\n",
    "    l1 = shape(arr)[0]\n",
    "\n",
    "    rejected, all_nan = [], []\n",
    "    for ii in range(shape(arr)[0]):\n",
    "\n",
    "        if isnan(arr[ii, :]).all():\n",
    "            all_nan.append(arr[ii, :])\n",
    "            continue\n",
    "\n",
    "        ## appy upper threshold\n",
    "        if threshold_mean is not None:\n",
    "            if nanmean(arr[ii, idx_min:idx_max]) > threshold_mean:\n",
    "                # print(\"mean threshold\")\n",
    "                rejected.append(arr[ii, :])\n",
    "                arr[ii, :] = ones(shape(arr)[1]) * nan\n",
    "\n",
    "        ## appy minimum threshold\n",
    "        if threshold_min is not None:\n",
    "            if any(arr[ii, :] < threshold_min):\n",
    "                # print(\"min threshold\")\n",
    "                rejected.append(arr[ii, :])\n",
    "                arr[ii, :] = ones(shape(arr)[1]) * nan\n",
    "\n",
    "        ## appy maximum threshold\n",
    "        if threshold_max is not None:\n",
    "            if any(arr[ii, :] > threshold_max):\n",
    "                # print(\"max threshold\")\n",
    "                rejected.append(arr[ii, :])\n",
    "                arr[ii, :] = ones(shape(arr)[1]) * nan\n",
    "\n",
    "    l2 = len(rejected)\n",
    "    l3 = len(all_nan)\n",
    "\n",
    "    print(f\" -> {l3} are all NaN\")\n",
    "    print(f\" -> {l2} rows removed due to mean thresholds ({round(ff[idx_min],4)} and {round(ff[idx_max],4)} Hz)!\")\n",
    "    print(f\" -> {l1-l2-l3} / {l1} psds remain\")\n",
    "\n",
    "    return arr, rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff2634",
   "metadata": {},
   "source": [
    "## RUN for all files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824ef59-1498-405d-8dea-2330a5413237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baro_lnm = read_csv(data_path+f\"LNM2/data/\"+\"baro_nlnm_nhnm.csv\")\n",
    "\n",
    "baro_lnm['nlnm_baro'] = 10**(baro_lnm['nlnm_baro_db']/10)\n",
    "baro_lnm['nhnm_baro'] = 10**(baro_lnm['nhnm_baro_db']/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c849ed0-6ec0-4031-986f-1a1fb29a0379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_models = read_csv(data_path+\"LNM/data/FINAL/\"+\"TLNM_to_RLNM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3822839",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T16:31:13.609975Z",
     "start_time": "2023-08-07T16:23:41.306613Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "psds_medians_out, times_out = [], []\n",
    "\n",
    "rejected_dat1, rejected_dat2, rejected_dat3, rejected_dat4, rejected_dat5 = [], [], [], [], []\n",
    "\n",
    "for _i, day in enumerate(date_range(config['d1'], config['d2'])):\n",
    "\n",
    "    day = str(day).split(\" \")[0].replace(\"-\", \"\")\n",
    "\n",
    "    config['outpath_figname'] = \"joint_\"+day\n",
    "\n",
    "    # if _i > 0:\n",
    "    #     continue\n",
    "\n",
    "    # if os.path.isfile(config['outpath_figures']+config['outpath_figname']):\n",
    "    #     print(f\" -> skipping {config['outpath_figname']} ...\")\n",
    "    #     continue\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        ## Data1 --------------------------\n",
    "        print(\"\\nData1\")\n",
    "        name1 = f\"ROMY/{config['year']}_ROMY_BJZ\"\n",
    "\n",
    "        out = read_pickle(config['path_to_data']+f\"{name1}_3600_{day}_hourly.pkl\")\n",
    "        ff1, dat1 = out['frequencies'], out['psd']\n",
    "\n",
    "        ff1, dat1 = __get_fband_averages(ff1, dat1)\n",
    "\n",
    "        dat1, ff1 = __cut_frequencies_array(dat1, ff1, 1e-3, 2e0)\n",
    "\n",
    "        # dat1, rejected_dat1 = __replace_noisy_psds_with_nan(dat1, ff=ff1, threshold_mean=5e-19, threshold_min=1e-23, flim=[0.002, 0.01])\n",
    "        dat1, rejected_dat1 = __replace_noisy_psds_with_nan(dat1, ff=ff1,\n",
    "                                                            threshold_mean=1e-19,\n",
    "                                                            threshold_min=1e-23,\n",
    "                                                            threshold_max=1e-15,\n",
    "                                                            flim=[0.5, 0.9],\n",
    "                                                           )\n",
    "\n",
    "        if len(rejected_dat1) > 0:\n",
    "            _, rejected_dat1 = __get_fband_averages(ff1, rejected_dat1)\n",
    "\n",
    "        ## Data2 --------------------------\n",
    "        print(\"\\nData2\")\n",
    "        name2 = f\"ROMY/{config['year']}_ROMY_BJN\"\n",
    "\n",
    "        out = read_pickle(config['path_to_data']+f\"{name2}_3600_{day}_hourly.pkl\")\n",
    "        ff2, dat2 = out['frequencies'], out['psd']\n",
    "\n",
    "        dat2, ff2 = __cut_frequencies_array(dat2, ff2, 1e-3, 2e0)\n",
    "\n",
    "        ff2, dat2 = __get_fband_averages(ff2, dat2)\n",
    "\n",
    "        # dat2, rejected_dat2 = __replace_noisy_psds_with_nan(dat2, ff=ff2, threshold_mean=1e-18, threshold_min=1e-22, flim=[0.0009, 0.002])\n",
    "        dat2, rejected_dat2 = __replace_noisy_psds_with_nan(dat2, ff=ff2,\n",
    "                                                            threshold_mean=1e-19,\n",
    "                                                            threshold_min=1e-22,\n",
    "                                                            threshold_max=1e-15,\n",
    "                                                            flim=[0.5, 0.9],\n",
    "                                                           )\n",
    "\n",
    "        if len(rejected_dat2) > 0:\n",
    "            _, rejected_dat2 = __get_fband_averages(ff2, rejected_dat2)\n",
    "\n",
    "\n",
    "        ## Data3 --------------------------\n",
    "        print(\"\\nData3\")\n",
    "        name3 = f\"ROMY/{config['year']}_ROMY_BJE\"\n",
    "\n",
    "        out = read_pickle(config['path_to_data']+f\"{name3}_3600_{day}_hourly.pkl\")\n",
    "        ff3, dat3 = out['frequencies'], out['psd']\n",
    "\n",
    "        dat3, ff3 = __cut_frequencies_array(dat3, ff3, 1e-3, 2e0)\n",
    "\n",
    "        ff3, dat3 = __get_fband_averages(ff3, dat3)\n",
    "\n",
    "\n",
    "        dat3, rejected_dat3 = __replace_noisy_psds_with_nan(dat3, ff=ff3,\n",
    "                                                            threshold_mean=1e-19,\n",
    "                                                            threshold_min=1e-22,\n",
    "                                                            threshold_max=1e-15,\n",
    "                                                            flim=[0.5, 0.9],\n",
    "                                                           )\n",
    "        # dat3, rejected_dat3 = __replace_noisy_psds_with_nan(dat3, ff=ff3, threshold_mean=1e-19, threshold_min=1e-22, flim=[0.5, 0.9])\n",
    "\n",
    "        if len(rejected_dat3) > 0:\n",
    "            _, rejected_dat3 = __get_fband_averages(ff3, rejected_dat3)\n",
    "\n",
    "\n",
    "        ## Data4 --------------------------\n",
    "        print(\"\\nData4\")\n",
    "        name4 = f\"FFBI/{config['year']}_FFBI_{config['code'][config['project']]}DF\"\n",
    "\n",
    "        out = read_pickle(config['path_to_data']+f\"{name4}_3600_{day}_hourly.pkl\")\n",
    "        ff4, dat4 = out['frequencies'], out['psd']\n",
    "\n",
    "        dat4, ff4 = __cut_frequencies_array(dat4, ff4, 1e-3, 2e0)\n",
    "\n",
    "        ff4, dat4 = __get_fband_averages(ff4, dat4)\n",
    "\n",
    "\n",
    "        dat4, rejected_dat4 = __replace_noisy_psds_with_nan(dat4, ff=ff4, threshold_mean=1e7, threshold_min=1e-7, flim=[0.001, 1.0])\n",
    "\n",
    "        if len(rejected_dat4) > 0:\n",
    "            _, rejected_dat4 = __get_fband_averages(ff4, rejected_dat4)\n",
    "\n",
    "\n",
    "        ## Data5 --------------------------\n",
    "        print(\"\\nData5\")\n",
    "        name5 = f\"FFBI/{config['year']}_FFBI_{config['code'][config['project']]}DO\"\n",
    "\n",
    "        out = read_pickle(config['path_to_data']+f\"{name5}_3600_{day}_hourly.pkl\")\n",
    "        ff5, dat5 = out['frequencies'], out['psd']\n",
    "\n",
    "        dat5, ff5 = __cut_frequencies_array(dat5, ff5, 1e-3, 2e0)\n",
    "\n",
    "        ff5, dat5 = __get_fband_averages(ff5, dat5)\n",
    "\n",
    "\n",
    "        dat5, rejected_dat5 = __replace_noisy_psds_with_nan(dat5, ff=ff5, threshold_mean=1e7, threshold_min=1e-5, flim=[0.001, 1.0])\n",
    "\n",
    "        if len(rejected_dat5) > 0:\n",
    "            _, rejected_dat5 = __get_fband_averages(ff5, rejected_dat5)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\" -> exception !\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        fig = __makeplot_colorlines_overview(config,\n",
    "                                             [ff1, ff2, ff3, ff4, ff5],\n",
    "                                             [dat1, dat2, dat3, dat4, dat5],\n",
    "                                             [rejected_dat1, rejected_dat2, rejected_dat3, rejected_dat4, rejected_dat5],\n",
    "                                             [name1, name2, name3, name4, name5],\n",
    "                                             day,\n",
    "                                             show_rejected=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    ## define file appendix\n",
    "    app = f\"_{name1[-1]}{name2[-1]}{name3[-1]}\"\n",
    "\n",
    "    print(f\" -> saving: {config['outpath_figures']}{config['outpath_figname']}.png\")\n",
    "    fig.savefig(config['outpath_figures']+\"joint_ROMY/\"+config['outpath_figname']+f\"_ROMY{app}.png\", format=\"png\", transparent=False, bbox_inches='tight', dpi=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516868f-9ef6-409a-ad23-fd5377d71264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"\"\"spd-say \"Finished\" \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc99383-16fb-4751-bffa-89656ba9d4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
