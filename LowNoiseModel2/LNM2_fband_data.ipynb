{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda030d3",
   "metadata": {},
   "source": [
    "# Hourly PSDS - ROMY | FUR | TILT with FFBI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-presentation",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "behind-arrangement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:54:03.050940Z",
     "start_time": "2023-08-07T14:54:00.312331Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "from scipy.signal import welch\n",
    "from numpy import log10, zeros, pi, append, linspace, mean, median, array, where, transpose, shape, histogram, arange, nanmedian, append\n",
    "from numpy import logspace, linspace, log, log10, isinf, ones, nan, count_nonzero, sqrt, isnan, append\n",
    "from pandas import DataFrame, concat, Series, date_range, read_csv, read_pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import os, sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from andbro__store_as_pickle import __store_as_pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f337911b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:54:03.147385Z",
     "start_time": "2023-08-07T14:54:03.133998Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == 'lighthouse':\n",
    "    root_path = '/home/andbro/'\n",
    "    data_path = '/home/andbro/kilauea-data/'\n",
    "    archive_path = '/home/andbro/freenas/'\n",
    "elif os.uname().nodename == 'kilauea':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-expression",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55978bc3-b134-4518-8da9-3689e9606971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T15:31:55.890800Z",
     "start_time": "2023-08-07T15:31:55.885708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## _____________________\n",
    "## pressure data\n",
    "# name, comp, app = \"PROMY\", \"\", \"\"\n",
    "# name, comp, app = \"FFBI\", \"BDF\", \"\"\n",
    "# name, comp, app = \"FFBI\", \"BDO\", \"\"\n",
    "\n",
    "## _____________________\n",
    "## ROMY data\n",
    "# name, comp, app = \"ROMY\", \"BJZ\", \"\"\n",
    "# name, comp, app = \"ROMY\", \"BJU\", \"\"\n",
    "# name, comp, app = \"ROMY\", \"BJV\", \"\"\n",
    "# name, comp, app = \"ROMY\", \"BJN\", \"\"\n",
    "# name, comp, app = \"ROMY\", \"BJE\", \"\"\n",
    "\n",
    "# name, comp, app = \"ROMY\", \"BAE\", \"\"\n",
    "\n",
    "\n",
    "## _____________________\n",
    "## FUR data\n",
    "# name, comp, app = \"FUR\", \"BHZ\", \"\"\n",
    "# name, comp, app = \"FUR\", \"BHN\", \"\"\n",
    "# name, comp, app = \"FUR\", \"BHE\", \"\"\n",
    "\n",
    "## _____________________\n",
    "## TILT data\n",
    "# name, comp, app = \"DROMY\", \"LAN\", \"\"\n",
    "# name, comp, app = \"DROMY\", \"LAE\", \"\"\n",
    "# name, comp, app = \"DROMY\", \"LAT\", \"\"\n",
    "\n",
    "\n",
    "## _____________________\n",
    "## coherence data\n",
    "# name, comp, app = \"ROMY\", \"BJZ\", \"_coherence\"\n",
    "# name, comp, app = \"ROMY\", \"BJU\", \"_coherence\"\n",
    "# name, comp, app = \"ROMY\", \"BJV\", \"_coherence\"\n",
    "# name, comp, app = \"ROMY\", \"BJN\", \"_coherence\"\n",
    "# name, comp, app = \"ROMY\", \"BJE\", \"_coherence\"\n",
    "\n",
    "# name, comp, app = \"ROMY\", \"BAE\", \"_coherence\"\n",
    "# name, comp, app = \"ROMY\", \"BAN\", \"_coherence\"\n",
    "name, comp, app = \"ROMY\", \"BAZ\", \"_coherence\"\n",
    "\n",
    "\n",
    "# name, comp, app = \"FUR\", \"BHZ\", \"_coherence\"\n",
    "# name, comp, app = \"FUR\", \"BHN\", \"_coherence\"\n",
    "# name, comp, app = \"FUR\", \"BHE\", \"_coherence\"\n",
    "\n",
    "# name, comp, app = \"DROMY\", \"LAN\", \"_coherence\"\n",
    "# name, comp, app = \"DROMY\", \"LAE\", \"_coherence\"\n",
    "\n",
    "name0 = \"BDO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73d35bd9-5242-4a57-a910-3cb0e03fc774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T15:31:55.890800Z",
     "start_time": "2023-08-07T15:31:55.885708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['year'] = \"2023\"\n",
    "\n",
    "config['path'] = data_path+f\"LNM2/PSDS/\"\n",
    "\n",
    "config['startdate'], config['enddate'] = \"2023-10-01\", \"2023-11-30\"\n",
    "\n",
    "## specify paths\n",
    "config['outpath_figures'] = data_path+f\"LNM2/figures/\"\n",
    "\n",
    "config['path_to_outdata'] = data_path+f\"LNM2/data/\"\n",
    "\n",
    "if \"coherence\" in app:\n",
    "    config['filename'] = f\"{name}{app}/{config['year']}_FFBI_{name0}_{name}_{comp}_3600\"\n",
    "    config['outname'] = f\"{name}_{comp}_coherence\"\n",
    "else:\n",
    "    config['filename'] = f\"{name}{app}/{config['year']}_{name}_{comp}_3600\"\n",
    "    config['outname'] = f\"{name}_{comp}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-beginning",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b42d3dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T15:31:57.679758Z",
     "start_time": "2023-08-07T15:31:57.677330Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __load_data_file(path, file):\n",
    "\n",
    "    from tqdm.notebook import tqdm\n",
    "    from numpy import array\n",
    "\n",
    "    psds_all = []\n",
    "\n",
    "    datafile = read_pickle(path+file)\n",
    "\n",
    "    try:\n",
    "        psds = datafile['psd']\n",
    "    except:\n",
    "        psds = datafile['coherence']\n",
    "\n",
    "    ff = datafile['frequencies']\n",
    "\n",
    "    del datafile\n",
    "\n",
    "    for psd in psds:\n",
    "        psds_all.append(psd)\n",
    "\n",
    "    return ff, psds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e039344-731c-494b-b850-232a39a92e9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute PSD value per frequency band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477bdeb-1ae9-473e-ab30-3677533e4d93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231001_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231002_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231003_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231004_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231005_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231006_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231007_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231008_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231009_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231010_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231011_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231012_hourly.pkl\n",
      "ROMY_coherence/2023_FFBI_BDO_ROMY_BAZ_3600_20231013_hourly.pkl\n"
     ]
    }
   ],
   "source": [
    "d1, d2 = config['startdate'], config['enddate']\n",
    "\n",
    "psds_medians_out, times_out = [], []\n",
    "\n",
    "dat, dates = [], []\n",
    "# dat = ones((date_range(d1, d2).size*24, 36002))*nan\n",
    "# dates = ones((date_range(d1, d2).size*24))*nan\n",
    "index = 0\n",
    "for jj, day in enumerate(date_range(d1, d2)):\n",
    "\n",
    "#     if jj > 4:\n",
    "#         continue\n",
    "\n",
    "    day = str(day).split(\" \")[0].replace(\"-\", \"\")\n",
    "\n",
    "    print(f\"{config['filename']}_{day}_hourly.pkl\")\n",
    "\n",
    "    try:\n",
    "        ff, _dat = __load_data_file(config['path'], f\"{config['filename']}_{day}_hourly.pkl\")\n",
    "        # _dat, _rejected = __remove_noisy_psds(_dat, threshold_mean=1e-15, ff=ff1, flim=0.1)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        print(f\" -> {day}: no data found\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        for _k, _psd in enumerate(_dat):\n",
    "            dat.append(_psd)\n",
    "            dates.append(f\"{day}_{str(_k).rjust(2, '0')}\")\n",
    "            # dat[index] = _psd\n",
    "            # dates[index] = f\"{day}_{str(_k).rjust(2, '0')}\"\n",
    "            index += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\" -> skip {day}\")\n",
    "        continue\n",
    "\n",
    "# dat = array(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f44d75-1f36-46f6-9b6a-8c895a4818fb",
   "metadata": {},
   "source": [
    "### Get frequency bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a6865-d65f-4f1e-a931-fffb7fb5bffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.get_octave_bands import __get_octave_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b28fb-2375-44a1-80c9-88831cadc9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_lower, f_upper, f_center = __get_octave_bands(1e-3, 1e0, faction_of_octave=12, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63082a8c-871b-4df8-87e9-ea706993a993",
   "metadata": {},
   "source": [
    "### Get PSD average for frequency bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cf5f9-a7cf-478c-8a32-bf02a1ec71be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __get_band_average(freq, data, f_center, f_upper, f_lower):\n",
    "\n",
    "    ## get frequency indices\n",
    "    fl_idx, fu_idx = [], []\n",
    "\n",
    "    for _k, (fl, fu) in enumerate(zip(f_lower, f_upper)):\n",
    "        if _k <= len(f_center):\n",
    "\n",
    "            for _i, _f in enumerate(freq):\n",
    "                if _f >= fl:\n",
    "                    fl_idx.append(int(_i))\n",
    "                    break\n",
    "\n",
    "            for _i, _f in enumerate(freq):\n",
    "                if _f >= fu:\n",
    "                    fu_idx.append(int(_i))\n",
    "                    break\n",
    "\n",
    "    ## compute average per band\n",
    "    psd_avg, fc, fu, fl = [], [], [], []\n",
    "    for _n, (ifl, ifu) in enumerate(zip(fl_idx, fu_idx)):\n",
    "\n",
    "        avg = []\n",
    "        for _psd in data:\n",
    "            avg.append(nanmedian(_psd[ifl:ifu]))\n",
    "\n",
    "        psd_avg.append(array(avg))\n",
    "        fc.append(f_center[_n])\n",
    "        fu.append(f_upper[_n])\n",
    "        fl.append(f_lower[_n])\n",
    "\n",
    "    psd_avg = array(psd_avg)\n",
    "\n",
    "\n",
    "    ## check up plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for _j, dd in enumerate(psd_avg):\n",
    "        plt.scatter(ones(len(dd))*fc[_j], dd, s=5)\n",
    "        plt.xscale(\"log\")\n",
    "        if not \"_coherence\" in app:\n",
    "            plt.yscale(\"log\")\n",
    "        else:\n",
    "            plt.ylim(-0.1, 1.1)\n",
    "\n",
    "    plt.show();\n",
    "\n",
    "\n",
    "    ## output\n",
    "    out = {}\n",
    "    out['psd_avg'] = psd_avg\n",
    "    out['fcenter'] = array(fc)\n",
    "    out['fupper'] = array(fu)\n",
    "    out['flower'] = array(fl)\n",
    "    out['dates'] = dates\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a4dec-c5a2-4a0a-bc6d-1667827a730d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out0 = __get_band_average(ff, dat, f_center, f_upper, f_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c45c62c-8af2-4eff-ae9e-8ddabe9e9564",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ca1a0-6fc5-40c4-b919-ef5f58f36766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create and fill data frame\n",
    "_df_out = DataFrame()\n",
    "\n",
    "_df_out['dates'] = out0['dates']\n",
    "\n",
    "for _i, fc in enumerate(out0['fcenter']):\n",
    "    _df_out[round(fc, 5)] = out0['psd_avg'][_i]\n",
    "\n",
    "df_out = _df_out.copy()\n",
    "\n",
    "## store as pickle file\n",
    "print(f\" -> {config['outname']}.pkl\")\n",
    "df_out.to_pickle(config['path_to_outdata']+config['outname']+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7a0b6-2ff1-409a-9f99-a3cc4c54ea1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.system(\"\"\"spd-say \"Finished\" \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc4223-43fc-4b4d-8af5-5b1340fd151b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4072e9bb-c895-4794-a67b-3f6c341d5724",
   "metadata": {},
   "source": [
    "## Plot Density Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2dd005-8b93-45cb-8f02-ca1ad9869c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.get_hist_loglog import __get_hist_loglog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d509c3e-46e0-471a-bf5d-c9937259bdad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = __get_hist_loglog(dat, ff, bins=100, density=False, axis=1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086223cb-c996-42ef-a575-f6f13c2731f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad7415-00f0-45b7-842d-43442a977b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pickle\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# from obspy import UTCDateTime, read, read_inventory\n",
    "# from obspy.signal.rotate import rotate2zne\n",
    "# from numpy import log10, zeros, append, linspace, mean, median, array, where, transpose, shape, histogram\n",
    "# from pandas import DataFrame, concat, Series, date_range, to_pickle\n",
    "# from pathlib import Path\n",
    "# from scipy.signal import coherence, welch\n",
    "\n",
    "# from andbro__read_sds import __read_sds\n",
    "# from andbro__readYaml import __readYaml\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# if os.uname().nodename == 'lighthouse':\n",
    "#     root_path = '/home/andbro/'\n",
    "#     data_path = '/home/andbro/kilauea-data/'\n",
    "#     archive_path = '/home/andbro/freenas/'\n",
    "#     bay_path = '/home/andbro/bay200/'\n",
    "# elif os.uname().nodename == 'kilauea':\n",
    "#     root_path = '/home/brotzer/'\n",
    "#     data_path = '/import/kilauea-data/'\n",
    "#     archive_path = '/import/freenas-ffb-01-data/'\n",
    "#     bay_path = '/bay200/'\n",
    "# elif os.uname().nodename == 'lin-ffb-01':\n",
    "#     root_path = '/home/brotzer/'\n",
    "#     data_path = '/import/kilauea-data/'\n",
    "#     archive_path = '/import/freenas-ffb-01-data/'\n",
    "#     bay_path = '/bay200/'\n",
    "\n",
    "# # In[] ___________________________________________________________\n",
    "# ''' ---- set variables ---- '''\n",
    "\n",
    "# config = {}\n",
    "\n",
    "\n",
    "# config['year'] = 2023\n",
    "\n",
    "\n",
    "# config['seed1'] = \"BW.FFBI..BDO\"  ## F = infrasound | O = absolute\n",
    "\n",
    "\n",
    "# config['seed2'] = \"GR.FUR..BHZ\"\n",
    "\n",
    "# config['date1'] = UTCDateTime(f\"{config['year']}-09-23\")\n",
    "# config['date2'] = UTCDateTime(f\"{config['year']}-09-23\")\n",
    "\n",
    "# config['path_to_data1'] = bay_path+f\"mseed_online/archive/\"\n",
    "# config['path_to_inv1'] = root_path+\"Documents/ROMY/ROMY_infrasound/station_BW_FFBI.xml\"\n",
    "\n",
    "# if \"FUR\" in config['seed2']:\n",
    "#     config['path_to_data2'] = bay_path+f\"mseed_online/archive/\"\n",
    "#     config['path_to_inv2'] = root_path+\"Documents/ROMY/stationxml_ringlaser/dataless.seed.GR_FUR\"\n",
    "# elif \"ROMY\" in config['seed2']:\n",
    "#     config['path_to_data2'] = archive_path+f\"romy_archive/\"\n",
    "#     config['path_to_inv2'] = root_path+\"Documents/ROMY/stationxml_ringlaser/dataless.seed.BW_ROMY\"\n",
    "\n",
    "\n",
    "# ## specify unit\n",
    "# config['unit'] = \"Pa\" ## hPa or Pa or None\n",
    "\n",
    "# config['interval_seconds'] = 3600 ## in seconds\n",
    "# config['interval_overlap'] = 0  ## in seconds\n",
    "\n",
    "# ## __________________________\n",
    "# ## choose psd method\n",
    "# config['mode'] = \"multitaper\"  ## \"multitaper\" | \"welch\"\n",
    "\n",
    "# ## __________________________\n",
    "# ## set welch and coherence settings\n",
    "\n",
    "# config['taper'] = 'hann'\n",
    "# config['tseconds'] = 3600 ## seconds\n",
    "# config['toverlap'] = 0 ## 0.75\n",
    "# config['nfft'] = None\n",
    "# config['detrend'] = 'constant'\n",
    "# config['scaling'] = 'density'\n",
    "# config['onesided'] = True\n",
    "# config['frequency_limits'] = None # (0, 0.05) # in Hz\n",
    "\n",
    "# ## __________________________\n",
    "# ## set multitaper settings\n",
    "\n",
    "# ## number of taper for multitaper to use\n",
    "# config['n_taper'] = 5\n",
    "\n",
    "\n",
    "# config['sta1'] = config['seed1'].split(\".\")[1]\n",
    "# config['sta2'] = config['seed2'].split(\".\")[1]\n",
    "\n",
    "# config['cha1'] = config['seed1'].split(\".\")[3]\n",
    "# config['cha2'] = config['seed2'].split(\".\")[3]\n",
    "\n",
    "# config['outname1'] = f\"{config['year']}_{config['sta1']}_{config['cha1']}_{config['interval_seconds']}\"\n",
    "# config['outname2'] = f\"{config['year']}_{config['sta2']}_{config['cha2']}_{config['interval_seconds']}\"\n",
    "# config['outname3'] = f\"{config['year']}_{config['sta1']}_{config['cha1']}_{config['sta2']}_{config['cha2']}_{config['interval_seconds']}\"\n",
    "\n",
    "# config['outpath1'] = data_path+f\"LNM2/PSDS/{config['sta1']}/\"\n",
    "# config['outpath2'] = data_path+f\"LNM2/PSDS/{config['sta2']}/\"\n",
    "# config['outpath3'] = data_path+f\"LNM2/PSDS/{config['sta2']}_coherence/\"\n",
    "\n",
    "# ## tiltmeter configurations\n",
    "# confTilt = __readYaml(f\"{root_path}Documents/ROMY/tiltmeter/\", \"tiltmeter.conf\")\n",
    "\n",
    "\n",
    "# # In[] ___________________________________________________________\n",
    "# '''---- define methods ----'''\n",
    "\n",
    "# def __multitaper_psd(arr, dt, n_win=5, time_bandwidth=4.0):\n",
    "\n",
    "#     import multitaper as mt\n",
    "\n",
    "#     out_psd = mt.MTSpec(arr, nw=time_bandwidth, kspec=n_win, dt=dt, iadapt=0)\n",
    "\n",
    "#     _f, _psd = out_psd.rspec()\n",
    "\n",
    "#     f = _f.reshape(_f.size)\n",
    "#     psd = _psd.reshape(_psd.size)\n",
    "\n",
    "\n",
    "#     return f, psd\n",
    "\n",
    "\n",
    "\n",
    "# def __write_to_csv(data, text, config):\n",
    "\n",
    "#     import csv\n",
    "\n",
    "#     opath = config['outpath']\n",
    "#     oname = config['outname']+\"_\"+text+\"_psd.csv\"\n",
    "\n",
    "#     # open the file in the write mode\n",
    "#     with open(opath+oname, 'w') as file:\n",
    "\n",
    "#         writer = csv.writer(file)\n",
    "#         for row in data:\n",
    "#             writer.writerow(row)\n",
    "\n",
    "#     if Path(opath+oname).exists():\n",
    "#         print(f\"created: {opath}{oname}\")\n",
    "\n",
    "\n",
    "# def __save_to_pickle(obj, path, name):\n",
    "\n",
    "#     ofile = open(path+name+\".pkl\", 'wb')\n",
    "#     pickle.dump(obj, ofile)\n",
    "\n",
    "#     if Path(path+name+\".pkl\").exists():\n",
    "#         print(f\"\\n -> created:  {path}{name}.pkl\")\n",
    "\n",
    "\n",
    "# def __get_time_intervals(tbeg, tend, interval_seconds, interval_overlap):\n",
    "\n",
    "#     from obspy import UTCDateTime\n",
    "\n",
    "#     tbeg, tend = UTCDateTime(tbeg), UTCDateTime(tend)\n",
    "\n",
    "#     times = []\n",
    "#     t1, t2 = tbeg, tbeg + interval_seconds\n",
    "#     while t2 <= tend:\n",
    "#         times.append((t1, t2))\n",
    "#         t1 = t1 + interval_seconds - interval_overlap\n",
    "#         t2 = t2 + interval_seconds - interval_overlap\n",
    "\n",
    "#     return times\n",
    "\n",
    "\n",
    "# def __conversion_to_tilt(st, conf):\n",
    "\n",
    "#     st0 = st.copy()\n",
    "\n",
    "#     def convertTemp(trace):\n",
    "#         Tvolt = trace.data * conf.get('gainTemp')\n",
    "#         coeff = conf.get('calcTempCoefficients')\n",
    "#         return coeff[0] + coeff[1]*Tvolt + coeff[2]*Tvolt**2 + coeff[3]*Tvolt**3\n",
    "\n",
    "#     def convertTilt(trace, conversion, sensitivity):\n",
    "#         return trace.data * conversion * sensitivity\n",
    "\n",
    "#     for tr in st0:\n",
    "#         if tr.stats.channel[-1] == 'T':\n",
    "#             tr.data = convertTemp(tr)\n",
    "#         elif tr.stats.channel[-1] == 'N':\n",
    "#             tr.data = convertTilt(tr, conf['convTN'], conf['gainTilt'])\n",
    "#         elif tr.stats.channel[-1] == 'E':\n",
    "#             tr.data = convertTilt(tr, conf['convTE'], conf['gainTilt'])\n",
    "#         else:\n",
    "#             print(\"no match\")\n",
    "\n",
    "#     print(f\"  -> converted data of {st[0].stats.station}\")\n",
    "#     return st0\n",
    "\n",
    "\n",
    "# # In[] ___________________________________________________________\n",
    "\n",
    "\n",
    "# days = int((config['date2'] - config['date1'])/86400)+1\n",
    "\n",
    "# if not Path(config['outpath1']).exists():\n",
    "#     Path(config['outpath1']).mkdir()\n",
    "#     print(f\" -> created {config['outpath1']}\")\n",
    "\n",
    "# if not Path(config['outpath2']).exists():\n",
    "#     Path(config['outpath2']).mkdir()\n",
    "#     print(f\" -> created {config['outpath2']}\")\n",
    "\n",
    "\n",
    "# minimum_collection = []\n",
    "# minimal_collection = []\n",
    "# columns = []\n",
    "# medians, dd = [], []\n",
    "\n",
    "# for date in date_range(str(config['date1'].date), str(config['date2'].date), days):\n",
    "\n",
    "#     print(f\"\\nprocessing  {str(date)[:10]}...\")\n",
    "\n",
    "\n",
    "#     ## load data for the entire day\n",
    "#     config['tbeg'] = UTCDateTime(date)\n",
    "#     config['tend'] = UTCDateTime(date) + 86400\n",
    "\n",
    "#     try:\n",
    "#         st1 = __read_sds(config['path_to_data1'], config['seed1'], config['tbeg']-1800, config['tend']+1800)\n",
    "#         st2 = __read_sds(config['path_to_data2'], config['seed2'], config['tbeg']-1800, config['tend']+1800)\n",
    "#     except:\n",
    "#         print(f\" -> failed to load data ...\")\n",
    "#         continue\n",
    "\n",
    "\n",
    "\n",
    "#     ## read inventories\n",
    "#     try:\n",
    "#         inv1 = read_inventory(config['path_to_inv1'])\n",
    "#         inv2 = read_inventory(config['path_to_inv2'])\n",
    "#     except:\n",
    "#         print(f\" -> failed to load inventory ...\")\n",
    "#         continue\n",
    "\n",
    "#     if \"BW.ROMY\" in config['seed2'] and \"Z\" not in config['seed2']:\n",
    "#         try:\n",
    "#             _stU = __read_sds(config['path_to_data2'], \"BW.ROMY..BJU\", config['tbeg']-10, config['tend']+10)\n",
    "#             _stV = __read_sds(config['path_to_data2'], \"BW.ROMY..BJV\", config['tbeg']-10, config['tend']+10)\n",
    "#             _stZ = __read_sds(config['path_to_data2'], \"BW.ROMY.10.BJZ\", config['tbeg']-10, config['tend']+10)\n",
    "\n",
    "#             print(_stU, _stV, _stZ)\n",
    "\n",
    "#             ori_z = inv2.get_orientation(\"BW.ROMY.10.BJZ\")\n",
    "#             ori_u = inv2.get_orientation(\"BW.ROMY..BJU\")\n",
    "#             ori_v = inv2.get_orientation(\"BW.ROMY..BJV\")\n",
    "\n",
    "#             romy_z, romy_n, romy_e = rotate2zne(\n",
    "#                                                _stZ[0].data, ori_z['azimuth'], ori_z['dip'],\n",
    "#                                                _stU[0].data, ori_u['azimuth'], ori_u['dip'],\n",
    "#                                                _stV[0].data, ori_v['azimuth'], ori_v['dip'],\n",
    "#                                                inverse=False\n",
    "#                                               )\n",
    "\n",
    "#             if \"N\" in config['seed2']:\n",
    "#                 _stU[0].data = romy_n\n",
    "#                 st2 = _stU.copy()\n",
    "#                 # st2.select(channel=\"*U\")[0].stats.channel = \"BJN\"\n",
    "\n",
    "#             elif \"E\" in config['seed2']:\n",
    "#                 _stV[0].data = romy_e\n",
    "#                 st2 = _stV.copy()\n",
    "#                 # st2.select(channel=\"*V\")[0].stats.channel = \"BJE\"\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             print(f\" -> failed to rotate ROMY ...\")\n",
    "#             continue\n",
    "\n",
    "\n",
    "#     if len(st1) > 1:\n",
    "#         st1.merge()\n",
    "#     if len(st2) > 1:\n",
    "#         st2.merge()\n",
    "\n",
    "#     if len(st1) == 0 or len(st2) == 0:\n",
    "#         print(st1)\n",
    "#         print(st2)\n",
    "#         continue\n",
    "\n",
    "#     ## conversion\n",
    "#     if \"O\" in st1[0].stats.channel:\n",
    "\n",
    "#         if config['unit'] == \"Pa\":\n",
    "#             for tr in st1:\n",
    "#                 tr.data = tr.data *1.589e-6 *1e5   # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity_mb2005 = 1 mV/hPa\n",
    "#         elif config['unit'] == \"hPa\":\n",
    "#             for tr in st1:\n",
    "#                 tr.data = tr.data *1.589e-6 *1e3   # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity_mb2005 = 1 mV/hPa\n",
    "\n",
    "\n",
    "\n",
    "#     elif \"F\" in st1[0].stats.channel:\n",
    "# #            for tr in st1:\n",
    "# #                tr.data = tr.data *1.589e-6 /0.02  # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity_mb2005=0.02 V/Pa\n",
    "#         st1 = st1.remove_response(inv1, water_level=10)\n",
    "\n",
    "#     if \"J\" in st2[0].stats.channel:\n",
    "#         st2 = st2.remove_sensitivity(inv2)\n",
    "\n",
    "#     elif \"H\" in st2[0].stats.channel:\n",
    "#         st2 = st2.remove_response(inv2, output=\"ACC\", water_level=10)\n",
    "\n",
    "#     elif \"A\" in st2[0].stats.channel:\n",
    "#         st2 = __conversion_to_tilt(st2, confTilt[\"BROMY\"])\n",
    "\n",
    "#     ## Pre-Processing\n",
    "#     try:\n",
    "#         st1 = st1.split()\n",
    "#         st2 = st2.split()\n",
    "\n",
    "\n",
    "#         if \"BW.DROMY\" in config['seed2']:\n",
    "#             st2 = st2.filter(\"lowpass\", freq=0.25, corners=4, zerophase=True)\n",
    "#             st2 = st2.decimate(2, no_filter=True) ## 1 -> 0.5 Hz\n",
    "\n",
    "#             st1 = st1.filter(\"lowpass\", freq=0.25, corners=4, zerophase=True)\n",
    "#             st1 = st1.decimate(2, no_filter=True) ## 40 -> 20 Hz\n",
    "#             st1 = st1.decimate(2, no_filter=True) ## 20 -> 10 Hz\n",
    "#             st1 = st1.decimate(2, no_filter=True) ## 10 -> 5 Hz\n",
    "#             st1 = st1.decimate(5, no_filter=True) ## 5 -> 1 Hz\n",
    "#             st1 = st1.decimate(2, no_filter=True) ## 1 -> 0.5 Hz\n",
    "\n",
    "#             ## convert tilt to acceleration\n",
    "#             for tr in st2:\n",
    "#                 tr.data = tr.data*9.81\n",
    "\n",
    "#         else:\n",
    "\n",
    "#             # st1.detrend(\"demean\")\n",
    "#             # st2.detrend(\"demean\")\n",
    "#             # st1.taper(0.01)\n",
    "#             # st2.taper(0.01)\n",
    "\n",
    "#             st1 = st1.filter(\"lowpass\", freq=5, corners=4, zerophase=True)\n",
    "#             st2 = st2.filter(\"lowpass\", freq=5, corners=4, zerophase=True)\n",
    "\n",
    "#             st1 = st1.decimate(2, no_filter=True) ## 40 -> 20 Hz\n",
    "#             st1 = st1.decimate(2, no_filter=True) ## 40 -> 20 Hz\n",
    "#             st2 = st2.decimate(2, no_filter=True) ## 40 -> 20 Hz\n",
    "#             # st1 = st1.resample(20.0, no_filter=False)\n",
    "#             # st2 = st2.resample(20.0, no_filter=False)\n",
    "\n",
    "\n",
    "#         st1 = st1.merge()\n",
    "#         st2 = st2.merge()\n",
    "\n",
    "#         st1 = st1.trim(config['tbeg'], config['tend'])\n",
    "#         st2 = st2.trim(config['tbeg'], config['tend'])\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(f\" -> pre-processing failed!\")\n",
    "#         continue\n",
    "\n",
    "#     # st1.plot(equal_scale=False);\n",
    "#     # st2.plot(equal_scale=False);\n",
    "\n",
    "#     ## prepare time intervals\n",
    "#     times = __get_time_intervals(config['tbeg'], config['tend'], config['interval_seconds'], config['interval_overlap'])\n",
    "\n",
    "#     ## prepare psd parameters\n",
    "#     config['nperseg'] = int(st1[0].stats.sampling_rate*config.get('tseconds'))\n",
    "#     config['noverlap'] = int(0.5*config.get('nperseg'))\n",
    "\n",
    "\n",
    "#     print(st1)\n",
    "#     print(st2)\n",
    "\n",
    "\n",
    "#     if len(st1[0].data) != len(st2[0].data):\n",
    "#         print(\" -> not sampe amount of samples!\")\n",
    "#         continue\n",
    "\n",
    "\n",
    "#     ## run operations for time intervals\n",
    "#     for n, (t1, t2) in enumerate(times):\n",
    "\n",
    "#         ## trim streams for current interval\n",
    "#         _st1 = st1.copy().trim(t1, t2, nearest_sample=False)\n",
    "#         _st2 = st2.copy().trim(t1, t2, nearest_sample=False)\n",
    "\n",
    "# #            print(\"st: \", _st1[0].data.size, _st2[0].data.size)\n",
    "\n",
    "#         if n == 0:\n",
    "#             ## prepare lists\n",
    "#             if config['mode'] == \"welch\":\n",
    "#                 psds1 = zeros([len(times), int(config.get('nperseg')/2)+1])\n",
    "#                 psds2 = zeros([len(times), int(config.get('nperseg')/2)+1])\n",
    "#                 cohs = zeros([len(times), int(config.get('nperseg')/2)+1])\n",
    "#             elif config['mode'] == \"multitaper\":\n",
    "#                 # psds1 = zeros([len(times), int((config['interval_seconds']*20))])\n",
    "#                 # psds2 = zeros([len(times), int((config['interval_seconds']*20))])\n",
    "#                 # cohs = zeros([len(times), int(config.get('nperseg')/2)])\n",
    "#                 psds1 = zeros([len(times), int(_st1[0].stats.npts)+1])\n",
    "#                 psds2 = zeros([len(times), int(_st2[0].stats.npts)+1])\n",
    "#                 cohs = zeros([len(times), int(config.get('nperseg')/2)+1])\n",
    "\n",
    "\n",
    "#         ## compute power spectra\n",
    "#         if config['mode'] == \"welch\":\n",
    "\n",
    "#             f1, psd1 = welch(\n",
    "#                             _st1[0].data,\n",
    "#                             fs=_st1[0].stats.sampling_rate,\n",
    "#                             window=config.get('taper'),\n",
    "#                             nperseg=config.get('nperseg'),\n",
    "#                             noverlap=config.get('noverlap'),\n",
    "#                             nfft=config.get('nfft'),\n",
    "#                             detrend=config.get('detrend'),\n",
    "#                             return_onesided=config.get('onesided'),\n",
    "#                             scaling=config.get('scaling'),\n",
    "#                            )\n",
    "\n",
    "#             f2, psd2 = welch(\n",
    "#                             _st2[0].data,\n",
    "#                             fs=_st2[0].stats.sampling_rate,\n",
    "#                             window=config.get('taper'),\n",
    "#                             nperseg=config.get('nperseg'),\n",
    "#                             noverlap=config.get('noverlap'),\n",
    "#                             nfft=config.get('nfft'),\n",
    "#                             detrend=config.get('detrend'),\n",
    "#                             return_onesided=config.get('onesided'),\n",
    "#                             scaling=config.get('scaling'),\n",
    "#                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5d6f7-06fd-4144-b2cc-a03fe05e7964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from multitaper import MTCross, MTSpec\n",
    "\n",
    "# f1, psd1 = __multitaper_psd(_st1[0].data, _st1[0].stats.delta, n_win=config.get(\"n_taper\"), time_bandwidth=3)\n",
    "\n",
    "# f2, psd2 = __multitaper_psd(_st2[0].data, _st2[0].stats.delta, n_win=config.get(\"n_taper\"), time_bandwidth=3)\n",
    "\n",
    "# psds1[n] = psd1\n",
    "# psds2[n] = psd2\n",
    "\n",
    "# # _st1.detrend(\"demean\")\n",
    "# # _st1.filter(\"bandpass\", freqmin=0.001, freqmax=5.0, corners=4, zerophase=True)\n",
    "# # _st1.plot();\n",
    "\n",
    "# # _st2.detrend(\"demean\")\n",
    "# # _st2.filter(\"bandpass\", freqmin=0.001, freqmax=5.0, corners=4, zerophase=True)\n",
    "# # _st2.plot();\n",
    "\n",
    "# x = _st1[0].data\n",
    "# y = _st2[0].data\n",
    "# dt = _st1[0].stats.delta\n",
    "\n",
    "# P1 = MTSpec(x, 4, 5, dt)\n",
    "# P2 = MTSpec(y, 4, 5, dt)\n",
    "\n",
    "# Pxy  = MTCross(P1, P2, wl=0.001)\n",
    "\n",
    "# from numpy.fft import fft\n",
    "\n",
    "# N = Pxy.freq.size\n",
    "\n",
    "# fxy_new, pxy_new = Pxy.freq[:,0][:N//2+1], Pxy.cohe[:,0][:N//2+1]\n",
    "\n",
    "# # plt.semilogx(dcohe[len(dcohe)//2:])\n",
    "# plt.semilogx(fxy_new, pxy_new)\n",
    "# # plt.semilogx(Pxy.freq[:,0], Pxy.cohe[:,0])\n",
    "\n",
    "# psd1.size, fxy_new.size, pxy_new.size, fxy_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834af35a-d8c6-4e30-a528-149dfc218402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from scipy.signal import resample_poly\n",
    "\n",
    "# pxy_new = resample_poly(Pxy.cohe, 2, 4)\n",
    "\n",
    "# fxy_new = resample_poly(Pxy.freq, 2, 4)\n",
    "\n",
    "# plt.semilogx(Pxy.freq, Pxy.cohe)\n",
    "# plt.semilogx(fxy_new, pxy_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b5fda-5b22-4b81-9a45-9c34558ad2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6749c40-2cec-4b0d-a206-a1972f37d2b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from gwpy.timeseries import TimeSeriesDict\n",
    "# from pandas import DataFrame\n",
    "# from gwpy.timeseries import TimeSeries\n",
    "\n",
    "# dat1 = TimeSeries(_st1[0].data, t0=0, dt=0.1, channel=\"d1\")\n",
    "# dat2 = TimeSeries(_st2[0].data, t0=0, dt=0.1, channel=\"d2\")\n",
    "\n",
    "# # coh = dat1.coherence_spectrogram(dat2, 10, fftlength=1/1000, overlap=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b098982-f8c3-4a6b-9f01-981f27994a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = coh.plot()\n",
    "# ax = plot.gca()\n",
    "# ax.set_ylabel('Frequency [Hz]')\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_ylim(10, 8000)\n",
    "# ax.set_title(\n",
    "#     'Coherence between PSL periscope motion and LIGO-Hanford strain data',\n",
    "# )\n",
    "# ax.grid(True, 'both', 'both')\n",
    "# ax.colorbar(label='Coherence', clim=[0, 1], cmap='plasma')\n",
    "# plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d96d4-325e-4245-bda2-2bbcf3273eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff68138-a0f3-43f0-a016-e2be780fe960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
