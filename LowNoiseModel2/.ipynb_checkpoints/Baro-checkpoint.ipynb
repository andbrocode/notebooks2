{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b61cd4",
   "metadata": {},
   "source": [
    "## PSD of BaroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4323b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T10:39:56.274325Z",
     "start_time": "2023-08-07T10:39:56.263933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from obspy import UTCDateTime, read, Stream, Trace, read_inventory\n",
    "# from scipy.signal import welch\n",
    "# from numpy import log10, zeros, append, linspace, mean, median, array, where, transpose, shape, histogram\n",
    "# from pandas import DataFrame, concat, Series, date_range, to_pickle, read_csv\n",
    "# from pathlib import Path\n",
    "# from andbro__load_FURT_stream import __load_furt_streamn\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56e9a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T10:39:56.856701Z",
     "start_time": "2023-08-07T10:39:56.848988Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == 'lighthouse':\n",
    "    root_path = '/home/andbro/'\n",
    "    data_path = '/home/andbro/kilauea-data/'\n",
    "    archive_path = '/home/andbro/freenas/'\n",
    "elif os.uname().nodename == 'kilauea':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd25eea-6808-45f7-b9d7-18e46d4174a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tbeg, tend = UTCDateTime(\"2023-09-03\"), UTCDateTime(\"2023-09-07\")\n",
    "tbeg, tend = UTCDateTime(\"2023-10-04\"), UTCDateTime(\"2023-10-08\")\n",
    "\n",
    "\n",
    "## time of inlet below gravel\n",
    "t_gravel = UTCDateTime(\"2023-09-20 12:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f57953-fb99-4905-a854-afd3d2b7c269",
   "metadata": {},
   "source": [
    "# IROMY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb07d41-9d27-48b9-b9b5-6385b8c81668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from andbro__read_sds import __read_sds\n",
    "from obspy import read_inventory\n",
    "\n",
    "## period to check data... one sided differential signals...\n",
    "# tbeg, tend = \"2023-08-13\",\"2023-08-20\"\n",
    "# ffbi = __read_sds(\"/import/kilauea-data/LNM2/mb2000/sds/\", \"BW.IROMY..BD*\", tbeg, tend)\n",
    "\n",
    "ffbi = __read_sds(\"/bay200/mseed_online/archive/\", \"BW.FFBI..BD*\", tbeg, tend)\n",
    "\n",
    "ffbi_inv = read_inventory(root_path+\"/Documents/ROMY/ROMY_infrasound/station_BW_FFBI.xml\")\n",
    "\n",
    "ffbi = ffbi.remove_sensitivity(ffbi_inv)\n",
    "\n",
    "## remove gain and sensitivity\n",
    "# for tr in ffbi:\n",
    "#     if \"DF\" in tr.stats.channel:\n",
    "#         tr.data = tr.data /1.0 /6.28099e5 /0.02  # gain=1 sensitivity_reftek=6.28099e5cou/nt/V; sensitivity_mb2005=0.02 VPa\n",
    "#     elif \"DI\" in tr.stats.channel:\n",
    "#         tr.data = tr.data /1.0 /6.28099e5 /1e-3  # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity = 1 mV/hPa\n",
    "#     elif \"DO\" in tr.stats.channel:\n",
    "#         tr.data = tr.data /1.0 /6.28099e5 /100e-3   # gain=1 sensitivity_reftek=6.28099e5count/V; sensitivity = 100 mV/hPa\n",
    "\n",
    "ffbi.merge()\n",
    "\n",
    "print(ffbi)\n",
    "\n",
    "ffbi.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd901a22-1c2a-4b92-83a9-cf6e1e4a3ffd",
   "metadata": {},
   "source": [
    "## PROMY Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80873e1c-851f-4e1a-820a-b6f3fd344ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "archive_path+\"romy_archive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119c52c-3bc7-4663-a0dd-713d62f1d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "promy = __read_sds(archive_path+\"romy_archive/\", \"BW.PROMY..L*\", tbeg, tend)\n",
    "\n",
    "promy.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a540c-1252-4f4c-af0a-f2805ed4e4bf",
   "metadata": {},
   "source": [
    "# FURT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8ebeb-bf70-4818-a498-5dab94f3eb3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from andbro__load_FURT_stream import __load_furt_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1224c-a69c-4217-b77d-361a4430a04b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load ~/andbro_python/andbro__load_FURT_stream.py\n",
    "#!/bin/python3\n",
    "\n",
    "def __load_furt_stream(starttime, endtime, show_raw=False, sampling_rate=1.0, path_to_archive = '/bay200/gif_online/FURT/WETTER/'):\n",
    "\n",
    "    '''\n",
    "    Load a selection of data of FURT weather station for certain times and return an obspy stream\n",
    "\n",
    "\n",
    "    PARAMETERS:\n",
    "        - config:    configuration dictionary\n",
    "        - show_raw:  bool (True/False) -> shows raw data FURT head\n",
    "\n",
    "\n",
    "    RETURN:\n",
    "        - stream\n",
    "\n",
    "    EXAMPLE:\n",
    "    >>> __load_furt_stream(config, show_raw=False, path_to_archive = '/bay200/gif_online/FURT/WETTER/')\n",
    "\n",
    "    '''\n",
    "\n",
    "    from pathlib import Path\n",
    "    from obspy import UTCDateTime\n",
    "    from tqdm.notebook import tqdm_notebook\n",
    "    from numpy import arange, ones, nan\n",
    "    from obspy import Stream\n",
    "    from pandas import concat, to_datetime, read_csv, DataFrame\n",
    "\n",
    "    def __add_trace(cha, tbeg, dat, dt=1):\n",
    "\n",
    "        from obspy import Trace, UTCDateTime\n",
    "        from numpy import array\n",
    "\n",
    "        tr = Trace()\n",
    "        tr.stats.station = 'FURT'\n",
    "        tr.stats.network = 'BW'\n",
    "        tr.stats.channel = str(cha)\n",
    "        tr.stats.sampling_rate = 1/dt\n",
    "        tr.stats.starttime = UTCDateTime(tbeg)\n",
    "        tr.data = array(dat)\n",
    "\n",
    "        return tr\n",
    "\n",
    "    def __resample(df, freq='1S'):\n",
    "\n",
    "        ## make column with datetime\n",
    "        df['datetime'] = df['date'].astype(str).str.rjust(6,\"0\")+\" \"+df['time'].astype(str).str.rjust(6,\"0\")\n",
    "\n",
    "        ## drop datetime duplicates\n",
    "        df = df[df.duplicated(\"datetime\", keep=\"first\") != True]\n",
    "\n",
    "        ## convert to pandas datetime object\n",
    "        df['datetime'] = to_datetime(df['datetime'], format=\"%d%m%y %H%M%S\", errors=\"coerce\")\n",
    "\n",
    "        ## set datetime column as index\n",
    "        df.set_index('datetime', inplace=True)\n",
    "\n",
    "        ## remove duplicates\n",
    "        df = df[~df.index.duplicated()]\n",
    "\n",
    "        ## resample\n",
    "        df = df.asfreq(freq=freq)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    starttime = UTCDateTime(starttime)\n",
    "    endtime = UTCDateTime(endtime)\n",
    "\n",
    "    output_text = []\n",
    "\n",
    "    new_delta = 1/sampling_rate\n",
    "\n",
    "    if not Path(path_to_archive).exists():\n",
    "        output_text.append(f\"  -> Path: {path_to_archive}, does not exist!\")\n",
    "#         print(f\"  -> Path: {path_to_archive}, does not exists!\")\n",
    "        return\n",
    "\n",
    "\n",
    "    ## declare empyt dataframe\n",
    "    df = DataFrame()\n",
    "\n",
    "    for i, date in enumerate(arange(starttime.date, (endtime+86400+10).date)):\n",
    "\n",
    "        date = UTCDateTime(str(date)).date\n",
    "        filename = f'FURT.WSX.D.{str(date.day).rjust(2,\"0\")}{str(date.month).rjust(2,\"0\")}{str(date.year).rjust(2,\"0\")[-2:]}.0000'\n",
    "\n",
    "        if show_raw:\n",
    "            df0 = read_csv(path_to_archive+filename)\n",
    "            print(df0.columns.tolist())\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                try:\n",
    "                    df0 = read_csv(path_to_archive+filename, header=0, usecols=[0,1,5,8,10,12,13,14], names=['date', 'time', 'Dm', 'Sm', 'T', 'H', 'P','Rc'])\n",
    "                except:\n",
    "                    df0 = read_csv(path_to_archive+filename, usecols=[0,1,5,8,10,12,13,14], names=['date', 'time', 'Dm', 'Sm', 'T', 'H', 'P','Rc'])\n",
    "            except:\n",
    "                print(f\" -> loading of {filename} failed!\")\n",
    "\n",
    "\n",
    "\n",
    "            ## substitute strings with floats\n",
    "\n",
    "            ## __________________________________________\n",
    "            ## air temperature Ta in degree C\n",
    "            # try:\n",
    "                # df0['T']  = [float(str(str(t).split(\"=\")[1]).split(\"C\")[0]) for t in df0['T']]\n",
    "            # except:\n",
    "            #     df0['T'] = ones(len(df0['T']))*nan\n",
    "            #     print(f\" -> {filename}: subsituted T with nan...\")\n",
    "\n",
    "            TT = ones(len(df0['T']))*nan\n",
    "            for _n, t in enumerate(df0['T']):\n",
    "                try:\n",
    "                    TT[_n] = float(str(str(t).split(\"=\")[1]).split(\"C\")[0])\n",
    "                except:\n",
    "                    # print(t)\n",
    "                    continue\n",
    "            df0['T'] = TT\n",
    "\n",
    "            ## __________________________________________\n",
    "            ## air pressure Pa in hPa\n",
    "\n",
    "            PP = ones(len(df0['P']))*nan\n",
    "            for _n, p in enumerate(df0['P']):\n",
    "                try:\n",
    "                    PP[_n] = float(str(str(p).split(\"=\")[1]).split(\"H\")[0])\n",
    "                except:\n",
    "                    # print(p)\n",
    "                    continue\n",
    "            df0['P'] = PP\n",
    "\n",
    "            ## __________________________________________\n",
    "            # ## relative humiditiy Ua in %RH\n",
    "\n",
    "            HH = ones(len(df0['H']))*nan\n",
    "            for _n, h in enumerate(df0['H']):\n",
    "                try:\n",
    "                    HH[_n] = float(str(str(h).split(\"=\")[1]).split(\"P\")[0])\n",
    "                except:\n",
    "                    # print(h)\n",
    "                    continue\n",
    "            df0['H'] = HH\n",
    "\n",
    "            ## __________________________________________\n",
    "            # ## rain accumulation in mm\n",
    "\n",
    "            Rc = ones(len(df0['Rc']))*nan\n",
    "            for _n, rc in enumerate(df0['Rc']):\n",
    "                try:\n",
    "                    Rc[_n] = float(str(str(rc).split(\"=\")[1]).split(\"M\")[0])\n",
    "                except:\n",
    "                    # print(rc)\n",
    "                    continue\n",
    "            df0['Rc'] = Rc\n",
    "\n",
    "            ## __________________________________________\n",
    "            # ## wind speed average in m/s\n",
    "\n",
    "            Sm = ones(len(df0['Sm']))*nan\n",
    "            for _n, sm in enumerate(df0['Sm']):\n",
    "                try:\n",
    "                    Sm[_n] = float(str(str(sm).split(\"=\")[1]).split(\"M\")[0])\n",
    "                except:\n",
    "                    # print(sm)\n",
    "                    continue\n",
    "            df0['Sm'] = Sm\n",
    "\n",
    "            ## __________________________________________\n",
    "            # ## wind direction average in degrees\n",
    "\n",
    "            Dm = ones(len(df0['Dm']))*nan\n",
    "            for _n, dm in enumerate(df0['Dm']):\n",
    "                try:\n",
    "                    Dm[_n] = float(str(str(dm).split(\"=\")[1]).split(\"D\")[0])\n",
    "                except:\n",
    "                    # print(dm)\n",
    "                    continue\n",
    "            df0['Dm'] = Dm\n",
    "\n",
    "\n",
    "            ## __________________________________________\n",
    "\n",
    "            ## replace error indicating values (-9999, 999.9) with NaN values\n",
    "#             df0.replace(to_replace=-9999, value=nan, inplace=True)\n",
    "#             df0.replace(to_replace=999.9, value=nan, inplace=True)\n",
    "\n",
    "\n",
    "            if df.empty:\n",
    "                df = df0\n",
    "            else:\n",
    "                try:\n",
    "                    df = concat([df, df0])\n",
    "                except:\n",
    "                    print(f\"  -> failed to concat for {filename}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            output_text.append(f\"  -> {filename}, failed!\")\n",
    "#             print(f\"  -> File: {filename}, does not exists!\")\n",
    "\n",
    "    ## reset the index for the joined frame\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "    ## resample dataframe and avoid data gaps\n",
    "    df = __resample(df, freq=f'{new_delta}S')\n",
    "\n",
    "\n",
    "    for text in output_text:\n",
    "        print(text)\n",
    "\n",
    "    df_starttime = UTCDateTime(df.index[0])\n",
    "\n",
    "    ## create stream and attach traces\n",
    "    st0 = Stream()\n",
    "    st0 += __add_trace(\"LAT\", df_starttime, df['T'], dt=new_delta)\n",
    "    st0 += __add_trace(\"LAP\", df_starttime, df['P'], dt=new_delta)\n",
    "    st0 += __add_trace(\"LAH\", df_starttime, df['H'], dt=new_delta)\n",
    "    st0 += __add_trace(\"LAR\", df_starttime, df['Rc'], dt=new_delta)\n",
    "    st0 += __add_trace(\"LAW\", df_starttime, df['Sm'], dt=new_delta)\n",
    "    st0 += __add_trace(\"LAD\", df_starttime, df['Dm'], dt=new_delta)\n",
    "\n",
    "    ## correct mseed naming\n",
    "    # st0 += __add_trace(\"LKO\", df_starttime, df['T'], dt=new_delta)\n",
    "    # st0 += __add_trace(\"LDO\", df_starttime, df['P'], dt=new_delta)\n",
    "    # st0 += __add_trace(\"LIO\", df_starttime, df['H'], dt=new_delta)\n",
    "    # st0 += __add_trace(\"LXR\", df_starttime, df['Rc'], dt=new_delta)\n",
    "\n",
    "    ## trim to specfied time period\n",
    "    st0.trim(starttime, endtime-new_delta/2)\n",
    "\n",
    "    t1 ,t2 = endtime-new_delta, st0.select(channel='*T')[0].stats.endtime\n",
    "    if t1 != t2:\n",
    "        print(f\"Specified end: {t1} \\nTrace end:     {t2}\")\n",
    "\n",
    "    return st0\n",
    "\n",
    "## END OF FILE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b51387-d51e-4bb5-bfbf-d13615d00dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "furt = __load_furt_stream(tbeg, tend, show_raw=False, sampling_rate=1.0)\n",
    "furt.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8816f6e-0934-4087-9572-6a617e00cd44",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7234259d-e5af-4243-9a6a-84a116290226",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(15,10), sharex=True)\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    from numpy import ones, convolve, zeros, array, concatenate\n",
    "    box = ones(box_pts)/box_pts\n",
    "    y = concatenate((zeros(box_pts), array(y), zeros(box_pts)))\n",
    "    y_smooth = convolve(y, box, mode='same')\n",
    "    return y_smooth[box_pts:-box_pts]\n",
    "\n",
    "\n",
    "time_scaling = 86400\n",
    "\n",
    "ax[0].plot(ffbi.select(channel=\"*F\")[0].times()/time_scaling, ffbi.select(channel=\"*F\")[0].data, label=\"FFBI\", color=\"k\")\n",
    "\n",
    "\n",
    "ax[1].plot(ffbi.select(channel=\"*O\")[0].times()/time_scaling, ffbi.select(channel=\"*O\")[0].data*1000, label=\"FFBI\", color=\"k\")\n",
    "ax[1].plot(promy.select(channel=\"LDI\")[0].times()/time_scaling, promy.select(channel=\"LDI\")[0].data/100, label=\"PROMY\", color=\"tab:blue\")\n",
    "ax[1].plot(furt.select(channel=\"LAP\")[0].times()/time_scaling, furt.select(channel=\"LAP\")[0].data, label=\"FURT\", color=\"tab:orange\")\n",
    "\n",
    "\n",
    "ax[2].plot(furt.select(channel=\"LAT\")[0].times()/time_scaling, furt.select(channel=\"LAT\")[0].data, label=\"FURT\", color=\"tab:red\")\n",
    "ax22 = ax[2].twinx()\n",
    "ax22.plot(promy.select(channel=\"LKI\")[0].times()/time_scaling, promy.select(channel=\"LKI\")[0].data, label=\"PROMY\", color=\"tab:brown\")\n",
    "ax22.legend(loc=4)\n",
    "ax22.tick_params(axis='y', colors=\"tab:brown\")\n",
    "\n",
    "\n",
    "ax[3].plot(furt.select(channel=\"LAW\")[0].times()/time_scaling, furt.select(channel=\"LAW\")[0].data, color=\"tab:green\")\n",
    "ax32 = ax[3].twinx()\n",
    "wind_direction = smooth(furt.select(channel=\"LAD\")[0].data, 1200)\n",
    "ax32.plot(furt.select(channel=\"LAD\")[0].times()/time_scaling, wind_direction, color=\"tab:purple\")\n",
    "ax32.set_ylim(0, 360)\n",
    "ax32.tick_params(axis='y', colors=\"tab:purple\")\n",
    "\n",
    "\n",
    "ax22.set_ylabel(\"Temperature (°C)\", color=\"tab:brown\")\n",
    "ax32.set_ylabel(\"Wind Direction (°)\", color=\"tab:purple\")\n",
    "ax[0].set_ylabel(\"Diff. Pressure (Pa)\")\n",
    "ax[1].set_ylabel(\"Abs. Pressure (hPa)\")\n",
    "ax[2].set_ylabel(\"Temperature (°C)\")\n",
    "ax[3].set_ylabel(\"Wind (m/s)\")\n",
    "\n",
    "ax[3].set_xlabel(f\"Time from {tbeg.date} {str(tbeg.time).split('.')[0]} UTC (days)\")\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].grid(alpha=0.5, color=\"grey\", zorder=0)\n",
    "    ax[i].legend()\n",
    "    ax[i].axvline((t_gravel-tbeg)/time_scaling, color=\"darkblue\", ls=\"--\")\n",
    "\n",
    "ax[1].set_ylim(930, 980)\n",
    "ax[3].set_xlim(0, max(promy.select(channel=\"LDI\")[0].times()/time_scaling))\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509c5e0-2ef9-4479-b594-91c49f5f538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"/home/brotzer/Documents/ROMY/ROMY_infrasound/comparison_inlet_below_ground.png\", dpi=200, format=\"png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb6b93-cfca-4038-9098-a10f3da24ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
