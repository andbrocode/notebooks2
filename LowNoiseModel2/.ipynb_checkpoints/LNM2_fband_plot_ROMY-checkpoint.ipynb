{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda030d3",
   "metadata": {},
   "source": [
    "# Scatter Plots - ROMY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-presentation",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behind-arrangement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:54:03.050940Z",
     "start_time": "2023-08-07T14:54:00.312331Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "from scipy.signal import welch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import os, gc\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from andbro__store_as_pickle import __store_as_pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f337911b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:54:03.147385Z",
     "start_time": "2023-08-07T14:54:03.133998Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == 'lighthouse':\n",
    "    root_path = '/home/andbro/'\n",
    "    data_path = '/home/andbro/kilauea-data/'\n",
    "    archive_path = '/home/andbro/freenas/'\n",
    "    bay_path = '/home/andbro/ontap-ffb-bay200/'\n",
    "    lamont_path = '/home/andbro/lamont/'\n",
    "elif os.uname().nodename == 'kilauea':\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/import/ontap-ffb-bay200/'\n",
    "    lamont_path = '/lamont/'\n",
    "elif os.uname().nodename in ['lin-ffb-01', 'ambrym', 'hochfelln']:\n",
    "    root_path = '/home/brotzer/'\n",
    "    data_path = '/import/kilauea-data/'\n",
    "    archive_path = '/import/freenas-ffb-01-data/'\n",
    "    bay_path = '/import/ontap-ffb-bay200/'\n",
    "    lamont_path = '/lamont/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e4536-c4f6-4dca-893a-94e37a1e81bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "subject-expression",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565a7b24-4640-4f17-b66e-2ee951eeee5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T15:31:55.890800Z",
     "start_time": "2023-08-07T15:31:55.885708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "# long data january - september\n",
    "config['project'] = \"2\"\n",
    "\n",
    "config['codes'] = {\"\":\"B\", \"2\":\"L\"}\n",
    "\n",
    "# ---------------------------------------\n",
    "c = config['codes'][config['project']]\n",
    "\n",
    "name01 = f\"FFBI_{c}DO\"\n",
    "name02 = f\"FFBI_{c}DF\"\n",
    "\n",
    "name1 = \"ROMY_BJN\"\n",
    "name2 = \"ROMY_BJE\"\n",
    "name3 = \"ROMY_BJZ\"\n",
    "\n",
    "t1, t2 = \"2024-01-01\", \"2024-09-30\"\n",
    "\n",
    "# data set 2 - januar to september\n",
    "config['path_to_figs'] = data_path+f\"LNM2/figures{config['project']}/scatter/\"\n",
    "\n",
    "config['path_to_data'] = data_path+f\"LNM2/data{config['project']}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-beginning",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa8d665-8b20-493b-87a9-dd980fe788aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.get_octave_bands import __get_octave_bands\n",
    "from functions.quantile_regression import __quantile_regression\n",
    "from functions.compute_odr import __compute_orthogonal_distance_regression\n",
    "from functions.statistical_odr import statistical_odr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f4f00-0fb0-4e76-b876-3f0afd624616",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d134d2-6924-456d-9779-e313619d9fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat01 = pd.read_pickle(config['path_to_data']+name01+\".pkl\")\n",
    "dat02 = pd.read_pickle(config['path_to_data']+name02+\".pkl\")\n",
    "\n",
    "dat1 = pd.read_pickle(config['path_to_data']+name1+\".pkl\")\n",
    "dat2 = pd.read_pickle(config['path_to_data']+name2+\".pkl\")\n",
    "dat3 = pd.read_pickle(config['path_to_data']+name3+\".pkl\")\n",
    "\n",
    "coh11 = pd.read_pickle(config['path_to_data']+name01+\"_\"+name1+\"_coherence.pkl\")\n",
    "coh12 = pd.read_pickle(config['path_to_data']+name01+\"_\"+name2+\"_coherence.pkl\")\n",
    "coh13 = pd.read_pickle(config['path_to_data']+name01+\"_\"+name3+\"_coherence.pkl\")\n",
    "\n",
    "coh21 = pd.read_pickle(config['path_to_data']+name02+\"_\"+name1+\"_coherence.pkl\")\n",
    "coh22 = pd.read_pickle(config['path_to_data']+name02+\"_\"+name2+\"_coherence.pkl\")\n",
    "coh23 = pd.read_pickle(config['path_to_data']+name02+\"_\"+name3+\"_coherence.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24093c5f-3ecb-4afb-8a83-ff43d7d501e5",
   "metadata": {},
   "source": [
    "## Plot all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a240158-68e1-4de7-b7ca-a5ad2b9cc830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeplot():\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "    font = 12\n",
    "\n",
    "    cmap = plt.colormaps.get(\"viridis\")\n",
    "    cmap = plt.get_cmap(\"viridis\", 10)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.12)\n",
    "\n",
    "    ca1 = ax[0].scatter(10**xx1, 10**yy1, s=15, c=ccoh1, edgecolors=\"black\", lw=0.5, zorder=2, cmap=cmap, vmin=0., vmax=1)\n",
    "    ca2 = ax[1].scatter(10**xx2, 10**yy2, s=15, c=ccoh2, edgecolors=\"black\", lw=0.5, zorder=2, cmap=cmap, vmin=0., vmax=1)\n",
    "    ca3 = ax[2].scatter(10**xx3, 10**yy3, s=15, c=ccoh3, edgecolors=\"black\", lw=0.5, zorder=2, cmap=cmap, vmin=0., vmax=1)\n",
    "\n",
    "#     try:\n",
    "#         ax[0].plot(10**xx1, 10**pre1[0.01], color=\"k\", zorder=1, ls=\":\", label=\"90%-fit\")\n",
    "#         ax[1].plot(10**xx2, 10**pre2[0.01], color=\"k\", zorder=1, ls=\":\", label=\"90%-fit\")\n",
    "#         ax[2].plot(10**xx3, 10**pre3[0.01], color=\"k\", zorder=1, ls=\":\", label=\"90%-fit\")\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         pass\n",
    "\n",
    "    ## add correlation estimate\n",
    "    _xx = np.logspace(-10, 10, 100)\n",
    "    _yy = 1e-22 * _xx\n",
    "\n",
    "    # ax[0].plot(_xx, _yy + _xx*1e-17, color=\"darkred\", ls=\"--\", label=\"1 $m^2/s^4/Pa^2$\")\n",
    "    # ax[1].plot(_xx, _yy + _xx*1e-17, color=\"darkred\", ls=\"--\", label=\"1 $m^2/s^4/Pa^2$\")\n",
    "    # ax[2].plot(_xx, _yy + _xx*1e-19, color=\"darkred\", ls=\"--\", label=\"1 $m^2/s^4/Pa^2$\")\n",
    "\n",
    "    try:\n",
    "        _xx = np.linspace(-10, 10, 100)\n",
    "        for _i, (slope, intercept) in enumerate(zip([slopeZ, slopeN, slopeE], [interZ, interN, interE])):\n",
    "\n",
    "            _intercept = np.sqrt(10**intercept)*1e11\n",
    "            ax[_i].plot(10**(_xx), 10**(_xx*slope+intercept), color=\"red\", ls=\"--\", label=f\"{round(_intercept,3)} $nrad/s/hPa$ (CC > {coh_thres})\")\n",
    "\n",
    "            # _intercept2 = np.sqrt(10**(intercept-shift_intercept))*1e11\n",
    "            # ax[_i].plot(10**(_xx), 10**(_xx*1+(intercept-shift_intercept)), color=\"purple\", ls=\"--\", label=f\"{round(_intercept2,3)} $nrad/s/hPa$\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    for _i in range(3):\n",
    "        ax[_i].set_xscale(\"log\")\n",
    "        ax[_i].set_yscale(\"logit\")\n",
    "        ax[_i].set_xlim(1e-2, 1e7)\n",
    "        ax[_i].set_ylim(1e-23, 1e-15)\n",
    "        ax[_i].grid(zorder=0, alpha=0.5, which=\"both\")\n",
    "        ax[_i].legend(loc=2)\n",
    "        ax[_i].set_xlabel(r\"PSD (Pa$^2$ /Hz)\", fontsize=font)\n",
    "\n",
    "        ax[_i].xaxis.set_major_locator(mticker.LogLocator(numticks=999))\n",
    "        ax[_i].xaxis.set_minor_locator(mticker.LogLocator(numticks=999, subs=\"auto\"))\n",
    "\n",
    "    # ax[0].set_title(f\"{name0.replace('_','-')} & {name1.replace('_','-')} | fc = {float(_df1.keys()[1][:-2])*1e3} mHz\")\n",
    "    # ax[1].set_title(f\"{name0.replace('_','-')} & {name2.replace('_','-')} | fc = {float(_df2.keys()[1][:-2])*1e3} mHz\")\n",
    "    # ax[2].set_title(f\"{name0.replace('_','-')} & {name3.replace('_','-')} | fc = {float(_df3.keys()[1][:-2])*1e3} mHz\")\n",
    "    ax[0].set_title(f\"{name00.replace('_','-')} & {name1.replace('_','-')} | {round(f_lower[_n]*1e3, 1)} - {round(f_upper[_n]*1e3, 1)} mHz\")\n",
    "    ax[1].set_title(f\"{name00.replace('_','-')} & {name2.replace('_','-')} | {round(f_lower[_n]*1e3, 1)} - {round(f_upper[_n]*1e3, 1)} mHz\")\n",
    "    ax[2].set_title(f\"{name00.replace('_','-')} & {name3.replace('_','-')} | {round(f_lower[_n]*1e3, 1)} - {round(f_upper[_n]*1e3, 1)} mHz\")\n",
    "\n",
    "    ax[0].text(.8, .04, f\"N={len(xx1)}\", ha='left', va='top', transform=ax[0].transAxes, fontsize=font)\n",
    "    ax[1].text(.8, .04, f\"N={len(xx2)}\", ha='left', va='top', transform=ax[1].transAxes, fontsize=font)\n",
    "    ax[2].text(.8, .04, f\"N={len(xx3)}\", ha='left', va='top', transform=ax[2].transAxes, fontsize=font)\n",
    "\n",
    "    ax[0].set_ylabel(r\"PSD (rad$^2$ /s$^2$ /Hz)\", fontsize=font)\n",
    "\n",
    "    ## add colorbar\n",
    "    cbar_ax = fig.add_axes([0.92, 0.11, 0.01, 0.77]) #[left, bottom, width, height]\n",
    "    cb = plt.colorbar(ca1, cax=cbar_ax)\n",
    "    cb.set_label(\"Coherence\", fontsize=font, labelpad=-50, color=\"black\")\n",
    "\n",
    "    plt.show();\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc04d6-a911-42d3-9e34-f21d43093155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "f_lower, f_upper, f_center = __get_octave_bands(1e-3, 1e0, faction_of_octave=12, plot=False)\n",
    "\n",
    "# N_bands = dat01.shape[1] - 1\n",
    "N_bands = len(f_center)\n",
    "\n",
    "bands = dat01.keys()[1:]\n",
    "\n",
    "# compliance\n",
    "compl = pd.DataFrame()\n",
    "compl['fl'] = f_lower\n",
    "compl['fu'] = f_upper\n",
    "compl['fc'] = f_center\n",
    "\n",
    "f_compl, complN, complE, complZ = np.ones(N_bands)*np.nan, np.ones(N_bands)*np.nan, np.ones(N_bands)*np.nan, np.ones(N_bands)*np.nan\n",
    "complN_pu, complE_pu, complZ_pu = np.ones(N_bands)*np.nan, np.ones(N_bands)*np.nan, np.ones(N_bands)*np.nan\n",
    "complN_pl, complE_pl, complZ_pl = np.ones(N_bands)*np.nan, np.ones(N_bands)*np.nan, np.ones(N_bands)*np.nan\n",
    "\n",
    "\n",
    "for _n, band in enumerate(bands):\n",
    "\n",
    "    # if not _n == 13:\n",
    "    # shape(2, N): Separate - and + values for each bar. First row contains the lower errors, the second row contains the upper errors.    continue\n",
    "\n",
    "    if pd.isnull(dat01.loc[:, band]).all():\n",
    "        continue\n",
    "\n",
    "    _dat1 = dat1.loc[:, [\"dates\", band]]\n",
    "    _dat2 = dat2.loc[:, [\"dates\", band]]\n",
    "    _dat3 = dat3.loc[:, [\"dates\", band]]\n",
    "\n",
    "    if band < 0.01:\n",
    "        _dat0 = dat01.loc[:, [\"dates\", band]]\n",
    "\n",
    "        name00 = name01\n",
    "\n",
    "        _coh1 = coh11.loc[:, [\"dates\", band]]\n",
    "        _coh2 = coh12.loc[:, [\"dates\", band]]\n",
    "        _coh3 = coh13.loc[:, [\"dates\", band]]\n",
    "\n",
    "    else:\n",
    "        _dat0 = dat02.loc[:, [\"dates\", band]]\n",
    "\n",
    "        name00 = name02\n",
    "\n",
    "        _coh1 = coh21.loc[:, [\"dates\", band]]\n",
    "        _coh2 = coh22.loc[:, [\"dates\", band]]\n",
    "        _coh3 = coh23.loc[:, [\"dates\", band]]\n",
    "\n",
    "    # join data frames based on dates and hour\n",
    "    _df1 = pd.merge(left=_dat0, right=_dat1, how=\"inner\", on=\"dates\")\n",
    "    _df2 = pd.merge(left=_dat0, right=_dat2, how=\"inner\", on=\"dates\")\n",
    "    _df3 = pd.merge(left=_dat0, right=_dat3, how=\"inner\", on=\"dates\")\n",
    "\n",
    "    _df1 = pd.merge(left=_df1, right=_coh1, how=\"inner\", on=\"dates\")\n",
    "    _df2 = pd.merge(left=_df2, right=_coh2, how=\"inner\", on=\"dates\")\n",
    "    _df3 = pd.merge(left=_df3, right=_coh3, how=\"inner\", on=\"dates\")\n",
    "\n",
    "    # remove NaN values\n",
    "    _df1.dropna(inplace=True)\n",
    "    _df2.dropna(inplace=True)\n",
    "    _df3.dropna(inplace=True)\n",
    "\n",
    "    # remove large values\n",
    "    _df1 = _df1[_df1.iloc[:, 2] < 1e-16]\n",
    "    _df2 = _df2[_df2.iloc[:, 2] < 1e-16]\n",
    "    _df3 = _df3[_df3.iloc[:, 2] < 1e-16]\n",
    "\n",
    "    # cut time interval\n",
    "    _df1 = _df1[(_df1.dates > UTCDateTime(t1)) & (_df1.dates < UTCDateTime(t2))]\n",
    "    _df2 = _df2[(_df2.dates > UTCDateTime(t1)) & (_df2.dates < UTCDateTime(t2))]\n",
    "    _df3 = _df3[(_df3.dates > UTCDateTime(t1)) & (_df3.dates < UTCDateTime(t2))]\n",
    "\n",
    "    # reset the index\n",
    "    _df1 = _df1.reset_index(drop=True)\n",
    "    _df2 = _df2.reset_index(drop=True)\n",
    "    _df3 = _df3.reset_index(drop=True)\n",
    "\n",
    "    # sort for bands\n",
    "    _df1 = _df1.sort_values(by=band, ascending=True)\n",
    "    _df2 = _df2.sort_values(by=band, ascending=True)\n",
    "    _df3 = _df3.sort_values(by=band, ascending=True)\n",
    "\n",
    "    # remove zeros (they make trouble for the log10)\n",
    "    print(_df1.shape, _df2.shape, _df3.shape)\n",
    "    _df1 = _df1[~(_df1.iloc[:, :2] == 0).any(axis=1)]\n",
    "    _df2 = _df2[~(_df2.iloc[:, :2] == 0).any(axis=1)]\n",
    "    _df3 = _df3[~(_df3.iloc[:, :2] == 0).any(axis=1)]\n",
    "    # _df3 = _df3[~(_df3 == 0).any(axis=1)]\n",
    "    print(_df1.shape, _df2.shape, _df3.shape)\n",
    "\n",
    "    # reset the index\n",
    "    _df1 = _df1.reset_index(drop=True)\n",
    "    _df2 = _df2.reset_index(drop=True)\n",
    "    _df3 = _df3.reset_index(drop=True)\n",
    "\n",
    "    xx1, yy1, ccoh1 = np.log10(_df1.iloc[:, 1]), np.log10(_df1.iloc[:, 2]), _df1.iloc[:, 3]\n",
    "    xx2, yy2, ccoh2 = np.log10(_df2.iloc[:, 1]), np.log10(_df2.iloc[:, 2]), _df2.iloc[:, 3]\n",
    "    xx3, yy3, ccoh3 = np.log10(_df3.iloc[:, 1]), np.log10(_df3.iloc[:, 2]), _df3.iloc[:, 3]\n",
    "\n",
    "#     try:\n",
    "#         pre1 = __quantile_regression(xx1, yy1, quantiles=[0.01, 0.5, 0.99])\n",
    "#         pre2 = __quantile_regression(xx2, yy2, quantiles=[0.01, 0.5, 0.99])\n",
    "#         pre3 = __quantile_regression(xx3, yy3, quantiles=[0.01, 0.5, 0.99])\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         pass\n",
    "\n",
    "    # only select high coherence (=hc)\n",
    "    coh_thres = 0.8\n",
    "    df1_hc = _df1_high_coh = _df1[_df1.iloc[:, 3] > coh_thres]\n",
    "    df2_hc = _df2_high_coh = _df2[_df2.iloc[:, 3] > coh_thres]\n",
    "    df3_hc = _df3_high_coh = _df3[_df3.iloc[:, 3] > coh_thres]\n",
    "\n",
    "    xx1_hc, yy1_hc = np.log10(df1_hc.iloc[:, 1]), np.log10(df1_hc.iloc[:, 2])\n",
    "    xx2_hc, yy2_hc = np.log10(df2_hc.iloc[:, 1]), np.log10(df2_hc.iloc[:, 2])\n",
    "    xx3_hc, yy3_hc = np.log10(df3_hc.iloc[:, 1]), np.log10(df3_hc.iloc[:, 2])\n",
    "\n",
    "    # xx1_hc, yy1_hc = xx1_hc[~np.isnan(xx1_hc)], yy1_hc[~np.isnan(yy1_hc)]\n",
    "    # xx2_hc, yy2_hc = xx2_hc[~np.isnan(xx2_hc)], yy2_hc[~np.isnan(yy2_hc)]\n",
    "    # xx3_hc, yy3_hc = xx3_hc[~np.isnan(xx3_hc)], yy3_hc[~np.isnan(yy3_hc)]\n",
    "\n",
    "    # define offest for estimated intercept\n",
    "    shift_intercept = 0.\n",
    "\n",
    "#     try:\n",
    "#         if len(xx1_hc) >= 5:\n",
    "#             odr1_slope, odr1_inter = __compute_orthogonal_distance_regression(xx1_hc, yy1_hc, xerr=None, yerr=None, bx=None, by=None)\n",
    "#         else:\n",
    "#             odr1_slope, odr1_inter = np.nan, np.nan\n",
    "#         if len(xx2_hc) >= 5:\n",
    "#             odr2_slope, odr2_inter = __compute_orthogonal_distance_regression(xx2_hc, yy2_hc, xerr=None, yerr=None, bx=None, by=None)\n",
    "#         else:\n",
    "#             odr2_slope, odr2_inter = np.nan, np.nan\n",
    "#         if len(xx3_hc) >= 5:\n",
    "#             odr3_slope, odr3_inter = __compute_orthogonal_distance_regression(xx3_hc, yy3_hc, xerr=None, yerr=None, bx=None, by=None)\n",
    "#         else:\n",
    "#             odr3_slope, odr3_inter = np.nan, np.nan\n",
    "#         try:\n",
    "#             complN[_n] = odr1_inter - shift_intercept\n",
    "#         except:\n",
    "#             complN[_n] = np.nan\n",
    "#         try:\n",
    "#             complE[_n] = odr2_inter - shift_intercept\n",
    "#         except:\n",
    "#             complE[_n] = np.nan\n",
    "#         try:\n",
    "#             complZ[_n] = odr3_inter - shift_intercept\n",
    "#         except:\n",
    "#             complZ[_n] = np.nan\n",
    "\n",
    "#         f_compl[_n] = band\n",
    "\n",
    "#         print(odr1_inter, odr2_inter, odr3_inter)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         f_compl[_n], complN[_n], complE[_n], complZ[_n] = band, np.nan, np.nan, np.nan\n",
    "#         print(\"fail\")\n",
    "#         print(e)\n",
    "#         pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        if len(xx1_hc) >= 10:\n",
    "\n",
    "            # make dataframe and statistical odr\n",
    "            out = statistical_odr(pd.DataFrame({'x':xx1_hc, 'y':yy1_hc}), Ndraws=10, percentile=90)\n",
    "\n",
    "            slopeZ, interZ = out['slope_median'], out['inter_median']\n",
    "            plowerZ, pupperZ = out['inter_plower'], out['inter_pupper']\n",
    "\n",
    "        else:\n",
    "            slopeZ, interZ, plowerZ, pupperZ = np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # append estaimate\n",
    "        complZ[_n], complZ_pl[_n], complZ_pu[_n] = interZ, plowerZ, pupperZ\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if len(xx2_hc) >= 10:\n",
    "\n",
    "            # make dataframe and statistical odr\n",
    "            out = statistical_odr(pd.DataFrame({'x':xx2_hc, 'y':yy2_hc}), Ndraws=10, percentile=90)\n",
    "\n",
    "            slopeN, interN = out['slope_median'], out['inter_median']\n",
    "            plowerN, pupperN = out['inter_plower'], out['inter_pupper']\n",
    "\n",
    "        else:\n",
    "            slopeN, interN, plowerN, pupperN = np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # append estaimate\n",
    "        complN[_n], complN_pl[_n], complN_pu[_n] = interN, plowerN, pupperN\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if len(xx3_hc) >= 10:\n",
    "\n",
    "            # make dataframe and statistical odr\n",
    "            out = statistical_odr(pd.DataFrame({'x':xx3_hc, 'y':yy3_hc}), Ndraws=10, percentile=90)\n",
    "\n",
    "            slopeE, interE = out['slope_median'], out['inter_median']\n",
    "            plowerE, pupperE = out['inter_plower'], out['inter_pupper']\n",
    "\n",
    "        else:\n",
    "            slopeE, interE, plowerE, pupperE = np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "        # append estaimate\n",
    "        complE[_n], complE_pl[_n], complE_pu[_n] = interE, plowerE, pupperE\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    # ____________________________________________________________________\n",
    "\n",
    "    fig = makeplot()\n",
    "\n",
    "    fig.savefig(config['path_to_figs']+f\"all/ROMY/{str(_n).rjust(3, '0')}_{name1}_{name2}_{band}Hz_all.jpg\", format=\"jpg\", dpi=150, bbox_inches='tight');\n",
    "    fig.savefig(config['path_to_figs']+f\"all/ROMY/gif/{str(_n).rjust(3, '0')}_{name1}_{name2}_{band}Hz_all.jpg\", format=\"jpg\", dpi=80, bbox_inches='tight');\n",
    "\n",
    "    del fig\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd44aee-61f1-4ef0-ad8e-8f7b210e1fc5",
   "metadata": {},
   "source": [
    "## Compliance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650625a-3dc4-4f5d-9685-5b0439377c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfac = 1e9*1e2 # converstoni to nano ... / hPa\n",
    "\n",
    "compl['N'] = np.sqrt(10**(complN))*cfac\n",
    "compl['E'] = np.sqrt(10**(complE))*cfac\n",
    "compl['Z'] = np.sqrt(10**(complZ))*cfac\n",
    "\n",
    "compl['N_pupper'] = np.sqrt(10**(complN_pu))*cfac\n",
    "compl['E_pupper'] = np.sqrt(10**(complE_pu))*cfac\n",
    "compl['Z_pupper'] = np.sqrt(10**(complZ_pu))*cfac\n",
    "\n",
    "compl['N_plower'] = np.sqrt(10**(complN_pl))*cfac\n",
    "compl['E_plower'] = np.sqrt(10**(complE_pl))*cfac\n",
    "compl['Z_plower'] = np.sqrt(10**(complZ_pl))*cfac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6544e-d42a-41ca-bb7a-4a7ec5e038cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compl['N'] = np.sqrt(10**complN)*1e9*1e2 # in nrad/hPa\n",
    "# compl['E'] = np.sqrt(10**complE)*1e9*1e2 # in nrad/hPa\n",
    "# compl['Z'] = np.sqrt(10**complZ)*1e9*1e2 # in nrad/hPa\n",
    "\n",
    "# compl.N = np.where(compl.N > 1000, np.nan, compl.N)\n",
    "# compl.E = np.where(compl.E > 1000, np.nan, compl.E)\n",
    "# compl.Z = np.where(compl.Z > 1000, np.nan, compl.Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996be91-33ef-4cfd-8518-cbc6f2c0d918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compl.to_pickle(config['path_to_data']+\"compliance_ROMY.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6fcad-1d7a-4e83-9a70-1e061fd4146b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __makeplot():\n",
    "\n",
    "    Nrow, Ncol = 1, 1\n",
    "\n",
    "    font = 12\n",
    "\n",
    "    scaling = 1\n",
    "\n",
    "    fig, ax = plt.subplots(Nrow, Ncol, figsize=(10, 5))\n",
    "\n",
    "    ax.plot(compl['fc'], compl['N']*scaling, label=f\"{name1}\")\n",
    "    ax.plot(compl['fc'], compl['E']*scaling, label=f\"{name2}\")\n",
    "    ax.plot(compl['fc'], compl['Z']*scaling, label=f\"{name3}\")\n",
    "\n",
    "    ax.grid(ls=\":\", zorder=0)\n",
    "    ax.legend(loc=1)\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    ax.set_xlim(1e-3, 1e0)\n",
    "    ax.set_ylim(-1, 200)\n",
    "\n",
    "    ax.set_xlabel(\"Frequency (Hz)\", fontsize=font)\n",
    "    ax.set_ylabel(\"Compliance (nrad/s/hPa)\", fontsize=font)\n",
    "\n",
    "    plt.show();\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d7b8f-22c1-4b64-9cbb-74c04115cfee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = __makeplot();\n",
    "\n",
    "# fig.savefig(config['path_to_figs']+f\"ROMY_ZNE_compliance.png\", format=\"png\", dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e39b0-c520-4d40-bb34-007fa050586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"\"\"spd-say \"I am ready\" \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
